{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X80i_girFR2o"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "bB8gHCR3FVC0"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCeYA79m1DEX"
   },
   "source": [
    "# Multi-task recommenders\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/multitask\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/multitask.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/multitask.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/multitask.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dk8QEc4sIPMi"
   },
   "source": [
    "In the [basic retrieval tutorial](basic_retrieval) we built a retrieval system using movie watches as positive interaction signals.\n",
    "\n",
    "In many applications, however, there are multiple rich sources of feedback to draw upon. For example, an e-commerce site may record user visits to product pages (abundant, but relatively low signal), image clicks, adding to cart, and, finally, purchases. It may even record post-purchase signals such as reviews and returns.\n",
    "\n",
    "Integrating all these different forms of feedback is critical to building systems that users love to use, and that do not optimize for any one metric at the expense of overall performance.\n",
    "\n",
    "In addition, building a joint model for multiple tasks may produce better results than building a number of task-specific models. This is especially true where some data is abundant (for example, clicks), and some data is sparse (purchases, returns, manual reviews). In those scenarios, a joint model may be able to use representations learned from the abundant task to improve its predictions on the sparse task via a phenomenon known as [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning). For example, [this paper](https://openreview.net/pdf?id=SJxPVcSonN) shows that a model predicting explicit user ratings from sparse user surveys can be substantially improved by adding an auxiliary task that uses abundant click log data.\n",
    "\n",
    "In this tutorial, we are going to build a multi-objective recommender for Movielens, using both implicit (movie watches) and explicit signals (ratings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwrcZeK7x7xI"
   },
   "source": [
    "## Imports\n",
    "\n",
    "\n",
    "Let's first get our imports out of the way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "izzoRqkGb2Zc"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement scann (from versions: none)\n",
      "ERROR: No matching distribution found for scann\n"
     ]
    }
   ],
   "source": [
    "!pip install -q scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BxQ_hy7xPH3N"
   },
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PAqjR4a1RR4"
   },
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "We're going to use the Movielens 100K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-ySWtibjm_6a"
   },
   "outputs": [],
   "source": [
    "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
    "\n",
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "    #\"movie_genres\": x[\"movie_genres\"],\n",
    "    #\"bucketized_user_age\": x['bucketized_user_age'],\n",
    "    #'raw_user_age': x['raw_user_age'],\n",
    "    #'timestamp': x['timestamp'],\n",
    "    #'user_gender': x['user_gender'],\n",
    "    #'user_occupation_label': x['user_occupation_label'],\n",
    "    #'user_zip_code': x['user_zip_code']\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRHorm8W1yf3"
   },
   "source": [
    "And repeat our preparations for building vocabularies and splitting the data into a train and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rS0eDfkjnjJL"
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "#movie_genres = ratings.batch(1_000).map(lambda x: x['movie_genres'])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "#unique_movie_genres = np.unique(np.concatenate(list(movie_genres)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCi-seR86qqa"
   },
   "source": [
    "## A multi-task model\n",
    "\n",
    "There are two critical parts to multi-task recommenders:\n",
    "\n",
    "1. They optimize for two or more objectives, and so have two or more losses.\n",
    "2. They share variables between the tasks, allowing for transfer learning.\n",
    "\n",
    "In this tutorial, we will define our models as before, but instead of having  a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXHrk_SLzKCM"
   },
   "source": [
    "The user and movie models are as before:\n",
    "\n",
    "```python\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add 1 to account for the unknown token.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWCwkE5z8QBe"
   },
   "source": [
    "However, now we will have two tasks. The first is the rating task:\n",
    "\n",
    "```python\n",
    "tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrgQIXEm8UWf"
   },
   "source": [
    "Its goal is to predict the ratings as accurately as possible.\n",
    "\n",
    "The second is the retrieval task:\n",
    "\n",
    "```python\n",
    "tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128)\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCNrv7_gakmF"
   },
   "source": [
    "As before, this task's goal is to predict which movies the user will or will not watch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSWw3xuq8mGh"
   },
   "source": [
    "### Putting it together\n",
    "\n",
    "We put it all together in a model class.\n",
    "\n",
    "The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YFSkOAMgzU0K"
   },
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "    # We take the loss weights in the constructor: this allows us to instantiate\n",
    "    # several model objects with different loss weights.\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # User and movie models.\n",
    "    self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "\n",
    "    # A small model to take in user and movie embeddings and predict ratings.\n",
    "    # We can make this as complicated as we want as long as we output a scalar\n",
    "    # as our prediction.\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    # The tasks.\n",
    "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.movie_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The loss weights.\n",
    "    self.rating_weight = rating_weight\n",
    "    self.retrieval_weight = retrieval_weight\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model.\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "    # genres\n",
    "    #genre_embeddings = self.movie_model(features['move_genres'])\n",
    "    \n",
    "    return (\n",
    "        user_embeddings,\n",
    "        movie_embeddings,\n",
    "        #genre_embeddings,\n",
    "        # We apply the multi-layered rating model to a concatentation of\n",
    "        # user and movie embeddings.\n",
    "        self.rating_model(\n",
    "            tf.concat([user_embeddings, movie_embeddings,], axis=1) #genre_embeddings], axis=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    ratings = features.pop(\"user_rating\")\n",
    "\n",
    "    user_embeddings, movie_embeddings, rating_predictions = self(features)#genre_embeddings, rating_predictions = self(features)\n",
    "\n",
    "    # We compute the loss for each task.\n",
    "    rating_loss = self.rating_task(\n",
    "        labels=ratings,\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)#, genre_embeddings)\n",
    "\n",
    "    # And combine them using the loss weights.\n",
    "    return (self.rating_weight * rating_loss\n",
    "            + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngvn-c0b8lc2"
   },
   "source": [
    "### Rating-specialized model\n",
    "\n",
    "Depending on the weights we assign, the model will encode a different balance of the tasks. Let's start with a model that only considers ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NNfB6rYL0VrS"
   },
   "outputs": [],
   "source": [
    "#model = MovielensModel(rating_weight=1.0, retrieval_weight=0.0)\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I6kjfF1j0iZR"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6NWadH1q0c_T"
   },
   "outputs": [],
   "source": [
    "#model.fit(cached_train, epochs=3)\n",
    "#metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "#print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "#print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lENViv04-i0T"
   },
   "source": [
    "The model does OK on predicting ratings (with an RMSE of around 1.11), but performs poorly at predicting which movies will be watched or not: its accuracy at 100 is almost 4 times worse than a model trained solely to predict watches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPYd9LtE-4Fm"
   },
   "source": [
    "### Retrieval-specialized model\n",
    "\n",
    "Let's now try a model that focuses on retrieval only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BfnkGd2G--Qt"
   },
   "outputs": [],
   "source": [
    "#model = MovielensModel(rating_weight=0.0, retrieval_weight=1.0)\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JCCBdM7U_B11"
   },
   "outputs": [],
   "source": [
    "#model.fit(cached_train, epochs=3)\n",
    "#metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "#print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "#print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjM7j7eY_jPh"
   },
   "source": [
    "We get the opposite result: a model that does well on retrieval, but poorly on predicting ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOFwjUus_pLU"
   },
   "source": [
    "### Joint model\n",
    "\n",
    "Let's now train a model that assigns positive weights to both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "10/10 [==============================] - 6s 413ms/step - root_mean_squared_error: 3.2670 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0021 - factorized_top_k/top_10_categorical_accuracy: 0.0050 - factorized_top_k/top_50_categorical_accuracy: 0.0279 - factorized_top_k/top_100_categorical_accuracy: 0.0575 - loss: 70378.5945 - regularization_loss: 0.0000e+00 - total_loss: 70378.5945\n",
      "Epoch 2/7\n",
      "10/10 [==============================] - 4s 403ms/step - root_mean_squared_error: 1.8842 - factorized_top_k/top_1_categorical_accuracy: 1.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0055 - factorized_top_k/top_10_categorical_accuracy: 0.0120 - factorized_top_k/top_50_categorical_accuracy: 0.0532 - factorized_top_k/top_100_categorical_accuracy: 0.0986 - loss: 70359.8828 - regularization_loss: 0.0000e+00 - total_loss: 70359.8828\n",
      "Epoch 3/7\n",
      "10/10 [==============================] - 4s 400ms/step - root_mean_squared_error: 1.1534 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0126 - factorized_top_k/top_10_categorical_accuracy: 0.0271 - factorized_top_k/top_50_categorical_accuracy: 0.1099 - factorized_top_k/top_100_categorical_accuracy: 0.1823 - loss: 70333.6051 - regularization_loss: 0.0000e+00 - total_loss: 70333.6051\n",
      "Epoch 4/7\n",
      "10/10 [==============================] - 4s 400ms/step - root_mean_squared_error: 1.1195 - factorized_top_k/top_1_categorical_accuracy: 2.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0188 - factorized_top_k/top_10_categorical_accuracy: 0.0410 - factorized_top_k/top_50_categorical_accuracy: 0.1749 - factorized_top_k/top_100_categorical_accuracy: 0.2848 - loss: 70278.0355 - regularization_loss: 0.0000e+00 - total_loss: 70278.0355\n",
      "Epoch 5/7\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 1.1092 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0460 - factorized_top_k/top_50_categorical_accuracy: 0.1991 - factorized_top_k/top_100_categorical_accuracy: 0.3278 - loss: 70176.9339 - regularization_loss: 0.0000e+00 - total_loss: 70176.9339\n",
      "Epoch 6/7\n",
      "10/10 [==============================] - 4s 401ms/step - root_mean_squared_error: 1.0946 - factorized_top_k/top_1_categorical_accuracy: 4.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0221 - factorized_top_k/top_10_categorical_accuracy: 0.0475 - factorized_top_k/top_50_categorical_accuracy: 0.2029 - factorized_top_k/top_100_categorical_accuracy: 0.3344 - loss: 70031.6527 - regularization_loss: 0.0000e+00 - total_loss: 70031.6527\n",
      "Epoch 7/7\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 1.0795 - factorized_top_k/top_1_categorical_accuracy: 2.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0220 - factorized_top_k/top_10_categorical_accuracy: 0.0471 - factorized_top_k/top_50_categorical_accuracy: 0.2015 - factorized_top_k/top_100_categorical_accuracy: 0.3325 - loss: 69855.9567 - regularization_loss: 0.0000e+00 - total_loss: 69855.9567\n",
      "5/5 [==============================] - 2s 224ms/step - root_mean_squared_error: 1.0678 - factorized_top_k/top_1_categorical_accuracy: 0.0025 - factorized_top_k/top_5_categorical_accuracy: 0.0172 - factorized_top_k/top_10_categorical_accuracy: 0.0348 - factorized_top_k/top_50_categorical_accuracy: 0.1636 - factorized_top_k/top_100_categorical_accuracy: 0.2770 - loss: 32339.5671 - regularization_loss: 0.0000e+00 - total_loss: 32339.5671\n",
      "Retrieval top-100 accuracy: 0.277.\n",
      "Ranking RMSE: 1.068.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))\n",
    "adaOhOne = model.fit(cached_train, epochs=6)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "\n",
    "#************************\n",
    "\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file models already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 80: [b'Graduate, The (1967)' b'High Noon (1952)' b'Bonnie and Clyde (1967)'\n",
      " b'Manchurian Candidate, The (1962)' b'Killing Fields, The (1984)'\n",
      " b'Citizen Kane (1941)' b'Taxi Driver (1976)'\n",
      " b'Godfather: Part II, The (1974)' b'Lawrence of Arabia (1962)'\n",
      " b'Annie Hall (1977)']\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index(movies.batch(1000).map(model.movie_model), movies)\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"80\"]))\n",
    "print(f\"Recommendations for user 80: {titles[0, :]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models\\adaOhOneModel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models\\adaOhOneModel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'Home Alone (1990)' b'Mrs. Doubtfire (1993)' b'Grease (1978)'\n",
      " b'Batman (1989)' b'Sneakers (1992)' b'Santa Clause, The (1994)'\n",
      " b'Star Trek III: The Search for Spock (1984)'\n",
      " b'Star Trek VI: The Undiscovered Country (1991)'\n",
      " b'Interview with the Vampire (1994)' b'Sleepless in Seattle (1993)']\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "\n",
    "path = os.path.join('./models', \"adaOhOneModel\")\n",
    "\n",
    "# Save the index.\n",
    "index.save(path)\n",
    "\n",
    "# Load it back; can also be done in TensorFlow Serving.\n",
    "loaded = tf.keras.models.load_model(path)\n",
    "\n",
    "# Pass a user id in, get top predicted movie titles back.\n",
    "scores, titles = loaded([\"42\"])\n",
    "\n",
    "print(f\"Recommendations: {titles[0][:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>factorized_top_k/top_1_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_5_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_10_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_50_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_100_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>regularization_loss</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.267021</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.027850</td>\n",
       "      <td>0.057450</td>\n",
       "      <td>54850.222656</td>\n",
       "      <td>0</td>\n",
       "      <td>54850.222656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.884248</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>0.098587</td>\n",
       "      <td>54833.230469</td>\n",
       "      <td>0</td>\n",
       "      <td>54833.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.153432</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.109888</td>\n",
       "      <td>0.182313</td>\n",
       "      <td>54805.402344</td>\n",
       "      <td>0</td>\n",
       "      <td>54805.402344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.119536</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.018787</td>\n",
       "      <td>0.040962</td>\n",
       "      <td>0.174938</td>\n",
       "      <td>0.284775</td>\n",
       "      <td>54745.894531</td>\n",
       "      <td>0</td>\n",
       "      <td>54745.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.109152</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.199062</td>\n",
       "      <td>0.327825</td>\n",
       "      <td>54647.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>54647.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.094633</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.022112</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.202875</td>\n",
       "      <td>0.334388</td>\n",
       "      <td>54515.718750</td>\n",
       "      <td>0</td>\n",
       "      <td>54515.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.079477</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.047125</td>\n",
       "      <td>0.201525</td>\n",
       "      <td>0.332538</td>\n",
       "      <td>54364.996094</td>\n",
       "      <td>0</td>\n",
       "      <td>54364.996094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   root_mean_squared_error  factorized_top_k/top_1_categorical_accuracy  \\\n",
       "0                 3.267021                                     0.000125   \n",
       "1                 1.884248                                     0.000137   \n",
       "2                 1.153432                                     0.000250   \n",
       "3                 1.119536                                     0.000262   \n",
       "4                 1.109152                                     0.000500   \n",
       "5                 1.094633                                     0.000425   \n",
       "6                 1.079477                                     0.000262   \n",
       "\n",
       "   factorized_top_k/top_5_categorical_accuracy  \\\n",
       "0                                     0.002087   \n",
       "1                                     0.005513   \n",
       "2                                     0.012650   \n",
       "3                                     0.018787   \n",
       "4                                     0.021388   \n",
       "5                                     0.022112   \n",
       "6                                     0.022000   \n",
       "\n",
       "   factorized_top_k/top_10_categorical_accuracy  \\\n",
       "0                                      0.005013   \n",
       "1                                      0.011963   \n",
       "2                                      0.027125   \n",
       "3                                      0.040962   \n",
       "4                                      0.046012   \n",
       "5                                      0.047500   \n",
       "6                                      0.047125   \n",
       "\n",
       "   factorized_top_k/top_50_categorical_accuracy  \\\n",
       "0                                      0.027850   \n",
       "1                                      0.053213   \n",
       "2                                      0.109888   \n",
       "3                                      0.174938   \n",
       "4                                      0.199062   \n",
       "5                                      0.202875   \n",
       "6                                      0.201525   \n",
       "\n",
       "   factorized_top_k/top_100_categorical_accuracy          loss  \\\n",
       "0                                       0.057450  54850.222656   \n",
       "1                                       0.098587  54833.230469   \n",
       "2                                       0.182313  54805.402344   \n",
       "3                                       0.284775  54745.894531   \n",
       "4                                       0.327825  54647.125000   \n",
       "5                                       0.334388  54515.718750   \n",
       "6                                       0.332538  54364.996094   \n",
       "\n",
       "   regularization_loss    total_loss  \n",
       "0                    0  54850.222656  \n",
       "1                    0  54833.230469  \n",
       "2                    0  54805.402344  \n",
       "3                    0  54745.894531  \n",
       "4                    0  54647.125000  \n",
       "5                    0  54515.718750  \n",
       "6                    0  54364.996094  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaOhOne = pd.DataFrame(adaOhOne.history)\n",
    "adaOhOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "10/10 [==============================] - 5s 404ms/step - root_mean_squared_error: 3.5811 - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0023 - factorized_top_k/top_10_categorical_accuracy: 0.0054 - factorized_top_k/top_50_categorical_accuracy: 0.0290 - factorized_top_k/top_100_categorical_accuracy: 0.0580 - loss: 70380.3139 - regularization_loss: 0.0000e+00 - total_loss: 70380.3139\n",
      "Epoch 2/12\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 3.1581 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0036 - factorized_top_k/top_10_categorical_accuracy: 0.0080 - factorized_top_k/top_50_categorical_accuracy: 0.0394 - factorized_top_k/top_100_categorical_accuracy: 0.0776 - loss: 70371.9474 - regularization_loss: 0.0000e+00 - total_loss: 70371.9474\n",
      "Epoch 3/12\n",
      "10/10 [==============================] - 4s 403ms/step - root_mean_squared_error: 2.3511 - factorized_top_k/top_1_categorical_accuracy: 1.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0053 - factorized_top_k/top_10_categorical_accuracy: 0.0111 - factorized_top_k/top_50_categorical_accuracy: 0.0517 - factorized_top_k/top_100_categorical_accuracy: 0.0958 - loss: 70362.3807 - regularization_loss: 0.0000e+00 - total_loss: 70362.3807\n",
      "Epoch 4/12\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 1.3467 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0079 - factorized_top_k/top_10_categorical_accuracy: 0.0159 - factorized_top_k/top_50_categorical_accuracy: 0.0672 - factorized_top_k/top_100_categorical_accuracy: 0.1182 - loss: 70352.2741 - regularization_loss: 0.0000e+00 - total_loss: 70352.2741\n",
      "Epoch 5/12\n",
      "10/10 [==============================] - 4s 404ms/step - root_mean_squared_error: 1.2969 - factorized_top_k/top_1_categorical_accuracy: 2.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0118 - factorized_top_k/top_10_categorical_accuracy: 0.0234 - factorized_top_k/top_50_categorical_accuracy: 0.0871 - factorized_top_k/top_100_categorical_accuracy: 0.1509 - loss: 70342.6293 - regularization_loss: 0.0000e+00 - total_loss: 70342.6293\n",
      "Epoch 6/12\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 1.1171 - factorized_top_k/top_1_categorical_accuracy: 2.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0160 - factorized_top_k/top_10_categorical_accuracy: 0.0314 - factorized_top_k/top_50_categorical_accuracy: 0.1160 - factorized_top_k/top_100_categorical_accuracy: 0.1910 - loss: 70327.6662 - regularization_loss: 0.0000e+00 - total_loss: 70327.6662\n",
      "Epoch 7/12\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 1.0964 - factorized_top_k/top_1_categorical_accuracy: 4.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0199 - factorized_top_k/top_10_categorical_accuracy: 0.0399 - factorized_top_k/top_50_categorical_accuracy: 0.1470 - factorized_top_k/top_100_categorical_accuracy: 0.2357 - loss: 70304.9048 - regularization_loss: 0.0000e+00 - total_loss: 70304.9048\n",
      "Epoch 8/12\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 1.0695 - factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0233 - factorized_top_k/top_10_categorical_accuracy: 0.0458 - factorized_top_k/top_50_categorical_accuracy: 0.1732 - factorized_top_k/top_100_categorical_accuracy: 0.2760 - loss: 70269.9467 - regularization_loss: 0.0000e+00 - total_loss: 70269.9467\n",
      "Epoch 9/12\n",
      "10/10 [==============================] - 4s 406ms/step - root_mean_squared_error: 1.0627 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0243 - factorized_top_k/top_10_categorical_accuracy: 0.0490 - factorized_top_k/top_50_categorical_accuracy: 0.1921 - factorized_top_k/top_100_categorical_accuracy: 0.3073 - loss: 70218.3729 - regularization_loss: 0.0000e+00 - total_loss: 70218.3729\n",
      "Epoch 10/12\n",
      "10/10 [==============================] - 4s 406ms/step - root_mean_squared_error: 1.0484 - factorized_top_k/top_1_categorical_accuracy: 4.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0248 - factorized_top_k/top_10_categorical_accuracy: 0.0510 - factorized_top_k/top_50_categorical_accuracy: 0.2031 - factorized_top_k/top_100_categorical_accuracy: 0.3263 - loss: 70145.8878 - regularization_loss: 0.0000e+00 - total_loss: 70145.8878\n",
      "Epoch 11/12\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 1.0409 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0251 - factorized_top_k/top_10_categorical_accuracy: 0.0509 - factorized_top_k/top_50_categorical_accuracy: 0.2088 - factorized_top_k/top_100_categorical_accuracy: 0.3364 - loss: 70049.5419 - regularization_loss: 0.0000e+00 - total_loss: 70049.5419\n",
      "Epoch 12/12\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 1.0346 - factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0243 - factorized_top_k/top_10_categorical_accuracy: 0.0512 - factorized_top_k/top_50_categorical_accuracy: 0.2096 - factorized_top_k/top_100_categorical_accuracy: 0.3390 - loss: 69928.5135 - regularization_loss: 0.0000e+00 - total_loss: 69928.5135\n",
      "5/5 [==============================] - 1s 219ms/step - root_mean_squared_error: 1.0286 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0131 - factorized_top_k/top_10_categorical_accuracy: 0.0284 - factorized_top_k/top_50_categorical_accuracy: 0.1356 - factorized_top_k/top_100_categorical_accuracy: 0.2423 - loss: 32395.6595 - regularization_loss: 0.0000e+00 - total_loss: 32395.6595\n",
      "Retrieval top-100 accuracy: 0.242.\n",
      "Ranking RMSE: 1.029.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "adamOhOhOne = model.fit(cached_train, epochs=12)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "\n",
    "#*****************************\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 80: [b'Third Man, The (1949)' b'Treasure of the Sierra Madre, The (1948)'\n",
      " b'Henry V (1989)' b'Wings of Desire (1987)' b'Taxi Driver (1976)'\n",
      " b'Citizen Kane (1941)' b'Manhattan (1979)' b'Graduate, The (1967)'\n",
      " b'Crumb (1994)' b'Vertigo (1958)']\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index(movies.batch(1000).map(model.movie_model), movies)\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"80\"]))\n",
    "print(f\"Recommendations for user 80: {titles[0, :]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models\\adamOhOhOneModel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models\\adamOhOhOneModel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'Terminator, The (1984)' b'Indiana Jones and the Last Crusade (1989)'\n",
      " b'When Harry Met Sally... (1989)' b'Dave (1993)' b'Maverick (1994)'\n",
      " b'Groundhog Day (1993)' b'Grease (1978)' b'True Lies (1994)'\n",
      " b'Love Bug, The (1969)' b'Clear and Present Danger (1994)']\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "path = os.path.join('./models', \"adamOhOhOneModel\")\n",
    "\n",
    "# Save the index.\n",
    "index.save(path)\n",
    "\n",
    "# Load it back; can also be done in TensorFlow Serving.\n",
    "loaded = tf.keras.models.load_model(path)\n",
    "\n",
    "# Pass a user id in, get top predicted movie titles back.\n",
    "scores, titles = loaded([\"42\"])\n",
    "\n",
    "print(f\"Recommendations: {titles[0][:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>factorized_top_k/top_1_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_5_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_10_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_50_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_100_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>regularization_loss</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.581145</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.029012</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>54854.082031</td>\n",
       "      <td>0</td>\n",
       "      <td>54854.082031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.158076</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.039425</td>\n",
       "      <td>0.077563</td>\n",
       "      <td>54847.312500</td>\n",
       "      <td>0</td>\n",
       "      <td>54847.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.351124</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>0.051737</td>\n",
       "      <td>0.095812</td>\n",
       "      <td>54838.097656</td>\n",
       "      <td>0</td>\n",
       "      <td>54838.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.346679</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.007925</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.067225</td>\n",
       "      <td>0.118238</td>\n",
       "      <td>54830.261719</td>\n",
       "      <td>0</td>\n",
       "      <td>54830.261719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.296900</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.087125</td>\n",
       "      <td>0.150912</td>\n",
       "      <td>54821.218750</td>\n",
       "      <td>0</td>\n",
       "      <td>54821.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.117080</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.031413</td>\n",
       "      <td>0.115988</td>\n",
       "      <td>0.191038</td>\n",
       "      <td>54806.921875</td>\n",
       "      <td>0</td>\n",
       "      <td>54806.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.096422</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.019912</td>\n",
       "      <td>0.039912</td>\n",
       "      <td>0.146950</td>\n",
       "      <td>0.235738</td>\n",
       "      <td>54784.863281</td>\n",
       "      <td>0</td>\n",
       "      <td>54784.863281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.069496</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.023325</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>0.173175</td>\n",
       "      <td>0.275988</td>\n",
       "      <td>54751.308594</td>\n",
       "      <td>0</td>\n",
       "      <td>54751.308594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.062699</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.192088</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>54702.488281</td>\n",
       "      <td>0</td>\n",
       "      <td>54702.488281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.048428</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.024825</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.326275</td>\n",
       "      <td>54635.148438</td>\n",
       "      <td>0</td>\n",
       "      <td>54635.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.040878</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.050875</td>\n",
       "      <td>0.208788</td>\n",
       "      <td>0.336363</td>\n",
       "      <td>54547.441406</td>\n",
       "      <td>0</td>\n",
       "      <td>54547.441406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.034641</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.024312</td>\n",
       "      <td>0.051188</td>\n",
       "      <td>0.209587</td>\n",
       "      <td>0.338987</td>\n",
       "      <td>54439.507812</td>\n",
       "      <td>0</td>\n",
       "      <td>54439.507812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    root_mean_squared_error  factorized_top_k/top_1_categorical_accuracy  \\\n",
       "0                  3.581145                                     0.000100   \n",
       "1                  3.158076                                     0.000125   \n",
       "2                  2.351124                                     0.000150   \n",
       "3                  1.346679                                     0.000250   \n",
       "4                  1.296900                                     0.000238   \n",
       "5                  1.117080                                     0.000275   \n",
       "6                  1.096422                                     0.000438   \n",
       "7                  1.069496                                     0.000350   \n",
       "8                  1.062699                                     0.000375   \n",
       "9                  1.048428                                     0.000475   \n",
       "10                 1.040878                                     0.000500   \n",
       "11                 1.034641                                     0.000450   \n",
       "\n",
       "    factorized_top_k/top_5_categorical_accuracy  \\\n",
       "0                                      0.002325   \n",
       "1                                      0.003575   \n",
       "2                                      0.005338   \n",
       "3                                      0.007925   \n",
       "4                                      0.011775   \n",
       "5                                      0.016050   \n",
       "6                                      0.019912   \n",
       "7                                      0.023325   \n",
       "8                                      0.024250   \n",
       "9                                      0.024825   \n",
       "10                                     0.025100   \n",
       "11                                     0.024312   \n",
       "\n",
       "    factorized_top_k/top_10_categorical_accuracy  \\\n",
       "0                                       0.005350   \n",
       "1                                       0.008025   \n",
       "2                                       0.011138   \n",
       "3                                       0.015850   \n",
       "4                                       0.023375   \n",
       "5                                       0.031413   \n",
       "6                                       0.039912   \n",
       "7                                       0.045825   \n",
       "8                                       0.049000   \n",
       "9                                       0.050963   \n",
       "10                                      0.050875   \n",
       "11                                      0.051188   \n",
       "\n",
       "    factorized_top_k/top_50_categorical_accuracy  \\\n",
       "0                                       0.029012   \n",
       "1                                       0.039425   \n",
       "2                                       0.051737   \n",
       "3                                       0.067225   \n",
       "4                                       0.087125   \n",
       "5                                       0.115988   \n",
       "6                                       0.146950   \n",
       "7                                       0.173175   \n",
       "8                                       0.192088   \n",
       "9                                       0.203125   \n",
       "10                                      0.208788   \n",
       "11                                      0.209587   \n",
       "\n",
       "    factorized_top_k/top_100_categorical_accuracy          loss  \\\n",
       "0                                        0.058000  54854.082031   \n",
       "1                                        0.077563  54847.312500   \n",
       "2                                        0.095812  54838.097656   \n",
       "3                                        0.118238  54830.261719   \n",
       "4                                        0.150912  54821.218750   \n",
       "5                                        0.191038  54806.921875   \n",
       "6                                        0.235738  54784.863281   \n",
       "7                                        0.275988  54751.308594   \n",
       "8                                        0.307300  54702.488281   \n",
       "9                                        0.326275  54635.148438   \n",
       "10                                       0.336363  54547.441406   \n",
       "11                                       0.338987  54439.507812   \n",
       "\n",
       "    regularization_loss    total_loss  \n",
       "0                     0  54854.082031  \n",
       "1                     0  54847.312500  \n",
       "2                     0  54838.097656  \n",
       "3                     0  54830.261719  \n",
       "4                     0  54821.218750  \n",
       "5                     0  54806.921875  \n",
       "6                     0  54784.863281  \n",
       "7                     0  54751.308594  \n",
       "8                     0  54702.488281  \n",
       "9                     0  54635.148438  \n",
       "10                    0  54547.441406  \n",
       "11                    0  54439.507812  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adamOhOhOne = pd.DataFrame(adamOhOhOne.history)\n",
    "adamOhOhOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.057450\n",
       "1    0.098587\n",
       "2    0.182313\n",
       "3    0.284775\n",
       "4    0.327825\n",
       "5    0.334388\n",
       "6    0.332538\n",
       "Name: factorized_top_k/top_100_categorical_accuracy, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaOhOne['factorized_top_k/top_100_categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(epochs, adaOhOne[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"ada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1bbc5ff0100>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3F0lEQVR4nO3dd3xUZfb48c9JSOi9d5AioPTQFBHcVbFQLAiiwNpQd3V1XX+uu66Ku25z1d31a0FkQaSIoKIgdgUbIAQElN5NaKH3QMr5/fHcsGMYwiTM5M5Mzvv1ymvmtpnzBDJn7n3ucx5RVYwxxpj8EvwOwBhjTHSyBGGMMSYoSxDGGGOCsgRhjDEmKEsQxhhjgrIEYYwxJihLEMaYkIhIExFRESnldyymeFiCMFFHROaKyD4RKe13LMaUZJYgTFQRkSbARYAC/Yv5ve2bsTEBLEGYaDMcWAC8CowI3CAiDUXkbRHZJSJ7ROT5gG13iMgqETkkIitFpJO3XkWkecB+r4rIk97z3iKSLiK/E5EdwHgRqSoi73nvsc973iDg+GoiMl5Etnnb3/HW/yAi/QL2SxKR3SLSIX8DvTivDlgu5e3bSUTKiMgkr337RWSRiNQO9osSkXoi8pYX6yYR+XXAtlEi8qaIvOH9TpaISPuA7a29M7X9IrJCRPoHbCsrIs+IyBYROSAiX4tI2YC3vklEfvRifiRYbCY+WIIw0WY4MNn7uTzvw1FEEoH3gC1AE6A+MNXbNggY5R1bCXfmsSfE96sDVAMaAyNxfxPjveVGwDHg+YD9JwLlgPOAWsC/vPWvATcH7HclsF1VlwZ5z9eBGwOWLwd2q+oSXFKsDDQEqgN3eTH8hIgkALOAZbjfxc+A+0Xk8oDdBgDTvfZNAd7xEleSd+zHXhvuBSaLyLnecU8DnYELvGMfAnIDXrcncK73no+JSOsgbTTxQFXtx36i4gf3wZMF1PCWVwO/8Z73AHYBpYIc9xFw32leU4HmAcuvAk96z3sDJ4AyBcTUAdjnPa+L+6CsGmS/esAhoJK3/Cbw0Gles7m3bzlveTLwmPf8VmAe0O4Mv6tuwI/51v0eGO89HwUsCNiWAGzHXb67CNgBJARsf907JgGXkNoHec8m3u+zQcC6hcAQv//v2E9kfuwMwkSTEcDHqrrbW57C/y4zNQS2qGp2kOMaAhuK+J67VDUzb0FEyonIy97llYPAl0AV7wymIbBXVfflfxFV3QZ8A1wnIlWAK3Af/KdQ1fXAKqCfiJTDnfFM8TZPxCW8qd5lrKe8b/z5NQbqeZeI9ovIfuAPQODlqLSA98wF0nGJrB6Q5q3LswV3JlIDKEPBv88dAc+PAhUK2NfEMOuUM1HBu8Z9A5Do9QcAlMZ9OLfHfdg1EpFSQZJEGtDsNC99FHdJKE8d3AdlnvzljH+Lu3zSTVV3eH0I3wHivU81EamiqvuDvNcE4Hbc39V8Vd16uvbyv8tMCcBKL2mgqlnAE8ATXof9+8Aa4L/5jk8DNqlqiwLeo2HeE++SVANgW942EUkISBKNgLXAbiAT9/tcVsBrmxLAziBMtBgI5ABtcJd1OgCtga9wfQsLcZdI/i4i5b3O3Au9Y8cCD4pIZ3Gai0hjb9tSYKiIJIpIX+DiM8RREXeJZb+IVAMez9ugqtuBD4AXvc7sJBHpFXDsO0An4D5cn0RBpgKXAXfzv7MHRKSPiLT1zlgO4i655QQ5fiFw0OtgL+u173wR6RKwT2cRuVbc3Vn3A8dxNwB8CxwBHvLa0BvoB0z1EsY44FmvEzxRRHqI3XJcIlmCMNFiBO76+Y+quiPvB9dBfBPuG3w/3PX7H3FnAYMBVHU68BfcB+0h3Ad1Ne917/OO2++9zjtniOPfQFncN+kFwIf5tg/DfWivBjJwH7x4cRwD3gKaAm8X9CZespmP6wh+I2BTHVz/xUHcZagvgElBjs/x2tUB2OTFOxbXwZ3nXdzvaJ8X97WqmqWqJ3CXta7wjnsRGK6qq73jHgS+BxYBe4F/YJ8VJZKo2oRBxoSLiDwGtFTVm8+4c2TjGIXrnPc1DhPbrA/CmDDxLkndhvu2bkzMs9NGY8JARO7AdRx/oKpf+h2PMeFgl5iMMcYEFdEzCBHpKyJrRGS9iDwcZPsAEVkuIktFJFVEegZs2ywi3+dti2ScxhhjThWxMwjvNr21wKW4O04WATeq6sqAfSoAR1RVRaQdME1VW3nbNgMpAYOmzqhGjRrapEmT8DXCGGPi3OLFi3eras1g2yLZSd0VWK+qGwFEZCquNszJBKGqhwP2L8+pg5YKpUmTJqSm2smGMcaESkS2nG5bJC8x1SdgqD/uLKJ+/p1E5BoRWQ3MxtWhyaPAxyKyWERGRjBOY4wxQUQyQUiQdaecIajqDO+y0kDgzwGbLlTVTrjBPL/KN2L1f28iMtLrv0jdtWtXGMI2xhgDkU0Q6QTUguGndWBO4d0a2ExEanjL27zHDGAG7pJVsOPGqGqKqqbUrBn0MpoxxpgiiGQfxCKghYg0BbYCQ4ChgTuIm8hlg9dJ3QlIBvaISHlcKeJD3vPLgD8VJYisrCzS09PJzMw8885xpkyZMjRo0ICkpGDFQI0xpmARSxCqmi0i9+BKFycC41R1hYjc5W0fDVwHDBeRLFyBtMFesqgNzBCRvBinqGr+mjghSU9Pp2LFijRp0gTv9UoEVWXPnj2kp6fTtGlTv8MxxsSgiJbaUNX3ceWKA9eNDnj+D1whsPzHbQTa519fFJmZmSUuOQCICNWrV8f6ZYwxRVUiSm2UtOSQp6S22xgTHlaszxhjol1uLhw/AMf2w7F9kLnfPc97lAToeX/Y39YSRBR49dVXSU1N5fnnn/c7FGNMpJzpQ76gx8yDFDiOuEIdSxDGGBO1cnMhYwVs+grSF8HRPYX7kE9MhjJVoGwV91ihDtRs9dN1p3tMKhuRJlmCKAYDBw4kLS2NzMxM7rvvPkaOHMn48eP529/+Rt26dWnZsiWlS7sZHWfNmsWTTz7JiRMnqF69OpMnT6Z27dpneAcTaZlZOWzcdYS9R05QrnQi5ZNLUS45kQqlS1GudCLJiQnW51PSqMLutbDpS/ez+Ws4ttdtq9wIKtaBCrWhxrlQtmpoH/JR9n+oRCWIJ2atYOW2g2F9zTb1KvF4v/MK3GfcuHFUq1aNY8eO0aVLF6666ioef/xxFi9eTOXKlenTpw8dO3YEoGfPnixYsAARYezYsTz11FM888wzYY3ZnF5eIliXcYh1Ow+zduch1mUcZsueI+QW8OWvVIJQLjmR8qVL/fQxuRTlSpeifHIi5ZJLUb50vsfkxNNuL5uUaEknmqjCvk3uDGHTl7D5Kzi8022r1ABa9oWmF0GTi6BKw4JfK0aUqAThl+eee44ZM2YAkJaWxsSJE+nduzd5I78HDx7M2rVrATduY/DgwWzfvp0TJ07YGIYIyczKYcOuw6zP8JLAzsOnJILEBKFJ9XK0qlORfu3q0qJ2RWpWLM2xrByOHs/hyIlsjh7P5siJHI4cz+Zo4OOJbI4ez2HHwcxT1odaQFkEbu/ZlEeuahO5X4Qp2IH0nyaEA155ufK1oGkvlxCa9oKqTaPu2384lKgEcaZv+pEwd+5cPv30U+bPn0+5cuXo3bs3rVq1YtWqVUH3v/fee3nggQfo378/c+fOZdSoUcUbcJzJSwQuARxi7U6XFPIngqY1yrtE0L4eLWpVoGXtijStUZ7kUuG9E1xVyczKPZlAjpzI5uiJbI4cz/np44kcjh7PpkOjKmF9f3MGhzMCLhl9BXs3uvVlq7ozgwvvcwmhRsu4TAj5lagE4YcDBw5QtWpVypUrx+rVq1mwYAHHjh1j7ty57Nmzh0qVKjF9+nTat29/cv/69V3R2wkTJvgZekwJlgjW7TzEj3uPnkwEpRKEJgGJoGXtCrSoFZlEcDoiQtnkRMomJ0KFYnlLU5Cje13fwWbvLGHXare+dCVofCF0ud0lhFrnQUKJGDb2E5YgIqxv376MHj2adu3ace6559K9e3fq1q3LqFGj6NGjB3Xr1qVTp07k5OQAMGrUKAYNGkT9+vXp3r07mzZt8rkF0St931H+9v5qVmw7EDQRtKlXif4d6tOytjsjaFK9+BKBiVKZB2HLPC8hfAE7fgAUkspBo+7QfohLCHXaQ6J9PMbVnNQpKSmaf8KgVatW0bp1a58i8l+8tn/34eMMGj2f3YeOc1HLGrSoVZEWlghMMEf2wKKxsO4j2LYUNAcSS0PDri4ZNLkI6neGUsl+R+oLEVmsqinBtlmKNDHnUGYWvxi/kO0HjjH59m50blzN75BMNDq4HeY/D6njIOsoNOgKFz3gEkLDrhEbOxBPLEGYmHI8O4c7Jy5m1fZDjB2eYsnBnGrfFvjm3/DdJMjNgbbXQ88HoFYrvyOLOZYgTMzIyVXun7qUeRv28K/B7enTqpbfIZlosnsdfPUsLH/D1SbqMNSVn6h2jt+RxSxLECYmqCqPvvsDH/ywg0evbsM1HRv4HZKJFtuXw1fPwMp3oVQZ6DoSLrgXKtf3O7KYZwnCxIR/fbKWKd/+yC97N+O2njZ40ABpi+Crp2Hth5Bc0Z0tdP8VVLCph8PFEoSJeuO/2cRzn69nSJeG/L/Lz/U7HOMnVXeL6pf/dOMWylaFPo9A1zvccxNWliCigJX7Pr13l27liVkrufy82jw58HyrTVRSqcK6j+HLpyF9oSuCd+mfIeVWKG0jDiPFEoSJWnPXZPDbacvo1rQa/xnSkVKJNrahxMnNhVUz3aWkHd9D5YZw5dPQcRgklfE7urhnCaIYhKPc96hRo9i0aRPbt29n7dq1PPvssyxYsIAPPviA+vXrM2vWLJKSknxuafgs+XEfd09aQsvaFXllRAplkhL9DskUp5ws+P5N+PpZV1K7WjMY8AK0GwyJ8fP/PNqVrATxwcPuW0g41WkLV/y9wF3CVe57w4YNzJkzh5UrV9KjRw/eeustnnrqKa655hpmz57NwIEDw9s2n6zbeYhbX11ErUqlmXBrVyqVsQ+EEiP7OCydDF//G/ZvcTWQrh8HbQZCgn1JKG4lK0H4JFzlvq+44gqSkpJo27YtOTk59O3bF4C2bduyefPm4m1UhGzdf4zh4xaSlJjAxFu7UbNiab9DMsXhxBFY/CrM+z84tN2Vvuj7dzfHQgkskhctSlaCOMM3/UgIZ7nvvMtQCQkJJCUlneywTUhIIDs7O+JtibS9R04w7L/fcvh4NtPu7EGj6uX8DslEWuYBWPgKLHjRTdHZuCcMfAnO6V0iymlHu5KVIHxg5b5Dc+R4NreMX8jWfceYeFs3Wtet5HdIJpKO7YP5L8C3Y+D4AWh+KfR60FVUNVHDEkSEWbnvMzuRnctdkxbzw7aDvHxzZ7o2tfpKcW3bUnhjGBz4EVr3g4t+C/U6+h2VCcLKfce5aG9/Tq5y39TveG/5dp4e1J7rO1sJjbi2bCrMug/K1YAbXoMGnf2OqMQrqNx3RHt/RKSviKwRkfUi8nCQ7QNEZLmILBWRVBHpGeqxJvapKk/MWsF7y7fzhytbWXKIZzlZ8MHvYMad0KALjJxrySEGROwSk4gkAi8AlwLpwCIRmamqKwN2+wyYqaoqIu2AaUCrEI81Me65z9bz2vwt3NnrHEb2auZ3OCZSDmfA9F/Alm9craRL/2SztcWISP4rdQXWq+pGABGZCgwATn7Iq+rhgP3LAxrqsYWhqiWyREM0Xz6cuGAL//p0LYM6N+DhK6xOf9xKT3X9Dcf2wbVjod0gvyMyhRDJS0z1gbSA5XRv3U+IyDUishqYDdxamGNDUaZMGfbs2RPVH5aRoKrs2bOHMmWirxzBe8u38di7P/Dz1rX527VtS2TyLhEWT4DxV7iRz7d/YskhBkXyDCLYX/0pn9KqOgOYISK9gD8DPw/1WAARGQmMBGjUqNEp2xs0aEB6ejq7du0KPfI4UaZMGRo0iK7r+l+v281v3lhKl8bVeH6o1VeKS9nH4YOH3MC3ZpfAdf+FcnZnWiyKZIJIBxoGLDcAtp1uZ1X9UkSaiUiNwhyrqmOAMeDuYsq/PSkp6SejkY1/lqXtZ+TEVJrVrGD1leLVwW0wbTikL4Kev4FLHrUSGTEskgliEdBCRJoCW4EhwNDAHUSkObDB66TuBCQDe4D9ZzrWxJb1GYf5xfiFVK+QzGu3dqVyWauvFHe2zHfJ4cQRdwtrmwF+R2TOUsQShKpmi8g9wEdAIjBOVVeIyF3e9tHAdcBwEckCjgGD1XUWBD02UrGayNp+4Bgjxi0kMcHVV6pVKfr6RcxZUIVFY+HDh6FKYxgxE2pF79gbE7q4Hyhn/LXvyAlueHk+Ow5k8vrI7pxfv7LfIZlwyjoG7z0Ay6a4wnrXvAxlq/gdlSmEggbK2c3IJmKOnsjm1gmL2LL3KBNu6WrJId7sT4M3bobtS+Hih+Hi31nl1ThjCcJERFZOLndPWsKytP28dHNnejSr7ndIJpw2fgFv3uJGSN84Fc69wu+ITARYujdhl5urPDh9GV+s3cXfrm3L5efV8TskEy6qMO95mDjQ1VO6Y44lhzhmZxAmrFSVP723kneXbuOhvucyuMupY1NMjDpxBGbeCz+85aqwDnwJSlf0OyoTQZYgTFi9OHcDr87bzG09m3L3xVZfKW7s3eT6G3augJ89Bj0fsAl9SgBLECZsMg5m8uwna7m6XV0eubK1ldCIF+s+hbduc89vfhOa/9zfeEyxsQRhwuatJVvJyVUeuLQlCQmWHGKeKnz1DHz+JNQ+DwZPgmpWlaAksQRhwkJVmZ6aRtcm1TinZgW/wzFn6/gheOduWDULzr8e+j8HyeX9jsoUM0sQJixSt+xj4+4j3N3b+h1i3u51MPUm2LMeLv8rdP+l9TeUUJYgTFhMW5RG+eRErmpX1+9QzNlY/b6b9S0xCYa/A017+R2R8ZElCHPWDh/PZvb32+nfvh7lku2/VEzKzYUv/gFf/B3qdnD9DVUanvEwE9/sr9mctdnLt3H0RA43dLEPlJikCrMfgMXjocNNcNUzkFTW76hMFLAEYc7atNR0mteqQMeGVfwOxRSWqje5z3g3f8PPHrf+BnOSldowZ2V9xiEWb9nH4JSGNu4h1qjCR4/AwjHQ4x5LDuYUliDMWZmemk6pBGFgxyJNGW78ogqfPg4LXoBud8NlT1pyMKewBGGKLCsnl7eWpHNJq1rUrFja73BMYcz5C3zzH0i5Dfr+zZKDCcoShCmyOasz2H34BIOtczq2zP0HfPlP6DQcrnzakoM5LUsQpsimpaZRq2JpLm5Z0+9QTKi+egbm/tXdrXT1f2yCH1Mg+99hiiTjYCZz1uzius4NKJVo/41iwjfPwWd/grY3QP//s+Rgzsj+h5giySvMN6hzA79DMaFY8BJ88iicd62bxyEh0e+ITAywBGEKzQrzxZiFr8CHD7tJfq4dA4k2/MmExhKEKbS8wnyDUuzsIeotfhXefxBaXgHXjXM1lowJkSUIU2hWmC9GfDcZZt0PzS+FGyZAqWS/IzIxxhKEKZS8wnz9rDBfdFv2Brz7Kzintyu8V8rGqZjCO2OCEJFqxRGIiQ1WmC8G/PAWvHMXNOkJQ6ZAUhm/IzIxKpQziG9FZLqIXClWbKfEs8J8UW7lu/DWHdCwOwx9A5LL+R2RiWGhJIiWwBhgGLBeRP4qIi0jG5aJRlaYL8qtfh/evBUapMBN02yKUHPWzpgg1PlEVW8EbgdGAAtF5AsR6VHQsSLSV0TWiMh6EXk4yPabRGS59zNPRNoHbNssIt+LyFIRSS1C20yYWWG+KLb2Y5g2HOq2h5umQ+mKfkdk4sAZexlFpDpwM+4MYidwLzAT6ABMB5qe5rhE4AXgUiAdWCQiM1V1ZcBum4CLVXWfiFyBO1PpFrC9j6ruLmyjTPhZYb4otv4zeONmqN0Gbn4bylT2OyITJ0K5DWU+MBEYqKrpAetTRWR0Acd1Bdar6kYAEZkKDABOJghVnRew/wLAbqyPUlaYL0pt/AKmDoUaLWHYO1C2it8RmTgSSoI4V1U12AZV/UcBx9UH0gKW0/np2UF+twEfBL488LGIKPCyqo4JdpCIjARGAjRq1KiAlzdnwwrzRaHN38DrQ6DaOTD8XShnNxya8Aqlk/pjEamStyAiVUXkoxCOC9aLGTTRiEgfXIL4XcDqC1W1E3AF8CsR6RXsWFUdo6opqppSs6Z9eEWCFeaLQj8ugMmDoHIDlxzKV/c7IhOHQvlrr6mq+/MWVHUfUCuE49KBwOsRDYBt+XcSkXbAWGCAqu4JeJ9t3mMGMAN3ycr4wArzRZn0VJh0PVSqCyNmQYVQ/hyNKbxQEkSOiJy8diMijTnNmUA+i4AWItJURJKBIbjO7ZO8130bGKaqawPWlxeRinnPgcuAH0J4TxNmVpgvymxdAhOvhfI1XHKoWMfviEwcC6UP4hHgaxH5wlvuhXfNvyCqmi0i9wAfAYnAOFVdISJ3edtHA48B1YEXvfvqs1U1BagNzPDWlQKmqOqHhWqZCYu8wnx3927mdyhm+3KYeA2UreySQ6V6fkdk4twZE4SqfiginYDuuH6F34R666mqvg+8n2/d6IDnt+PGVuQ/biPQPv96U/ysMF+U2LkCXhsAyRVccqhid5OZyAu12loOkAGUAdqICKr6ZeTCMtEgrzBffyvM56+M1TChvyu4N2ImVG3id0SmhAhloNztwH24TualuDOJ+cAlEY3M+M4K80WB3evgtf5uBrgR70F1u9Rnik8ondT3AV2ALaraB+gI7IpoVCYqWGE+n+3ZABP6QW6Ou6xUo7nfEZkSJpQEkamqmQAiUlpVVwPnRjYs4zcrzOezg9tdn0P2cZccatqfnCl+oVxYTvcGyr0DfCIi+wgynsHEFyvM56PMg24Q3LF98IvZrsaSMT4I5S6ma7yno0RkDlAZsFtO45gV5vNR9gmYNgwyVrqS3fU6+B2RKcEKTBAikgAsV9XzAVT1i4L2N/HBCvP5RBVm/Ro2zoUBL0Dzn/sdkSnhCuyDUNVcYFngSGoT/6wwn0/m/BWWvQ69/wAdb/Y7GmNC6oOoC6wQkYXAkbyVqto/YlEZ3+QV5hvZ6xwrzFecFr8KXz4FHYfBxQ/5HY0xQGgJ4omIR2GihhXm88Haj+G9B9wlpav/BXbXmIkSoXRSW79DCWGF+XywdQlMHwF1zodBEyAxye+IjDnpjNcQROSQiBz0fjJFJEdEDhZHcKZ45RXmG5RiZw/FYu8mmHKDq8w6dDqUtqRsoksoZxA/mf1cRAZiczPEJSvMV4yO7oXJ10NOFvzifahY2++IjDlFoXshVfUdrA5T3MkrzNfPCvNFXtYxN1Xo/jS4cSrUbOl3RMYEFUqxvmsDFhOAFEKbMMjEECvMV0xyc+DtOyBtIQx6FRr38DsiY04rlK+K/QKeZwObgQERicb4xgrzFQNV+OgPsGoWXP5XOG+g3xEZU6BQ+iBuKY5AjH/yCvM9cmVrK8wXSfNfgG9HQ/dfQo9f+R2NMWcUyl1ME7xifXnLVUVkXESjMsXKCvMVgx/eho8fgTYD4LK/+B2NMSEJpZO6naruz1tQ1X24OSFMHLDCfMVg8zcw405o1AOuGQMJNkLdxIZQ/qcmiEjVvAURqUboU5WaKGeF+SIsYzVMvRGqNIYhUyCpjN8RGROyUD7onwHmicibuLuXbgDsHDlOWGG+CDq0w411SCwNN78J5ar5HZExhRJKJ/VrIpKKG/sgwLWqujLikZmIs8J8EXT8kJv05+heuGU2VG3id0TGFFoo4yC6AytU9XlvuaKIdFPVbyMenYkoK8wXITlZMG0E7FwBQ9+AetZlZ2JTKF8bXwIOBywf8daZGGaF+SJEFWbdDxs+c5VZW1zqd0TGFFkoCUJU9eTIaW8SIeukjnFWmC9C5v4dlk6Ci38HnUf4HY0xZyWUBLFRRH4tIknez33AxkgHZiLLCvNFwJKJ8MXfocNN0Pv3fkdjzFkLJUHcBVwAbAXSgW7AyFBeXET6isgaEVkvIg8H2X6TiCz3fuaJSPtQjzVFZ4X5ImDdpzDrPjinD/T7j036Y+JCKHcxZQBDCvvCIpIIvABcikssi0RkZr47oDYBF6vqPhG5AhgDdAvxWFNEVpgvzLYthWnDoXYbuOE1m/THxI1Q7mIqA9wGnAecHOWjqree4dCuwHpV3ei9zlRckb+TH/KqOi9g/wVAg1CPNUX3xqI0K8wXLvu2uNtZy1Vzk/6UqeR3RMaETSiXmCYCdYDLgS9wH+KHQjiuPpAWsJzurTud24APCnusiIwUkVQRSd21a1cIYZVs6zMOseTH/QxOaWiF+c7WyUl/jsNN06GS9eeY+BJKgmiuqo8CR1R1AnAV0DaE44J9+gSdR0JE+uASxO8Ke6yqjlHVFFVNqVnTRgOfiRXmC5OsTJg6FPZtdiU0arX2OyJjwi6UBJHlPe4XkfOBykCTEI5LBwIvcjcAtuXfSUTaAWOBAaq6pzDHmsKxwnxhkpvriu/9OB+uGQ1NevodkTEREUqCGOMV6/sjMBPXD/CPEI5bBLQQkaYikozr6J4ZuIOINALeBoap6trCHGsKzwrzhcknj8LKd+DSP8P51/kdjTERE8pdTGO9p18C54T6wqqaLSL3AB8BicA4VV0hInd520cDjwHVgRe96+HZ3uWioMcWol0mCCvMFwbzX4T5z0PXO+GCe/2OxpiIiuhN8Kr6PvB+vnWjA57fDtwe6rGm6KwwXxismOGmDG11NfT9m411MHHPPilKCCvMd5ZWz4a3boeG3eC6sZCQ6HdExkScJYgSwArznaU1H7rqrHXbu9tZk8r6HZExxaLAS0wiUhnoixuDoLg7iT4KnILURL+8wnx3927mdyixZ92nMG0Y1D4Pbn7bBsKZEuW0ZxAiMhxYAvQGygHlgT7AYm+biRFWmK+INnzuxjrUPBeGzYCyVfyOyJhiVdAZxCNA5/xnC94tr98Cr0UwLhMmeYX5+lthvsLZ+AW8fiPUaAHDZ9p0oaZEKqgPQgg+ejmX4COdTRSywnxFsPkbeH0IVG0Kw9+15GBKrIK+Uv4FWCIiH/O/ukiNcBVW/xzpwMzZU1XGf7OZlrWtMF/Iflzgiu9VbgAjZkL5Gn5HZIxvTnsG4dVdSsEV6DsOnADmAimq+mpxBGfOztw1u1i94xB39mpmhflCkbYIJl3niu6NmAUVavkdkTG+KvCitKruA6aKSDW3qPuKJywTDi/OXU/9KmXp36Ge36FEv62LYdK1UL6mSw4V6/gdkTG+K+gupkYiMlVEMnCd0otEJMNb16TYIjRFsmjzXhZt3scdFzUlyUZOF2zbUph4DZStCr94DypZQjUGCu6kfgOYAdRV1Raq2hyoC7wDTC2G2MxZeGnuBqqVT2Zwl0Z+hxLddnwPrw2A0pXcmUNlG2luTJ6CEkQNVX1DVXPyVqhqjqpOxRXYM1Fq1faDfL46g1suaELZZCsJcVo7V8CE/pBc3iWHqo39jsiYqFJQH8RiEXkRmMD/7mJqCIwAvot0YKboRn+xgfLJiQzv0cTvUKJXxmqXHEqVdsmhWlO/IzIm6hSUIIbjZnl7AldqQ3CJYhbw38iHZorixz1HmbVsG7dfdA6VyyX5HU502rUWJvRzBfdGzILqVoLEmGBOmyBU9QTwkvdjYsSYrzZQKiGB23raN+Kg9mxwyQGF4bPcSGljTFBFur1FRB4LdyDm7O06dJxpqelc17k+tSuV8Tuc6LN3k0sOuVmufEatVn5HZExUK+r9j0En+TH+GvfNJrJychnZyy6ZnGLfFpccso668hm12/gdkTFR77SXmETk4Ok2AVYQP8oczMxi0vwtXHl+XZrWKO93ONFlfxpMuBqOH3RnDnXa+h2RMTGhoE7q/UAXVd2Zf4OIpJ26u/HTpAVbOHQ82+Z8yO/AVnfmcGw/DH8H6nXwOSBjYkdBl5heA053Y/iUCMRiiigzK4dxX2/mohY1OL9+Zb/DiR4Ht7vkcGS3m+ynfme/IzImphR0F9MfC9j2u8iEY4pi+uJ0dh8+zi97d/Q7lOhxOANe6w+HdsCwt6FhF78jMibmFKqTWkRGRSgOU0TZObmM+XIDHRpWofs5Nm8BAId3uTOHA+luDulG3f2OyJiYVNi7mPpHJApTZLO/307a3mP8sreV9AbgyB5XW2nfFhj6BjS50O+IjIlZhZ2D0j6Booiq8tLcDbSoVYGft67tdzj+O7oXJg6AvRvgxqnQtJffERkT0wp7BtEpIlGYIpmzJoPVOw5x18XNSEgo4bn72H5XsnvXGhgyGZr18TsiY2LeGROEiJwjIrNEZDewU0TeFZFziiE2cwYvzd1gEwIBZB5wk/3sXAGDJ0Hzn/sdkTFxIZQziCnANKAOUA+YDrweyouLSF8RWSMi60Xk4SDbW4nIfBE5LiIP5tu2WUS+F5GlIpIayvuVJDYhkOf4IZh0PWxfBjdMgJaX+x2RMXEjlE8WUdWJqprt/UwC9IwHiSQCLwBXAG2AG0Ukf32DvcCvgadP8zJ9VLWDqqaEEGeJYhMCAZkHYfIgN13o9eOg1VV+R2RMXAklQcwRkYdFpImINBaRh4DZIlLNm6v6dLoC61V1o1cZdiowIHAHVc1Q1UVAVpFbUALZhEC4wnv/vQzSFsJ1r0CbAWc+xhhTKKHcxTTYe7wz3/pbcWcSp+uPqM//JhoCSAe6FSI2BT4WEQVeVtUxwXYSkZHASIBGjUrGt+kSPyHQ5q/hjWGguW4Q3Dm9/Y7ImLh0xgShqkWdWCDYbTVnvDQV4EJV3SYitYBPRGS1qn4ZJL4xwBiAlJSUwrx+TCrxEwItfhVm/xaqNnXjHGyyH2Mi5owJQkSSgLuBvJvK5+K+0Z/pslA6borSPA2AbaEGpqrbvMcMEZmBu2R1SoIoaUrshEA52fDxH+Hbl6DZz1yfQ9kqfkdlTFwLpQ/iJaAz8KL305nQZplbBLQQkaYikgwMAWaGEpSIlBeRinnPgcuAH0I5Np5lHMosmRMCHdsPUwa55ND9lzB0miUHY4pBQfNBlFLVbFzJ7/YBmz4XkWVnemFVzRaRe4CPgERgnKquEJG7vO2jRaQOkApUAnJF5H7cHU81gBle6YhSwBRV/bBILYwj47/ZTHZJmxBozwaYMhj2bYZ+z0HnEX5HZEyJUdAlpoW4kdM5ItJMVTeAGzgH5ITy4qr6PvB+vnWjA57vwF16yu8g0D7I+hIrb0KgK9qWoAmBNsyB6b+AhEQ3C5zVVTKmWBWUIPI6mR/E3eq60VtuAtwSyaDMqU5OCHRxCTl7WPgKfPA7qHku3Pg6VG3id0TGlDgFJYiaIvKA9/xl3GWiI0AZoCMwJ8KxGY+bEGgTvVrWjP8JgXKyXGJI/S+0vMKNcShd0e+ojCmRCkoQiUAFfnq7agXv0f5ii5GbEOhE/J89HN0L04bD5q/gwvvhZ4+5y0vGGF8UlCC2q+qfii0SE1TehEAdG8X5hEC71rjO6INb4ZqXof0QvyMypsQLpQ/C+ChvQqBHr2oTvxMCrfsE3rwVSpWGX8yGhl39jsgYQ8HjIH5WbFGYoOJ+QiBVmP8CTLkBqjaGO+ZYcjAmipz2DEJV9xZnIOZUeRMCPTOoffxNCJR9AmY/AN9NhNb93GWl5BJy+64xMaKwU46aYvTinDidEOjIblds78d50Osh6P17SCjBc1oYE6UsQUSpRZv3krplH6P6tYmvCYF2roApQ+BIhqundP51fkdkjDkNSxBR6sU56+NvQqDV78Pbd0ByBbjlfajf2e+IjDEFiKOvpvFj1faDzFmzK34mBFKFr/8FU4dCjRYwco4lB2NigJ1BRKGX5sbRhEBZmTDr17D8DXc5acALkFTW76iMMSGwBBFlftxzlPeWx8mEQId2urOGranQ54/Q60GI17EcxsQhSxBR5uUv42RCoO3L4PUb4dg+uGEitOnvd0TGmEKyBBFFMg5lMn1xHEwItPJdmHEXlK0Gt34Eddv5HZExpggsQUSRcV+7CYHujNUJgbKPw5dPw5dPQYOuMGQyVKjld1TGmCKyBBElDmZmMXmBmxCoSaxNCKQKq2bBJ4+6md/aD4V+/3a1lYwxMcsSRJSYOD9GJwTavgw+/ANs+RpqtYFhM6DZJX5HZYwJA0sQUSAzK4fx38TYhECHdsDnf4bvJkO5anDVs9BpBCTafylj4oX9NUeB6alp7D58gl/2joGzh6xjrgLr1/9yfQ4X3AMXPQhlq/gdmTEmzCxB+Cw7J5eXv9xIx0ZV6NY0iicEUoUVM+CTx+HAj9Dqarj0T1A9BpKaMaZILEH47L3l20nfd4zH+50XvRMCbV0CH/4e0hZA7bYwcBY07eV3VMaYCLME4aPACYF+1ioKbwc9uA0++xMsex3K14T+/wcdbrJ5oo0pISxB+Ojz1Rms2XmIZ2+IsgmBThyFef8H3/wbcrOh52+g5wNQppLfkRljipElCB+9NNdNCNSvfZRMCJSbCz+8CZ+OgoNboc1AuPQJqNrE58CMMX6wBOGThZvchEBP9D8vOiYESlsEHz7sCuvVbQ/XjYXGF/gdlTHGRxH9ZBKRviKyRkTWi8jDQba3EpH5InJcRB4szLGx7qW566lePpkbUhr6G8j+NHjzNvjvz+FAOgx8Ce6Ya8nBGBO5MwgRSQReAC4F0oFFIjJTVVcG7LYX+DUwsAjHxqyV29yEQA9e1tK/CYGOH4Zv/gPznnPLvf4fXHg/lK7gTzzGmKgTyUtMXYH1qroRQESmAgOAkx/yqpoBZIjIVYU9NpaN/sJNCDSse5Pif/PcXFg+FT59Ag7vgPOvh5+Pgio+n8kYY6JOJBNEfSAtYDkd6BbuY0VkJDASoFGj6J+/ec2OQ7y3fBt3+DEh0Jb5rp9h+1I35ecNr0GjUP9JjDElTSQTRLD7NjXcx6rqGGAMQEpKSqiv74ste44wfNy3VCtfmtsuKsYJgfZtdiOgV74DFevBta+4M4eEKOgcN8ZErUgmiHQg8LpFA2BbMRwblbbtP8bQV77lRHYuU0f2oFbFYpgQaH8aLHgRFv3XDW7r/Xu44F5IjrFy4sYYX0QyQSwCWohIU2ArMAQYWgzHRp2MQ5ncNPZbDh7LYsod3Tm3TsXIvuHOla4D+oc3XQ2ldoPhkj9C5fqRfV9jTFyJWIJQ1WwRuQf4CEgExqnqChG5y9s+WkTqAKlAJSBXRO4H2qjqwWDHRirWSNp75AQ3j/2WnQczmXhbV9o2iFA5b1XYMs8lhnUfQVI56HIH9PglVIn+vhljTPQR1ai+bF8oKSkpmpqa6ncYJx04lsVNYxewbudhxv+iCxc0rxH+N8nNhTWzXWJIXwTlqkO3u6DL7W6eBmOMKYCILFbVlGDbbCR1hBw5ns0t4xeyZschxgxPCX9yyD4Oy6a6cQx71kOVxnDl066YXnK58L6XMaZEsgQRAZlZOdw+IZVl6Qd4YWhH+pwbxkqtmQcgdRwseAkO74Q67eD6cdB6gM3mZowJK/tECbPj2TncNWkxCzbt4V83dKDv+XXD88IHt7s7klLHw4lDcE5vuOZl9xit80gYY2KaJYgwys7J5b7XlzJ3zS7+dm1bBnYMw11Du9bCvP/AsjdAc1yF1Qvvg3odzv61jTGmAJYgwiQnV3lw+jI+XLGDx65uw41dz/LOobSFruN59WwoVRo6j4Ae90C1YhxgZ4wp0SxBhIGq8siM73ln6Tb+3+XncmvPIn6I5+bCuo9dYvhxHpSp4orodR0JFWqGNWZjjDkTSxBnSVV5YtZKpi5K454+zflVn+aFf5HsE25Q2zfPwa5VUKkB9P07dBxm1VWNMb6xBHGW/vnRGl6dt5lbL2zKby9rWbiDjx+CxRNc5/PBrVDrPLhmDJx/LSQWcyE/Y4zJxxLEWXj+83W8OHcDQ7s14tGrWyOh3k10OAO+HQ2LxrrbVhv3hKv/DS0utTuSjDFRwxJEEY39aiNPf7yWazvW58kB54eWHA5ug6//DUsmuIFura92k/Q0CDqI0RhjfGUJoggmf7uFJ2ev4sq2dXjq+nYkJJwhORzYCl//yyWG3BxofyP0vB9qtCiWeI0xpigsQRTS20vS+eM7P3BJq1r8e3BHSiUWMKfCgXT46ln4biJoLnQYChf9Fqo2KbZ4jTGmqCxBFML732/nwenLuKBZdV68qRPJpU6THPb/6CWGSW65403Q8wGo2rj4gjXGmLNkCSJEn6/eya9f/45OjaryyvAUyiQlnrrTvi3w9bPw3WS33GkY9PyNlds2xsQkSxAh+Hrdbu6atIQ29Sox7pYulEvO92vbtxm+egaWTgFJcKOee/4GKjfwJV5jjAkHSxBnsGjzXu54LZWm1csz4ZauVCoTMD5h7yb46mlXdlsSoPMtXmKwmduMMbHPEkQBlqfv55bxi6hbuQyTbu9G1fLJbsOeDe6MYdlUSCgFKbe5u5Iq1fM1XmOMCSdLEKexesdBho9bSNXySUy+oxs1K5Z2ieHLf8LyaW6kc9eRrrJqpTCV9DbGmChiCSKIDbsOc/PYbylTKpEpt3enbtZWePuf8P00SCztpvS88NdQsY7foRpjTMRYgsgnbe9RbnrlWwCmXV+dhnPuc4X0EktD91+6M4YKYZwhzhhjopQliADbDxzjxlcWUOfEFiY0n0vlKTMhqaybh+GCX1vJbWNMiWIJwrPr0HEeGT2dR46+Tl+Zj2wp584WLrgXytfwOzxjjCl2liCAA5uXsWry7xl7Yh6aVA7p/ht31lC+ut+hGWOMb0p8gji0fw+lX72UTprA1rZ30fDKh6BcNb/DMsYY35X4BFGmYlXGNXiC1l0uoVf7c/0OxxhjokaJTxBJiQncefvdfodhjDFRp4Ba1WdPRPqKyBoRWS8iDwfZLiLynLd9uYh0Cti2WUS+F5GlIpIayTiNMcacKmJnECKSCLwAXAqkA4tEZKaqrgzY7QqghffTDXjJe8zTR1V3RypGY4wxpxfJM4iuwHpV3aiqJ4CpwIB8+wwAXlNnAVBFRKxuhTHGRIFIJoj6QFrAcrq3LtR9FPhYRBaLyMjTvYmIjBSRVBFJ3bVrVxjCNsYYA5FNEMEmatZC7HOhqnbCXYb6lYj0CvYmqjpGVVNUNaVmTRvpbIwx4RLJBJEONAxYbgBsC3UfVc17zABm4C5ZGWOMKSaRTBCLgBYi0lREkoEhwMx8+8wEhnt3M3UHDqjqdhEpLyIVAUSkPHAZ8EMEYzXGGJNPxO5iUtVsEbkH+AhIBMap6goRucvbPhp4H7gSWA8cBW7xDq8NzBCRvBinqOqHkYrVGGPMqUQ1f7dA7BKRXcAWv+MIQQ0gnm/fjef2WdtiVzy372za1lhVg3bgxlWCiBUikqqqKX7HESnx3D5rW+yK5/ZFqm0RHUltjDEmdlmCMMYYE5QlCH+M8TuACIvn9lnbYlc8ty8ibbM+CGOMMUHZGYQxxpigLEEYY4wJyhJEhInIOBHJEJEfAtZVE5FPRGSd91jVzxiLSkQaisgcEVklIitE5D5vfcy3T0TKiMhCEVnmte0Jb33Mty2QiCSKyHci8p63HBftCzafTLy0DUBEqojImyKy2vv76xGJ9lmCiLxXgb751j0MfKaqLYDPvOVYlA38VlVbA91xRRXbEB/tOw5coqrtgQ5AX68cTDy0LdB9wKqA5XhqXx9V7RAwPiCe2vYf4ENVbQW0x/0bhr99qmo/Ef4BmgA/BCyvAep6z+sCa/yOMUztfBc3QVRctQ8oByzBTWYVN23DFcf8DLgEeM9bFxftAzYDNfKti5e2VQI24d1kFMn22RmEP2qr6nYA77GWz/GcNRFpAnQEviVO2uddflkKZACfqGrctM3zb+AhIDdgXby0L9h8MvHStnOAXcB47/LgWK+oadjbZwnCnDURqQC8Bdyvqgf9jidcVDVHVTvgvml3FZHzfQ4pbETkaiBDVRf7HUuEhDSfTIwqBXQCXlLVjsARInS5zBKEP3bmTa3qPWb4HE+RiUgSLjlMVtW3vdVx0z4AVd0PzMX1JcVL2y4E+ovIZtx0wJeIyCTipH0afD6ZuGgbbh6ddO+MFuBNXMIIe/ssQfhjJjDCez4Cd+0+5oirx/5fYJWqPhuwKebbJyI1RaSK97ws8HNgNXHQNgBV/b2qNlDVJri5Wj5X1ZuJg/YVMJ9MzLcNQFV3AGkicq636mfASiLQPhtJHWEi8jrQG1eOdyfwOPAOMA1oBPwIDFLVvT6FWGQi0hP4Cvie/13H/gOuHyKm2yci7YAJuLlMEoBpqvonEalOjLctPxHpDTyoqlfHQ/tE5BzcWQP8bz6Zv8RD2/KISAdgLJAMbMTNpZNAmNtnCcIYY0xQdonJGGNMUJYgjDHGBGUJwhhjTFCWIIwxxgRlCcIYY0xQliCMiQIi0juvoqox0cIShDHGmKAsQRhTCCJyszdPxFIRedkr6HdYRJ4RkSUi8pmI1PT27SAiC0RkuYjMyKvPLyLNReRTb66JJSLSzHv5CgE1/id7I9WN8Y0lCGNCJCKtgcG4QnAdgBzgJqA8sMQrDvcFbrQ8wGvA71S1HW60ed76ycAL6uaauADY7q3vCNwPtMFV7Lwwwk0ypkCl/A7AmBjyM6AzsMj7cl8WVxAtF3jD22cS8LaIVAaqqOoX3voJwHSvRlB9VZ0BoKqZAN7rLVTVdG95KW4eka8j3ipjTsMShDGhE2CCqv7+JytFHs23X0H1awq6bHQ84HkO9vdpfGaXmIwJ3WfA9SJSC07OcdwY93d0vbfPUOBrVT0A7BORi7z1w4AvvPky0kVkoPcapUWkXHE2wphQ2TcUY0KkqitF5I+4mcoSgCzgV7gJW84TkcXAAVw/BbiSy6O9BJBXcRNcsnhZRP7kvcagYmyGMSGzaq7GnCUROayqFfyOw5hws0tMxhhjgrIzCGOMMUHZGYQxxpigLEEYY4wJyhKEMcaYoCxBGGOMCcoShDHGmKD+PwIyxJoK721VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_validation_runsAda = len(adaOhOne[\"factorized_top_k/top_100_categorical_accuracy\"])\n",
    "epochsAda = [(x + 1)* 5 for x in range(num_validation_runsAda)]\n",
    "num_validation_runsAdam = len(adamOhOhOne[\"factorized_top_k/top_100_categorical_accuracy\"])\n",
    "epochsAdam = [(x + 1)* 5 for x in range(num_validation_runsAdam)]\n",
    "\n",
    "plt.plot(epochsAda, adaOhOne[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"ada\")\n",
    "plt.plot(epochsAdam, adamOhOhOne[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"adam\")\n",
    "#plt.plot(epochs, rmsOhOhOne[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"rms\")\n",
    "#plt.plot(epochs, RMS_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"RMS .01\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni_rkOsaB3f9"
   },
   "source": [
    "The result is a model that performs roughly as well on both tasks as each specialized model. \n",
    "\n",
    "While the results here do not show a clear accuracy benefit from a joint model in this case, multi-task learning is in general an extremely useful tool. We can expect better results when we can transfer knowledge from a data-abundant task (such as clicks) to a closely related data-sparse task (such as purchases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movielens_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_3 (Sequential)    (None, 32)                53280     \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 32)                30208     \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 1)                 49665     \n",
      "_________________________________________________________________\n",
      "ranking_1 (Ranking)          multiple                  2         \n",
      "_________________________________________________________________\n",
      "retrieval_1 (Retrieval)      multiple                  11        \n",
      "=================================================================\n",
      "Total params: 133,166\n",
      "Trainable params: 133,153\n",
      "Non-trainable params: 13\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Export the query model.\\nwith tempfile.TemporaryDirectory() as tmp:\\n  path = os.path.join(tmp, \"adamOhOhOneModel\")\\n\\n  # Save the index.\\n  index.save(path)\\n\\n  # Load it back; can also be done in TensorFlow Serving.\\n  loaded = tf.keras.models.load_model(path)\\n\\n  # Pass a user id in, get top predicted movie titles back.\\n  scores, titles = loaded([\"42\"])\\n\\n  print(f\"Recommendations: {titles[0][:]}\")'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Export the query model.\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "  path = os.path.join(tmp, \"adamOhOhOneModel\")\n",
    "\n",
    "  # Save the index.\n",
    "  index.save(path)\n",
    "\n",
    "  # Load it back; can also be done in TensorFlow Serving.\n",
    "  loaded = tf.keras.models.load_model(path)\n",
    "\n",
    "  # Pass a user id in, get top predicted movie titles back.\n",
    "  scores, titles = loaded([\"42\"])\n",
    "\n",
    "  print(f\"Recommendations: {titles[0][:]}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multitask.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
