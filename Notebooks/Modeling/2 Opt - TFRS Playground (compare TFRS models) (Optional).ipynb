{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X80i_girFR2o"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "bB8gHCR3FVC0"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCeYA79m1DEX"
   },
   "source": [
    "# Multi-task recommenders\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/multitask\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/multitask.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/multitask.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/multitask.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dk8QEc4sIPMi"
   },
   "source": [
    "In the [basic retrieval tutorial](basic_retrieval) we built a retrieval system using movie watches as positive interaction signals.\n",
    "\n",
    "In many applications, however, there are multiple rich sources of feedback to draw upon. For example, an e-commerce site may record user visits to product pages (abundant, but relatively low signal), image clicks, adding to cart, and, finally, purchases. It may even record post-purchase signals such as reviews and returns.\n",
    "\n",
    "Integrating all these different forms of feedback is critical to building systems that users love to use, and that do not optimize for any one metric at the expense of overall performance.\n",
    "\n",
    "In addition, building a joint model for multiple tasks may produce better results than building a number of task-specific models. This is especially true where some data is abundant (for example, clicks), and some data is sparse (purchases, returns, manual reviews). In those scenarios, a joint model may be able to use representations learned from the abundant task to improve its predictions on the sparse task via a phenomenon known as [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning). For example, [this paper](https://openreview.net/pdf?id=SJxPVcSonN) shows that a model predicting explicit user ratings from sparse user surveys can be substantially improved by adding an auxiliary task that uses abundant click log data.\n",
    "\n",
    "In this tutorial, we are going to build a multi-objective recommender for Movielens, using both implicit (movie watches) and explicit signals (ratings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwrcZeK7x7xI"
   },
   "source": [
    "## Imports\n",
    "\n",
    "\n",
    "Let's first get our imports out of the way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "izzoRqkGb2Zc"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BxQ_hy7xPH3N"
   },
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PAqjR4a1RR4"
   },
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "We're going to use the Movielens 100K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-ySWtibjm_6a"
   },
   "outputs": [],
   "source": [
    "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
    "\n",
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "    #\"movie_genres\": x[\"movie_genres\"],\n",
    "    #\"bucketized_user_age\": x['bucketized_user_age'],\n",
    "    #'raw_user_age': x['raw_user_age'],\n",
    "    #'timestamp': x['timestamp'],\n",
    "    #'user_gender': x['user_gender'],\n",
    "    #'user_occupation_label': x['user_occupation_label'],\n",
    "    #'user_zip_code': x['user_zip_code']\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRHorm8W1yf3"
   },
   "source": [
    "And repeat our preparations for building vocabularies and splitting the data into a train and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rS0eDfkjnjJL"
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "#movie_genres = ratings.batch(1_000).map(lambda x: x['movie_genres'])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "#unique_movie_genres = np.unique(np.concatenate(list(movie_genres)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCi-seR86qqa"
   },
   "source": [
    "## A multi-task model\n",
    "\n",
    "There are two critical parts to multi-task recommenders:\n",
    "\n",
    "1. They optimize for two or more objectives, and so have two or more losses.\n",
    "2. They share variables between the tasks, allowing for transfer learning.\n",
    "\n",
    "In this tutorial, we will define our models as before, but instead of having  a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXHrk_SLzKCM"
   },
   "source": [
    "The user and movie models are as before:\n",
    "\n",
    "```python\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add 1 to account for the unknown token.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWCwkE5z8QBe"
   },
   "source": [
    "However, now we will have two tasks. The first is the rating task:\n",
    "\n",
    "```python\n",
    "tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrgQIXEm8UWf"
   },
   "source": [
    "Its goal is to predict the ratings as accurately as possible.\n",
    "\n",
    "The second is the retrieval task:\n",
    "\n",
    "```python\n",
    "tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128)\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCNrv7_gakmF"
   },
   "source": [
    "As before, this task's goal is to predict which movies the user will or will not watch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSWw3xuq8mGh"
   },
   "source": [
    "### Putting it together\n",
    "\n",
    "We put it all together in a model class.\n",
    "\n",
    "The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.user_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "    ])\n",
    "    self.genre_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_movie_genres, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_movie_genres) + 1, 32),\n",
    "    ])\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    # Take the input dictionary, pass it through each input layer,\n",
    "    # and concatenate the result.\n",
    "    return tf.concat([\n",
    "        self.user_embedding(inputs[\"user_id\"]),\n",
    "        self.genre_embedding(inputs[\"timestamp\"]),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "\n",
    "    self.title_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "          vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, 32)\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "        max_tokens=max_tokens)\n",
    "\n",
    "    self.title_text_embedding = tf.keras.Sequential([\n",
    "      self.title_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer.adapt(movies)\n",
    "\n",
    "  def call(self, titles):\n",
    "    return tf.concat([\n",
    "        self.title_embedding(titles),\n",
    "        self.title_text_embedding(titles),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YFSkOAMgzU0K"
   },
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "    # We take the loss weights in the constructor: this allows us to instantiate\n",
    "    # several model objects with different loss weights.\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # User and movie models.\n",
    "    self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "\n",
    "    # A small model to take in user and movie embeddings and predict ratings.\n",
    "    # We can make this as complicated as we want as long as we output a scalar\n",
    "    # as our prediction.\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    # The tasks.\n",
    "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.movie_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The loss weights.\n",
    "    self.rating_weight = rating_weight\n",
    "    self.retrieval_weight = retrieval_weight\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model.\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "    # genres\n",
    "    #genre_embeddings = self.movie_model(features['move_genres'])\n",
    "    \n",
    "    return (\n",
    "        user_embeddings,\n",
    "        movie_embeddings,\n",
    "        #genre_embeddings,\n",
    "        # We apply the multi-layered rating model to a concatentation of\n",
    "        # user and movie embeddings.\n",
    "        self.rating_model(\n",
    "            tf.concat([user_embeddings, movie_embeddings,], axis=1) #genre_embeddings], axis=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    ratings = features.pop(\"user_rating\")\n",
    "\n",
    "    user_embeddings, movie_embeddings, rating_predictions = self(features)#genre_embeddings, rating_predictions = self(features)\n",
    "\n",
    "    # We compute the loss for each task.\n",
    "    rating_loss = self.rating_task(\n",
    "        labels=ratings,\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)#, genre_embeddings)\n",
    "\n",
    "    # And combine them using the loss weights.\n",
    "    return (self.rating_weight * rating_loss\n",
    "            + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngvn-c0b8lc2"
   },
   "source": [
    "### Rating-specialized model\n",
    "\n",
    "Depending on the weights we assign, the model will encode a different balance of the tasks. Let's start with a model that only considers ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NNfB6rYL0VrS"
   },
   "outputs": [],
   "source": [
    "#model = MovielensModel(rating_weight=1.0, retrieval_weight=0.0)\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "I6kjfF1j0iZR"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6NWadH1q0c_T"
   },
   "outputs": [],
   "source": [
    "#model.fit(cached_train, epochs=3)\n",
    "#metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "#print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "#print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lENViv04-i0T"
   },
   "source": [
    "The model does OK on predicting ratings (with an RMSE of around 1.11), but performs poorly at predicting which movies will be watched or not: its accuracy at 100 is almost 4 times worse than a model trained solely to predict watches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPYd9LtE-4Fm"
   },
   "source": [
    "### Retrieval-specialized model\n",
    "\n",
    "Let's now try a model that focuses on retrieval only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "BfnkGd2G--Qt"
   },
   "outputs": [],
   "source": [
    "#model = MovielensModel(rating_weight=0.0, retrieval_weight=1.0)\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JCCBdM7U_B11"
   },
   "outputs": [],
   "source": [
    "#model.fit(cached_train, epochs=3)\n",
    "#metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "#print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "#print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjM7j7eY_jPh"
   },
   "source": [
    "We get the opposite result: a model that does well on retrieval, but poorly on predicting ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOFwjUus_pLU"
   },
   "source": [
    "### Joint model\n",
    "\n",
    "Let's now train a model that assigns positive weights to both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7xyDbNMf_t8a"
   },
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2pZmM_ub_uEO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 6s 413ms/step - root_mean_squared_error: 2.1022 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0045 - factorized_top_k/top_50_categorical_accuracy: 0.0531 - factorized_top_k/top_100_categorical_accuracy: 0.1201 - loss: 69826.2720 - regularization_loss: 0.0000e+00 - total_loss: 69826.2720\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 4s 399ms/step - root_mean_squared_error: 1.2918 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0124 - factorized_top_k/top_10_categorical_accuracy: 0.0265 - factorized_top_k/top_50_categorical_accuracy: 0.1398 - factorized_top_k/top_100_categorical_accuracy: 0.2590 - loss: 67478.8409 - regularization_loss: 0.0000e+00 - total_loss: 67478.8409\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 4s 403ms/step - root_mean_squared_error: 1.1717 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0185 - factorized_top_k/top_10_categorical_accuracy: 0.0389 - factorized_top_k/top_50_categorical_accuracy: 0.1748 - factorized_top_k/top_100_categorical_accuracy: 0.3020 - loss: 66312.0682 - regularization_loss: 0.0000e+00 - total_loss: 66312.0682\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 4s 399ms/step - root_mean_squared_error: 1.1217 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0220 - factorized_top_k/top_10_categorical_accuracy: 0.0454 - factorized_top_k/top_50_categorical_accuracy: 0.1947 - factorized_top_k/top_100_categorical_accuracy: 0.3260 - loss: 65618.7940 - regularization_loss: 0.0000e+00 - total_loss: 65618.7940\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 1.0972 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0235 - factorized_top_k/top_10_categorical_accuracy: 0.0499 - factorized_top_k/top_50_categorical_accuracy: 0.2085 - factorized_top_k/top_100_categorical_accuracy: 0.3420 - loss: 65114.0419 - regularization_loss: 0.0000e+00 - total_loss: 65114.0419\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 1.0786 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0258 - factorized_top_k/top_10_categorical_accuracy: 0.0548 - factorized_top_k/top_50_categorical_accuracy: 0.2204 - factorized_top_k/top_100_categorical_accuracy: 0.3549 - loss: 64721.0710 - regularization_loss: 0.0000e+00 - total_loss: 64721.0710\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 1.0647 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0278 - factorized_top_k/top_10_categorical_accuracy: 0.0578 - factorized_top_k/top_50_categorical_accuracy: 0.2283 - factorized_top_k/top_100_categorical_accuracy: 0.3653 - loss: 64406.3388 - regularization_loss: 0.0000e+00 - total_loss: 64406.3388\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 1.0539 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0295 - factorized_top_k/top_10_categorical_accuracy: 0.0606 - factorized_top_k/top_50_categorical_accuracy: 0.2345 - factorized_top_k/top_100_categorical_accuracy: 0.3736 - loss: 64149.7770 - regularization_loss: 0.0000e+00 - total_loss: 64149.7770\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 4s 403ms/step - root_mean_squared_error: 1.0445 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0303 - factorized_top_k/top_10_categorical_accuracy: 0.0622 - factorized_top_k/top_50_categorical_accuracy: 0.2389 - factorized_top_k/top_100_categorical_accuracy: 0.3794 - loss: 63937.5696 - regularization_loss: 0.0000e+00 - total_loss: 63937.5696\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 1.0367 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0314 - factorized_top_k/top_10_categorical_accuracy: 0.0639 - factorized_top_k/top_50_categorical_accuracy: 0.2430 - factorized_top_k/top_100_categorical_accuracy: 0.3844 - loss: 63759.6477 - regularization_loss: 0.0000e+00 - total_loss: 63759.6477\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 1.0300 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0322 - factorized_top_k/top_10_categorical_accuracy: 0.0650 - factorized_top_k/top_50_categorical_accuracy: 0.2461 - factorized_top_k/top_100_categorical_accuracy: 0.3891 - loss: 63608.5391 - regularization_loss: 0.0000e+00 - total_loss: 63608.5391\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 4s 402ms/step - root_mean_squared_error: 1.0242 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0324 - factorized_top_k/top_10_categorical_accuracy: 0.0663 - factorized_top_k/top_50_categorical_accuracy: 0.2491 - factorized_top_k/top_100_categorical_accuracy: 0.3927 - loss: 63478.6967 - regularization_loss: 0.0000e+00 - total_loss: 63478.6967\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 4s 403ms/step - root_mean_squared_error: 1.0190 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0330 - factorized_top_k/top_10_categorical_accuracy: 0.0668 - factorized_top_k/top_50_categorical_accuracy: 0.2508 - factorized_top_k/top_100_categorical_accuracy: 0.3955 - loss: 63365.9517 - regularization_loss: 0.0000e+00 - total_loss: 63365.9517\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 4s 403ms/step - root_mean_squared_error: 1.0143 - factorized_top_k/top_1_categorical_accuracy: 9.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0329 - factorized_top_k/top_10_categorical_accuracy: 0.0674 - factorized_top_k/top_50_categorical_accuracy: 0.2531 - factorized_top_k/top_100_categorical_accuracy: 0.3986 - loss: 63267.0916 - regularization_loss: 0.0000e+00 - total_loss: 63267.0916\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 4s 404ms/step - root_mean_squared_error: 1.0100 - factorized_top_k/top_1_categorical_accuracy: 9.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0334 - factorized_top_k/top_10_categorical_accuracy: 0.0681 - factorized_top_k/top_50_categorical_accuracy: 0.2554 - factorized_top_k/top_100_categorical_accuracy: 0.4011 - loss: 63179.6207 - regularization_loss: 0.0000e+00 - total_loss: 63179.6207\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 4s 404ms/step - root_mean_squared_error: 1.0060 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0337 - factorized_top_k/top_10_categorical_accuracy: 0.0683 - factorized_top_k/top_50_categorical_accuracy: 0.2570 - factorized_top_k/top_100_categorical_accuracy: 0.4033 - loss: 63101.5774 - regularization_loss: 0.0000e+00 - total_loss: 63101.5774\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 4s 403ms/step - root_mean_squared_error: 1.0024 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0342 - factorized_top_k/top_10_categorical_accuracy: 0.0691 - factorized_top_k/top_50_categorical_accuracy: 0.2590 - factorized_top_k/top_100_categorical_accuracy: 0.4060 - loss: 63031.4183 - regularization_loss: 0.0000e+00 - total_loss: 63031.4183\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 4s 404ms/step - root_mean_squared_error: 0.9987 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0340 - factorized_top_k/top_10_categorical_accuracy: 0.0694 - factorized_top_k/top_50_categorical_accuracy: 0.2605 - factorized_top_k/top_100_categorical_accuracy: 0.4085 - loss: 62967.9084 - regularization_loss: 0.0000e+00 - total_loss: 62967.9084\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 0.9949 - factorized_top_k/top_1_categorical_accuracy: 8.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0342 - factorized_top_k/top_10_categorical_accuracy: 0.0699 - factorized_top_k/top_50_categorical_accuracy: 0.2624 - factorized_top_k/top_100_categorical_accuracy: 0.4109 - loss: 62910.0625 - regularization_loss: 0.0000e+00 - total_loss: 62910.0625\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 0.9918 - factorized_top_k/top_1_categorical_accuracy: 8.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0345 - factorized_top_k/top_10_categorical_accuracy: 0.0703 - factorized_top_k/top_50_categorical_accuracy: 0.2645 - factorized_top_k/top_100_categorical_accuracy: 0.4125 - loss: 62857.0724 - regularization_loss: 0.0000e+00 - total_loss: 62857.0724\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 0.9892 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0352 - factorized_top_k/top_10_categorical_accuracy: 0.0708 - factorized_top_k/top_50_categorical_accuracy: 0.2663 - factorized_top_k/top_100_categorical_accuracy: 0.4147 - loss: 62808.2855 - regularization_loss: 0.0000e+00 - total_loss: 62808.2855\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 0.9863 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0352 - factorized_top_k/top_10_categorical_accuracy: 0.0712 - factorized_top_k/top_50_categorical_accuracy: 0.2680 - factorized_top_k/top_100_categorical_accuracy: 0.4168 - loss: 62763.1612 - regularization_loss: 0.0000e+00 - total_loss: 62763.1612\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 4s 405ms/step - root_mean_squared_error: 0.9824 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0356 - factorized_top_k/top_10_categorical_accuracy: 0.0716 - factorized_top_k/top_50_categorical_accuracy: 0.2693 - factorized_top_k/top_100_categorical_accuracy: 0.4186 - loss: 62721.2500 - regularization_loss: 0.0000e+00 - total_loss: 62721.2500\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 0.9790 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0356 - factorized_top_k/top_10_categorical_accuracy: 0.0721 - factorized_top_k/top_50_categorical_accuracy: 0.2709 - factorized_top_k/top_100_categorical_accuracy: 0.4198 - loss: 62682.1754 - regularization_loss: 0.0000e+00 - total_loss: 62682.1754\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 0.9771 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0354 - factorized_top_k/top_10_categorical_accuracy: 0.0723 - factorized_top_k/top_50_categorical_accuracy: 0.2723 - factorized_top_k/top_100_categorical_accuracy: 0.4216 - loss: 62645.6278 - regularization_loss: 0.0000e+00 - total_loss: 62645.6278\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 4s 437ms/step - root_mean_squared_error: 0.9756 - factorized_top_k/top_1_categorical_accuracy: 8.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0358 - factorized_top_k/top_10_categorical_accuracy: 0.0726 - factorized_top_k/top_50_categorical_accuracy: 0.2739 - factorized_top_k/top_100_categorical_accuracy: 0.4230 - loss: 62611.3356 - regularization_loss: 0.0000e+00 - total_loss: 62611.3356\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 4s 413ms/step - root_mean_squared_error: 0.9729 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0364 - factorized_top_k/top_10_categorical_accuracy: 0.0733 - factorized_top_k/top_50_categorical_accuracy: 0.2752 - factorized_top_k/top_100_categorical_accuracy: 0.4251 - loss: 62579.0639 - regularization_loss: 0.0000e+00 - total_loss: 62579.0639\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 5s 471ms/step - root_mean_squared_error: 0.9685 - factorized_top_k/top_1_categorical_accuracy: 3.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0357 - factorized_top_k/top_10_categorical_accuracy: 0.0731 - factorized_top_k/top_50_categorical_accuracy: 0.2761 - factorized_top_k/top_100_categorical_accuracy: 0.4263 - loss: 62548.6136 - regularization_loss: 0.0000e+00 - total_loss: 62548.6136\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 414ms/step - root_mean_squared_error: 0.9646 - factorized_top_k/top_1_categorical_accuracy: 7.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0363 - factorized_top_k/top_10_categorical_accuracy: 0.0736 - factorized_top_k/top_50_categorical_accuracy: 0.2774 - factorized_top_k/top_100_categorical_accuracy: 0.4278 - loss: 62519.8143 - regularization_loss: 0.0000e+00 - total_loss: 62519.8143\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 0.9640 - factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0361 - factorized_top_k/top_10_categorical_accuracy: 0.0739 - factorized_top_k/top_50_categorical_accuracy: 0.2782 - factorized_top_k/top_100_categorical_accuracy: 0.4289 - loss: 62492.5227 - regularization_loss: 0.0000e+00 - total_loss: 62492.5227\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 4s 446ms/step - root_mean_squared_error: 0.9655 - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0359 - factorized_top_k/top_10_categorical_accuracy: 0.0740 - factorized_top_k/top_50_categorical_accuracy: 0.2790 - factorized_top_k/top_100_categorical_accuracy: 0.4303 - loss: 62466.6033 - regularization_loss: 0.0000e+00 - total_loss: 62466.6033\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 0.9627 - factorized_top_k/top_1_categorical_accuracy: 7.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0363 - factorized_top_k/top_10_categorical_accuracy: 0.0746 - factorized_top_k/top_50_categorical_accuracy: 0.2800 - factorized_top_k/top_100_categorical_accuracy: 0.4317 - loss: 62441.9279 - regularization_loss: 0.0000e+00 - total_loss: 62441.9279\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 4s 436ms/step - root_mean_squared_error: 0.9547 - factorized_top_k/top_1_categorical_accuracy: 8.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0367 - factorized_top_k/top_10_categorical_accuracy: 0.0748 - factorized_top_k/top_50_categorical_accuracy: 0.2809 - factorized_top_k/top_100_categorical_accuracy: 0.4331 - loss: 62418.3952 - regularization_loss: 0.0000e+00 - total_loss: 62418.3952\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 0.9487 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0370 - factorized_top_k/top_10_categorical_accuracy: 0.0753 - factorized_top_k/top_50_categorical_accuracy: 0.2819 - factorized_top_k/top_100_categorical_accuracy: 0.4344 - loss: 62395.9233 - regularization_loss: 0.0000e+00 - total_loss: 62395.9233\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 5s 451ms/step - root_mean_squared_error: 0.9510 - factorized_top_k/top_1_categorical_accuracy: 4.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0366 - factorized_top_k/top_10_categorical_accuracy: 0.0751 - factorized_top_k/top_50_categorical_accuracy: 0.2822 - factorized_top_k/top_100_categorical_accuracy: 0.4355 - loss: 62374.4467 - regularization_loss: 0.0000e+00 - total_loss: 62374.4467\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 0.9658 - factorized_top_k/top_1_categorical_accuracy: 9.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0369 - factorized_top_k/top_10_categorical_accuracy: 0.0758 - factorized_top_k/top_50_categorical_accuracy: 0.2830 - factorized_top_k/top_100_categorical_accuracy: 0.4370 - loss: 62353.8970 - regularization_loss: 0.0000e+00 - total_loss: 62353.8970\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 415ms/step - root_mean_squared_error: 0.9606 - factorized_top_k/top_1_categorical_accuracy: 9.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0371 - factorized_top_k/top_10_categorical_accuracy: 0.0760 - factorized_top_k/top_50_categorical_accuracy: 0.2838 - factorized_top_k/top_100_categorical_accuracy: 0.4380 - loss: 62334.1495 - regularization_loss: 0.0000e+00 - total_loss: 62334.1495\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 415ms/step - root_mean_squared_error: 0.9366 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0374 - factorized_top_k/top_10_categorical_accuracy: 0.0764 - factorized_top_k/top_50_categorical_accuracy: 0.2848 - factorized_top_k/top_100_categorical_accuracy: 0.4388 - loss: 62315.1509 - regularization_loss: 0.0000e+00 - total_loss: 62315.1509\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 410ms/step - root_mean_squared_error: 0.9224 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0375 - factorized_top_k/top_10_categorical_accuracy: 0.0765 - factorized_top_k/top_50_categorical_accuracy: 0.2855 - factorized_top_k/top_100_categorical_accuracy: 0.4399 - loss: 62296.8988 - regularization_loss: 0.0000e+00 - total_loss: 62296.8988\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 4s 449ms/step - root_mean_squared_error: 1.0084 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0373 - factorized_top_k/top_10_categorical_accuracy: 0.0765 - factorized_top_k/top_50_categorical_accuracy: 0.2862 - factorized_top_k/top_100_categorical_accuracy: 0.4410 - loss: 62279.5508 - regularization_loss: 0.0000e+00 - total_loss: 62279.5508\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 0.9853 - factorized_top_k/top_1_categorical_accuracy: 4.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0375 - factorized_top_k/top_10_categorical_accuracy: 0.0768 - factorized_top_k/top_50_categorical_accuracy: 0.2870 - factorized_top_k/top_100_categorical_accuracy: 0.4416 - loss: 62262.5558 - regularization_loss: 0.0000e+00 - total_loss: 62262.5558\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 5s 463ms/step - root_mean_squared_error: 0.9343 - factorized_top_k/top_1_categorical_accuracy: 4.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0375 - factorized_top_k/top_10_categorical_accuracy: 0.0770 - factorized_top_k/top_50_categorical_accuracy: 0.2876 - factorized_top_k/top_100_categorical_accuracy: 0.4423 - loss: 62246.1531 - regularization_loss: 0.0000e+00 - total_loss: 62246.1531\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 4s 448ms/step - root_mean_squared_error: 0.9387 - factorized_top_k/top_1_categorical_accuracy: 3.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0375 - factorized_top_k/top_10_categorical_accuracy: 0.0771 - factorized_top_k/top_50_categorical_accuracy: 0.2886 - factorized_top_k/top_100_categorical_accuracy: 0.4436 - loss: 62230.4091 - regularization_loss: 0.0000e+00 - total_loss: 62230.4091\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 5s 470ms/step - root_mean_squared_error: 0.9504 - factorized_top_k/top_1_categorical_accuracy: 3.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0376 - factorized_top_k/top_10_categorical_accuracy: 0.0773 - factorized_top_k/top_50_categorical_accuracy: 0.2895 - factorized_top_k/top_100_categorical_accuracy: 0.4444 - loss: 62215.2056 - regularization_loss: 0.0000e+00 - total_loss: 62215.2056\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 0.9481 - factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0378 - factorized_top_k/top_10_categorical_accuracy: 0.0774 - factorized_top_k/top_50_categorical_accuracy: 0.2903 - factorized_top_k/top_100_categorical_accuracy: 0.4452 - loss: 62200.4702 - regularization_loss: 0.0000e+00 - total_loss: 62200.4702\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 5s 465ms/step - root_mean_squared_error: 0.9408 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0379 - factorized_top_k/top_10_categorical_accuracy: 0.0774 - factorized_top_k/top_50_categorical_accuracy: 0.2909 - factorized_top_k/top_100_categorical_accuracy: 0.4462 - loss: 62186.1946 - regularization_loss: 0.0000e+00 - total_loss: 62186.1946\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 5s 459ms/step - root_mean_squared_error: 0.9388 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0380 - factorized_top_k/top_10_categorical_accuracy: 0.0779 - factorized_top_k/top_50_categorical_accuracy: 0.2915 - factorized_top_k/top_100_categorical_accuracy: 0.4471 - loss: 62172.3725 - regularization_loss: 0.0000e+00 - total_loss: 62172.3725\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 5s 457ms/step - root_mean_squared_error: 0.9387 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0381 - factorized_top_k/top_10_categorical_accuracy: 0.0780 - factorized_top_k/top_50_categorical_accuracy: 0.2920 - factorized_top_k/top_100_categorical_accuracy: 0.4478 - loss: 62158.9712 - regularization_loss: 0.0000e+00 - total_loss: 62158.9712\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 5s 458ms/step - root_mean_squared_error: 0.9373 - factorized_top_k/top_1_categorical_accuracy: 3.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0381 - factorized_top_k/top_10_categorical_accuracy: 0.0781 - factorized_top_k/top_50_categorical_accuracy: 0.2924 - factorized_top_k/top_100_categorical_accuracy: 0.4484 - loss: 62145.9624 - regularization_loss: 0.0000e+00 - total_loss: 62145.9624\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 5s 459ms/step - root_mean_squared_error: 0.9351 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0382 - factorized_top_k/top_10_categorical_accuracy: 0.0782 - factorized_top_k/top_50_categorical_accuracy: 0.2929 - factorized_top_k/top_100_categorical_accuracy: 0.4492 - loss: 62133.3310 - regularization_loss: 0.0000e+00 - total_loss: 62133.3310\n",
      "5/5 [==============================] - 2s 245ms/step - root_mean_squared_error: 0.9612 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0012 - factorized_top_k/top_10_categorical_accuracy: 0.0036 - factorized_top_k/top_50_categorical_accuracy: 0.0660 - factorized_top_k/top_100_categorical_accuracy: 0.1719 - loss: 32791.3216 - regularization_loss: 0.0000e+00 - total_loss: 32791.3216\n",
      "Retrieval top-100 accuracy: 0.172.\n",
      "Ranking RMSE: 0.961.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=50)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 5s 411ms/step - root_mean_squared_error: 3.1496 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0027 - factorized_top_k/top_10_categorical_accuracy: 0.0053 - factorized_top_k/top_50_categorical_accuracy: 0.0283 - factorized_top_k/top_100_categorical_accuracy: 0.0566 - loss: 70377.7912 - regularization_loss: 0.0000e+00 - total_loss: 70377.7912\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 4s 408ms/step - root_mean_squared_error: 1.6215 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0058 - factorized_top_k/top_10_categorical_accuracy: 0.0118 - factorized_top_k/top_50_categorical_accuracy: 0.0531 - factorized_top_k/top_100_categorical_accuracy: 0.0963 - loss: 70359.5206 - regularization_loss: 0.0000e+00 - total_loss: 70359.5206\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 4s 413ms/step - root_mean_squared_error: 1.1379 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0134 - factorized_top_k/top_10_categorical_accuracy: 0.0272 - factorized_top_k/top_50_categorical_accuracy: 0.1065 - factorized_top_k/top_100_categorical_accuracy: 0.1765 - loss: 70335.9482 - regularization_loss: 0.0000e+00 - total_loss: 70335.9482\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 1.1317 - factorized_top_k/top_1_categorical_accuracy: 8.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0187 - factorized_top_k/top_10_categorical_accuracy: 0.0403 - factorized_top_k/top_50_categorical_accuracy: 0.1741 - factorized_top_k/top_100_categorical_accuracy: 0.2833 - loss: 70284.0568 - regularization_loss: 0.0000e+00 - total_loss: 70284.0568\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 4s 409ms/step - root_mean_squared_error: 1.1241 - factorized_top_k/top_1_categorical_accuracy: 2.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0207 - factorized_top_k/top_10_categorical_accuracy: 0.0457 - factorized_top_k/top_50_categorical_accuracy: 0.2005 - factorized_top_k/top_100_categorical_accuracy: 0.3334 - loss: 70186.5938 - regularization_loss: 0.0000e+00 - total_loss: 70186.5938\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 1.1075 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0211 - factorized_top_k/top_10_categorical_accuracy: 0.0468 - factorized_top_k/top_50_categorical_accuracy: 0.2059 - factorized_top_k/top_100_categorical_accuracy: 0.3426 - loss: 70043.4290 - regularization_loss: 0.0000e+00 - total_loss: 70043.4290\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 4s 409ms/step - root_mean_squared_error: 1.0892 - factorized_top_k/top_1_categorical_accuracy: 4.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0224 - factorized_top_k/top_10_categorical_accuracy: 0.0489 - factorized_top_k/top_50_categorical_accuracy: 0.2081 - factorized_top_k/top_100_categorical_accuracy: 0.3454 - loss: 69868.5724 - regularization_loss: 0.0000e+00 - total_loss: 69868.5724\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 4s 415ms/step - root_mean_squared_error: 1.0752 - factorized_top_k/top_1_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0490 - factorized_top_k/top_50_categorical_accuracy: 0.2082 - factorized_top_k/top_100_categorical_accuracy: 0.3435 - loss: 69678.9830 - regularization_loss: 0.0000e+00 - total_loss: 69678.9830\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 4s 428ms/step - root_mean_squared_error: 1.0656 - factorized_top_k/top_1_categorical_accuracy: 2.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0233 - factorized_top_k/top_10_categorical_accuracy: 0.0499 - factorized_top_k/top_50_categorical_accuracy: 0.2080 - factorized_top_k/top_100_categorical_accuracy: 0.3422 - loss: 69487.7720 - regularization_loss: 0.0000e+00 - total_loss: 69487.7720\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 5s 452ms/step - root_mean_squared_error: 1.0592 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0494 - factorized_top_k/top_50_categorical_accuracy: 0.2068 - factorized_top_k/top_100_categorical_accuracy: 0.3395 - loss: 69302.9673 - regularization_loss: 0.0000e+00 - total_loss: 69302.9673\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 4s 439ms/step - root_mean_squared_error: 1.0547 - factorized_top_k/top_1_categorical_accuracy: 1.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0235 - factorized_top_k/top_10_categorical_accuracy: 0.0499 - factorized_top_k/top_50_categorical_accuracy: 0.2074 - factorized_top_k/top_100_categorical_accuracy: 0.3384 - loss: 69128.6470 - regularization_loss: 0.0000e+00 - total_loss: 69128.6470\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 1.0514 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0243 - factorized_top_k/top_10_categorical_accuracy: 0.0507 - factorized_top_k/top_50_categorical_accuracy: 0.2079 - factorized_top_k/top_100_categorical_accuracy: 0.3372 - loss: 68966.3949 - regularization_loss: 0.0000e+00 - total_loss: 68966.3949\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 4s 437ms/step - root_mean_squared_error: 1.0488 - factorized_top_k/top_1_categorical_accuracy: 3.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0511 - factorized_top_k/top_50_categorical_accuracy: 0.2071 - factorized_top_k/top_100_categorical_accuracy: 0.3356 - loss: 68816.4034 - regularization_loss: 0.0000e+00 - total_loss: 68816.4034\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 4s 410ms/step - root_mean_squared_error: 1.0466 - factorized_top_k/top_1_categorical_accuracy: 4.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0246 - factorized_top_k/top_10_categorical_accuracy: 0.0510 - factorized_top_k/top_50_categorical_accuracy: 0.2069 - factorized_top_k/top_100_categorical_accuracy: 0.3351 - loss: 68678.1293 - regularization_loss: 0.0000e+00 - total_loss: 68678.1293\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 1.0446 - factorized_top_k/top_1_categorical_accuracy: 3.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0246 - factorized_top_k/top_10_categorical_accuracy: 0.0512 - factorized_top_k/top_50_categorical_accuracy: 0.2061 - factorized_top_k/top_100_categorical_accuracy: 0.3342 - loss: 68550.7351 - regularization_loss: 0.0000e+00 - total_loss: 68550.7351\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 1.0428 - factorized_top_k/top_1_categorical_accuracy: 3.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0244 - factorized_top_k/top_10_categorical_accuracy: 0.0515 - factorized_top_k/top_50_categorical_accuracy: 0.2049 - factorized_top_k/top_100_categorical_accuracy: 0.3333 - loss: 68433.2706 - regularization_loss: 0.0000e+00 - total_loss: 68433.2706\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 4s 434ms/step - root_mean_squared_error: 1.0409 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0247 - factorized_top_k/top_10_categorical_accuracy: 0.0515 - factorized_top_k/top_50_categorical_accuracy: 0.2044 - factorized_top_k/top_100_categorical_accuracy: 0.3325 - loss: 68324.7649 - regularization_loss: 0.0000e+00 - total_loss: 68324.7649\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 1.0392 - factorized_top_k/top_1_categorical_accuracy: 5.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0246 - factorized_top_k/top_10_categorical_accuracy: 0.0517 - factorized_top_k/top_50_categorical_accuracy: 0.2043 - factorized_top_k/top_100_categorical_accuracy: 0.3318 - loss: 68224.3196 - regularization_loss: 0.0000e+00 - total_loss: 68224.3196\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 1.0375 - factorized_top_k/top_1_categorical_accuracy: 4.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0246 - factorized_top_k/top_10_categorical_accuracy: 0.0517 - factorized_top_k/top_50_categorical_accuracy: 0.2035 - factorized_top_k/top_100_categorical_accuracy: 0.3310 - loss: 68131.0795 - regularization_loss: 0.0000e+00 - total_loss: 68131.0795\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 4s 446ms/step - root_mean_squared_error: 1.0359 - factorized_top_k/top_1_categorical_accuracy: 2.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0244 - factorized_top_k/top_10_categorical_accuracy: 0.0509 - factorized_top_k/top_50_categorical_accuracy: 0.2030 - factorized_top_k/top_100_categorical_accuracy: 0.3303 - loss: 68044.2962 - regularization_loss: 0.0000e+00 - total_loss: 68044.2962\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 1.0343 - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0243 - factorized_top_k/top_10_categorical_accuracy: 0.0506 - factorized_top_k/top_50_categorical_accuracy: 0.2029 - factorized_top_k/top_100_categorical_accuracy: 0.3307 - loss: 67963.2763 - regularization_loss: 0.0000e+00 - total_loss: 67963.2763\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.0328 - factorized_top_k/top_1_categorical_accuracy: 4.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0502 - factorized_top_k/top_50_categorical_accuracy: 0.2024 - factorized_top_k/top_100_categorical_accuracy: 0.3296 - loss: 67887.4254 - regularization_loss: 0.0000e+00 - total_loss: 67887.4254\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 4s 451ms/step - root_mean_squared_error: 1.0314 - factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0505 - factorized_top_k/top_50_categorical_accuracy: 0.2018 - factorized_top_k/top_100_categorical_accuracy: 0.3293 - loss: 67816.1974 - regularization_loss: 0.0000e+00 - total_loss: 67816.1974\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 5s 459ms/step - root_mean_squared_error: 1.0300 - factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0238 - factorized_top_k/top_10_categorical_accuracy: 0.0499 - factorized_top_k/top_50_categorical_accuracy: 0.2017 - factorized_top_k/top_100_categorical_accuracy: 0.3287 - loss: 67749.1222 - regularization_loss: 0.0000e+00 - total_loss: 67749.1222\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 1.0287 - factorized_top_k/top_1_categorical_accuracy: 5.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0238 - factorized_top_k/top_10_categorical_accuracy: 0.0499 - factorized_top_k/top_50_categorical_accuracy: 0.2009 - factorized_top_k/top_100_categorical_accuracy: 0.3283 - loss: 67685.7827 - regularization_loss: 0.0000e+00 - total_loss: 67685.7827\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 5s 468ms/step - root_mean_squared_error: 1.0274 - factorized_top_k/top_1_categorical_accuracy: 5.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0237 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - factorized_top_k/top_50_categorical_accuracy: 0.2003 - factorized_top_k/top_100_categorical_accuracy: 0.3281 - loss: 67625.8118 - regularization_loss: 0.0000e+00 - total_loss: 67625.8118\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 1.0262 - factorized_top_k/top_1_categorical_accuracy: 5.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0493 - factorized_top_k/top_50_categorical_accuracy: 0.1998 - factorized_top_k/top_100_categorical_accuracy: 0.3281 - loss: 67568.8828 - regularization_loss: 0.0000e+00 - total_loss: 67568.8828\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 5s 458ms/step - root_mean_squared_error: 1.0250 - factorized_top_k/top_1_categorical_accuracy: 5.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0240 - factorized_top_k/top_10_categorical_accuracy: 0.0491 - factorized_top_k/top_50_categorical_accuracy: 0.1998 - factorized_top_k/top_100_categorical_accuracy: 0.3273 - loss: 67514.7138 - regularization_loss: 0.0000e+00 - total_loss: 67514.7138\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.0239 - factorized_top_k/top_1_categorical_accuracy: 7.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0494 - factorized_top_k/top_50_categorical_accuracy: 0.1999 - factorized_top_k/top_100_categorical_accuracy: 0.3271 - loss: 67463.0511 - regularization_loss: 0.0000e+00 - total_loss: 67463.0511\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 432ms/step - root_mean_squared_error: 1.0228 - factorized_top_k/top_1_categorical_accuracy: 6.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0240 - factorized_top_k/top_10_categorical_accuracy: 0.0488 - factorized_top_k/top_50_categorical_accuracy: 0.1994 - factorized_top_k/top_100_categorical_accuracy: 0.3270 - loss: 67413.6747 - regularization_loss: 0.0000e+00 - total_loss: 67413.6747\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 4s 444ms/step - root_mean_squared_error: 1.0218 - factorized_top_k/top_1_categorical_accuracy: 8.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0240 - factorized_top_k/top_10_categorical_accuracy: 0.0489 - factorized_top_k/top_50_categorical_accuracy: 0.1995 - factorized_top_k/top_100_categorical_accuracy: 0.3266 - loss: 67366.3906 - regularization_loss: 0.0000e+00 - total_loss: 67366.3906\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 1.0208 - factorized_top_k/top_1_categorical_accuracy: 7.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0240 - factorized_top_k/top_10_categorical_accuracy: 0.0486 - factorized_top_k/top_50_categorical_accuracy: 0.1991 - factorized_top_k/top_100_categorical_accuracy: 0.3263 - loss: 67321.0135 - regularization_loss: 0.0000e+00 - total_loss: 67321.0135\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 1.0198 - factorized_top_k/top_1_categorical_accuracy: 7.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0489 - factorized_top_k/top_50_categorical_accuracy: 0.1991 - factorized_top_k/top_100_categorical_accuracy: 0.3261 - loss: 67277.4048 - regularization_loss: 0.0000e+00 - total_loss: 67277.4048\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 4s 434ms/step - root_mean_squared_error: 1.0188 - factorized_top_k/top_1_categorical_accuracy: 6.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0240 - factorized_top_k/top_10_categorical_accuracy: 0.0488 - factorized_top_k/top_50_categorical_accuracy: 0.1989 - factorized_top_k/top_100_categorical_accuracy: 0.3261 - loss: 67235.4155 - regularization_loss: 0.0000e+00 - total_loss: 67235.4155\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 1.0179 - factorized_top_k/top_1_categorical_accuracy: 8.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0240 - factorized_top_k/top_10_categorical_accuracy: 0.0492 - factorized_top_k/top_50_categorical_accuracy: 0.1986 - factorized_top_k/top_100_categorical_accuracy: 0.3259 - loss: 67194.9261 - regularization_loss: 0.0000e+00 - total_loss: 67194.9261\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 4s 443ms/step - root_mean_squared_error: 1.0170 - factorized_top_k/top_1_categorical_accuracy: 8.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0494 - factorized_top_k/top_50_categorical_accuracy: 0.1988 - factorized_top_k/top_100_categorical_accuracy: 0.3262 - loss: 67155.8217 - regularization_loss: 0.0000e+00 - total_loss: 67155.8217\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.0161 - factorized_top_k/top_1_categorical_accuracy: 7.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0494 - factorized_top_k/top_50_categorical_accuracy: 0.1991 - factorized_top_k/top_100_categorical_accuracy: 0.3258 - loss: 67118.0170 - regularization_loss: 0.0000e+00 - total_loss: 67118.0170\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.0152 - factorized_top_k/top_1_categorical_accuracy: 8.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0496 - factorized_top_k/top_50_categorical_accuracy: 0.1991 - factorized_top_k/top_100_categorical_accuracy: 0.3259 - loss: 67081.4105 - regularization_loss: 0.0000e+00 - total_loss: 67081.4105\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 434ms/step - root_mean_squared_error: 1.0144 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0240 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - factorized_top_k/top_50_categorical_accuracy: 0.1990 - factorized_top_k/top_100_categorical_accuracy: 0.3259 - loss: 67045.9233 - regularization_loss: 0.0000e+00 - total_loss: 67045.9233\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 4s 428ms/step - root_mean_squared_error: 1.0136 - factorized_top_k/top_1_categorical_accuracy: 8.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - factorized_top_k/top_50_categorical_accuracy: 0.1991 - factorized_top_k/top_100_categorical_accuracy: 0.3261 - loss: 67011.4844 - regularization_loss: 0.0000e+00 - total_loss: 67011.4844\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 4s 441ms/step - root_mean_squared_error: 1.0128 - factorized_top_k/top_1_categorical_accuracy: 7.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0494 - factorized_top_k/top_50_categorical_accuracy: 0.1995 - factorized_top_k/top_100_categorical_accuracy: 0.3262 - loss: 66978.0348 - regularization_loss: 0.0000e+00 - total_loss: 66978.0348\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 5s 454ms/step - root_mean_squared_error: 1.0120 - factorized_top_k/top_1_categorical_accuracy: 7.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0243 - factorized_top_k/top_10_categorical_accuracy: 0.0493 - factorized_top_k/top_50_categorical_accuracy: 0.1998 - factorized_top_k/top_100_categorical_accuracy: 0.3261 - loss: 66945.5099 - regularization_loss: 0.0000e+00 - total_loss: 66945.5099\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 4s 443ms/step - root_mean_squared_error: 1.0113 - factorized_top_k/top_1_categorical_accuracy: 7.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0493 - factorized_top_k/top_50_categorical_accuracy: 0.1995 - factorized_top_k/top_100_categorical_accuracy: 0.3259 - loss: 66913.8544 - regularization_loss: 0.0000e+00 - total_loss: 66913.8544\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 5s 457ms/step - root_mean_squared_error: 1.0105 - factorized_top_k/top_1_categorical_accuracy: 8.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0238 - factorized_top_k/top_10_categorical_accuracy: 0.0494 - factorized_top_k/top_50_categorical_accuracy: 0.1995 - factorized_top_k/top_100_categorical_accuracy: 0.3262 - loss: 66883.0199 - regularization_loss: 0.0000e+00 - total_loss: 66883.0199\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 4s 434ms/step - root_mean_squared_error: 1.0098 - factorized_top_k/top_1_categorical_accuracy: 9.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0493 - factorized_top_k/top_50_categorical_accuracy: 0.2000 - factorized_top_k/top_100_categorical_accuracy: 0.3262 - loss: 66852.9602 - regularization_loss: 0.0000e+00 - total_loss: 66852.9602\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 5s 460ms/step - root_mean_squared_error: 1.0091 - factorized_top_k/top_1_categorical_accuracy: 8.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0492 - factorized_top_k/top_50_categorical_accuracy: 0.1999 - factorized_top_k/top_100_categorical_accuracy: 0.3268 - loss: 66823.6371 - regularization_loss: 0.0000e+00 - total_loss: 66823.6371\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 1.0084 - factorized_top_k/top_1_categorical_accuracy: 8.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0240 - factorized_top_k/top_10_categorical_accuracy: 0.0494 - factorized_top_k/top_50_categorical_accuracy: 0.1998 - factorized_top_k/top_100_categorical_accuracy: 0.3267 - loss: 66795.0099 - regularization_loss: 0.0000e+00 - total_loss: 66795.0099\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 5s 470ms/step - root_mean_squared_error: 1.0077 - factorized_top_k/top_1_categorical_accuracy: 8.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - factorized_top_k/top_50_categorical_accuracy: 0.1997 - factorized_top_k/top_100_categorical_accuracy: 0.3268 - loss: 66767.0440 - regularization_loss: 0.0000e+00 - total_loss: 66767.0440\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 4s 447ms/step - root_mean_squared_error: 1.0070 - factorized_top_k/top_1_categorical_accuracy: 9.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0243 - factorized_top_k/top_10_categorical_accuracy: 0.0497 - factorized_top_k/top_50_categorical_accuracy: 0.1998 - factorized_top_k/top_100_categorical_accuracy: 0.3272 - loss: 66739.7095 - regularization_loss: 0.0000e+00 - total_loss: 66739.7095\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 1.0063 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0244 - factorized_top_k/top_10_categorical_accuracy: 0.0499 - factorized_top_k/top_50_categorical_accuracy: 0.2001 - factorized_top_k/top_100_categorical_accuracy: 0.3273 - loss: 66712.9723 - regularization_loss: 0.0000e+00 - total_loss: 66712.9723\n",
      "5/5 [==============================] - 2s 225ms/step - root_mean_squared_error: 1.0014 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0117 - factorized_top_k/top_10_categorical_accuracy: 0.0260 - factorized_top_k/top_50_categorical_accuracy: 0.1412 - factorized_top_k/top_100_categorical_accuracy: 0.2515 - loss: 31219.0977 - regularization_loss: 0.0000e+00 - total_loss: 31219.0977\n",
      "Retrieval top-100 accuracy: 0.252.\n",
      "Ranking RMSE: 1.001.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))\n",
    "adaOhOne = model.fit(cached_train, epochs=50)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "\n",
    "#************************\n",
    "\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('adaOhOne.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>factorized_top_k/top_1_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_5_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_10_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_50_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_100_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>regularization_loss</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.288998</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.027275</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>54849.933594</td>\n",
       "      <td>0</td>\n",
       "      <td>54849.933594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.953145</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.012362</td>\n",
       "      <td>0.055512</td>\n",
       "      <td>0.103013</td>\n",
       "      <td>54830.937500</td>\n",
       "      <td>0</td>\n",
       "      <td>54830.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.171531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>0.028937</td>\n",
       "      <td>0.118425</td>\n",
       "      <td>0.197262</td>\n",
       "      <td>54798.488281</td>\n",
       "      <td>0</td>\n",
       "      <td>54798.488281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.134231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018675</td>\n",
       "      <td>0.040787</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>0.291638</td>\n",
       "      <td>54733.171875</td>\n",
       "      <td>0</td>\n",
       "      <td>54733.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.126864</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.045550</td>\n",
       "      <td>0.197425</td>\n",
       "      <td>0.323287</td>\n",
       "      <td>54630.246094</td>\n",
       "      <td>0</td>\n",
       "      <td>54630.246094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.111921</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.022350</td>\n",
       "      <td>0.047812</td>\n",
       "      <td>0.202912</td>\n",
       "      <td>0.330462</td>\n",
       "      <td>54497.359375</td>\n",
       "      <td>0</td>\n",
       "      <td>54497.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.094067</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.022287</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>0.202975</td>\n",
       "      <td>0.330563</td>\n",
       "      <td>54347.066406</td>\n",
       "      <td>0</td>\n",
       "      <td>54347.066406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   root_mean_squared_error  factorized_top_k/top_1_categorical_accuracy  \\\n",
       "0                 3.288998                                     0.000012   \n",
       "1                 1.953145                                     0.000025   \n",
       "2                 1.171531                                     0.000000   \n",
       "3                 1.134231                                     0.000000   \n",
       "4                 1.126864                                     0.000200   \n",
       "5                 1.111921                                     0.000550   \n",
       "6                 1.094067                                     0.000100   \n",
       "\n",
       "   factorized_top_k/top_5_categorical_accuracy  \\\n",
       "0                                     0.002325   \n",
       "1                                     0.005925   \n",
       "2                                     0.013875   \n",
       "3                                     0.018675   \n",
       "4                                     0.020913   \n",
       "5                                     0.022350   \n",
       "6                                     0.022287   \n",
       "\n",
       "   factorized_top_k/top_10_categorical_accuracy  \\\n",
       "0                                      0.005000   \n",
       "1                                      0.012362   \n",
       "2                                      0.028937   \n",
       "3                                      0.040787   \n",
       "4                                      0.045550   \n",
       "5                                      0.047812   \n",
       "6                                      0.047625   \n",
       "\n",
       "   factorized_top_k/top_50_categorical_accuracy  \\\n",
       "0                                      0.027275   \n",
       "1                                      0.055512   \n",
       "2                                      0.118425   \n",
       "3                                      0.177075   \n",
       "4                                      0.197425   \n",
       "5                                      0.202912   \n",
       "6                                      0.202975   \n",
       "\n",
       "   factorized_top_k/top_100_categorical_accuracy          loss  \\\n",
       "0                                       0.056075  54849.933594   \n",
       "1                                       0.103013  54830.937500   \n",
       "2                                       0.197262  54798.488281   \n",
       "3                                       0.291638  54733.171875   \n",
       "4                                       0.323287  54630.246094   \n",
       "5                                       0.330462  54497.359375   \n",
       "6                                       0.330563  54347.066406   \n",
       "\n",
       "   regularization_loss    total_loss  \n",
       "0                    0  54849.933594  \n",
       "1                    0  54830.937500  \n",
       "2                    0  54798.488281  \n",
       "3                    0  54733.171875  \n",
       "4                    0  54630.246094  \n",
       "5                    0  54497.359375  \n",
       "6                    0  54347.066406  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaOhOne = pd.DataFrame(adaOhOne.history)\n",
    "adaOhOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 6s 451ms/step - root_mean_squared_error: 3.6430 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0024 - factorized_top_k/top_10_categorical_accuracy: 0.0051 - factorized_top_k/top_50_categorical_accuracy: 0.0291 - factorized_top_k/top_100_categorical_accuracy: 0.0584 - loss: 70380.8089 - regularization_loss: 0.0000e+00 - total_loss: 70380.8089\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 3.5899 - factorized_top_k/top_1_categorical_accuracy: 8.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0025 - factorized_top_k/top_10_categorical_accuracy: 0.0054 - factorized_top_k/top_50_categorical_accuracy: 0.0307 - factorized_top_k/top_100_categorical_accuracy: 0.0610 - loss: 70379.5668 - regularization_loss: 0.0000e+00 - total_loss: 70379.5668\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 4s 414ms/step - root_mean_squared_error: 3.5455 - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0027 - factorized_top_k/top_10_categorical_accuracy: 0.0056 - factorized_top_k/top_50_categorical_accuracy: 0.0319 - factorized_top_k/top_100_categorical_accuracy: 0.0635 - loss: 70378.5589 - regularization_loss: 0.0000e+00 - total_loss: 70378.5589\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 3.5034 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0028 - factorized_top_k/top_10_categorical_accuracy: 0.0059 - factorized_top_k/top_50_categorical_accuracy: 0.0328 - factorized_top_k/top_100_categorical_accuracy: 0.0655 - loss: 70377.6605 - regularization_loss: 0.0000e+00 - total_loss: 70377.6605\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 4s 433ms/step - root_mean_squared_error: 3.4619 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0062 - factorized_top_k/top_50_categorical_accuracy: 0.0336 - factorized_top_k/top_100_categorical_accuracy: 0.0675 - loss: 70376.8210 - regularization_loss: 0.0000e+00 - total_loss: 70376.8210\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 4s 439ms/step - root_mean_squared_error: 3.4202 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0031 - factorized_top_k/top_10_categorical_accuracy: 0.0064 - factorized_top_k/top_50_categorical_accuracy: 0.0348 - factorized_top_k/top_100_categorical_accuracy: 0.0694 - loss: 70376.0142 - regularization_loss: 0.0000e+00 - total_loss: 70376.0142\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 4s 428ms/step - root_mean_squared_error: 3.3777 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0032 - factorized_top_k/top_10_categorical_accuracy: 0.0069 - factorized_top_k/top_50_categorical_accuracy: 0.0359 - factorized_top_k/top_100_categorical_accuracy: 0.0713 - loss: 70375.2351 - regularization_loss: 0.0000e+00 - total_loss: 70375.2351\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 4s 439ms/step - root_mean_squared_error: 3.3340 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0033 - factorized_top_k/top_10_categorical_accuracy: 0.0071 - factorized_top_k/top_50_categorical_accuracy: 0.0369 - factorized_top_k/top_100_categorical_accuracy: 0.0732 - loss: 70374.4702 - regularization_loss: 0.0000e+00 - total_loss: 70374.4702\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 5s 452ms/step - root_mean_squared_error: 3.2888 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0034 - factorized_top_k/top_10_categorical_accuracy: 0.0074 - factorized_top_k/top_50_categorical_accuracy: 0.0382 - factorized_top_k/top_100_categorical_accuracy: 0.0749 - loss: 70373.7173 - regularization_loss: 0.0000e+00 - total_loss: 70373.7173\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 3.2419 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0036 - factorized_top_k/top_10_categorical_accuracy: 0.0078 - factorized_top_k/top_50_categorical_accuracy: 0.0394 - factorized_top_k/top_100_categorical_accuracy: 0.0770 - loss: 70372.9652 - regularization_loss: 0.0000e+00 - total_loss: 70372.9652\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 4s 444ms/step - root_mean_squared_error: 3.1932 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0037 - factorized_top_k/top_10_categorical_accuracy: 0.0081 - factorized_top_k/top_50_categorical_accuracy: 0.0404 - factorized_top_k/top_100_categorical_accuracy: 0.0786 - loss: 70372.2124 - regularization_loss: 0.0000e+00 - total_loss: 70372.2124\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 4s 436ms/step - root_mean_squared_error: 3.1426 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0038 - factorized_top_k/top_10_categorical_accuracy: 0.0084 - factorized_top_k/top_50_categorical_accuracy: 0.0416 - factorized_top_k/top_100_categorical_accuracy: 0.0805 - loss: 70371.4624 - regularization_loss: 0.0000e+00 - total_loss: 70371.4624\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 3.0901 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0040 - factorized_top_k/top_10_categorical_accuracy: 0.0086 - factorized_top_k/top_50_categorical_accuracy: 0.0424 - factorized_top_k/top_100_categorical_accuracy: 0.0823 - loss: 70370.7131 - regularization_loss: 0.0000e+00 - total_loss: 70370.7131\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 5s 458ms/step - root_mean_squared_error: 3.0356 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0041 - factorized_top_k/top_10_categorical_accuracy: 0.0089 - factorized_top_k/top_50_categorical_accuracy: 0.0431 - factorized_top_k/top_100_categorical_accuracy: 0.0840 - loss: 70369.9553 - regularization_loss: 0.0000e+00 - total_loss: 70369.9553\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 2.9793 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0043 - factorized_top_k/top_10_categorical_accuracy: 0.0094 - factorized_top_k/top_50_categorical_accuracy: 0.0443 - factorized_top_k/top_100_categorical_accuracy: 0.0859 - loss: 70369.1989 - regularization_loss: 0.0000e+00 - total_loss: 70369.1989\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 2.9212 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0045 - factorized_top_k/top_10_categorical_accuracy: 0.0096 - factorized_top_k/top_50_categorical_accuracy: 0.0453 - factorized_top_k/top_100_categorical_accuracy: 0.0876 - loss: 70368.4375 - regularization_loss: 0.0000e+00 - total_loss: 70368.4375\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 4s 445ms/step - root_mean_squared_error: 2.8615 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0047 - factorized_top_k/top_10_categorical_accuracy: 0.0101 - factorized_top_k/top_50_categorical_accuracy: 0.0466 - factorized_top_k/top_100_categorical_accuracy: 0.0893 - loss: 70367.6747 - regularization_loss: 0.0000e+00 - total_loss: 70367.6747\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 449ms/step - root_mean_squared_error: 2.8003 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0049 - factorized_top_k/top_10_categorical_accuracy: 0.0104 - factorized_top_k/top_50_categorical_accuracy: 0.0476 - factorized_top_k/top_100_categorical_accuracy: 0.0911 - loss: 70366.9112 - regularization_loss: 0.0000e+00 - total_loss: 70366.9112\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 5s 460ms/step - root_mean_squared_error: 2.7379 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0050 - factorized_top_k/top_10_categorical_accuracy: 0.0107 - factorized_top_k/top_50_categorical_accuracy: 0.0486 - factorized_top_k/top_100_categorical_accuracy: 0.0929 - loss: 70366.1463 - regularization_loss: 0.0000e+00 - total_loss: 70366.1463\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 5s 468ms/step - root_mean_squared_error: 2.6744 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0052 - factorized_top_k/top_10_categorical_accuracy: 0.0110 - factorized_top_k/top_50_categorical_accuracy: 0.0497 - factorized_top_k/top_100_categorical_accuracy: 0.0945 - loss: 70365.3814 - regularization_loss: 0.0000e+00 - total_loss: 70365.3814\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 5s 469ms/step - root_mean_squared_error: 2.6100 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0053 - factorized_top_k/top_10_categorical_accuracy: 0.0112 - factorized_top_k/top_50_categorical_accuracy: 0.0507 - factorized_top_k/top_100_categorical_accuracy: 0.0962 - loss: 70364.6179 - regularization_loss: 0.0000e+00 - total_loss: 70364.6179\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 5s 465ms/step - root_mean_squared_error: 2.5449 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0055 - factorized_top_k/top_10_categorical_accuracy: 0.0116 - factorized_top_k/top_50_categorical_accuracy: 0.0520 - factorized_top_k/top_100_categorical_accuracy: 0.0980 - loss: 70363.8558 - regularization_loss: 0.0000e+00 - total_loss: 70363.8558\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 2.4793 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0056 - factorized_top_k/top_10_categorical_accuracy: 0.0121 - factorized_top_k/top_50_categorical_accuracy: 0.0532 - factorized_top_k/top_100_categorical_accuracy: 0.0998 - loss: 70363.0959 - regularization_loss: 0.0000e+00 - total_loss: 70363.0959\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 5s 468ms/step - root_mean_squared_error: 2.4135 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0059 - factorized_top_k/top_10_categorical_accuracy: 0.0125 - factorized_top_k/top_50_categorical_accuracy: 0.0544 - factorized_top_k/top_100_categorical_accuracy: 0.1015 - loss: 70362.3395 - regularization_loss: 0.0000e+00 - total_loss: 70362.3395\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 5s 465ms/step - root_mean_squared_error: 2.3476 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0061 - factorized_top_k/top_10_categorical_accuracy: 0.0127 - factorized_top_k/top_50_categorical_accuracy: 0.0558 - factorized_top_k/top_100_categorical_accuracy: 0.1037 - loss: 70361.5838 - regularization_loss: 0.0000e+00 - total_loss: 70361.5838\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 5s 460ms/step - root_mean_squared_error: 2.2819 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0063 - factorized_top_k/top_10_categorical_accuracy: 0.0131 - factorized_top_k/top_50_categorical_accuracy: 0.0570 - factorized_top_k/top_100_categorical_accuracy: 0.1056 - loss: 70360.8388 - regularization_loss: 0.0000e+00 - total_loss: 70360.8388\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 2.2166 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0066 - factorized_top_k/top_10_categorical_accuracy: 0.0135 - factorized_top_k/top_50_categorical_accuracy: 0.0585 - factorized_top_k/top_100_categorical_accuracy: 0.1075 - loss: 70360.0980 - regularization_loss: 0.0000e+00 - total_loss: 70360.0980\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 2.1521 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0069 - factorized_top_k/top_10_categorical_accuracy: 0.0139 - factorized_top_k/top_50_categorical_accuracy: 0.0596 - factorized_top_k/top_100_categorical_accuracy: 0.1094 - loss: 70359.3636 - regularization_loss: 0.0000e+00 - total_loss: 70359.3636\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 435ms/step - root_mean_squared_error: 2.0887 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0071 - factorized_top_k/top_10_categorical_accuracy: 0.0143 - factorized_top_k/top_50_categorical_accuracy: 0.0610 - factorized_top_k/top_100_categorical_accuracy: 0.1113 - loss: 70358.6328 - regularization_loss: 0.0000e+00 - total_loss: 70358.6328\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 2.0264 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0074 - factorized_top_k/top_10_categorical_accuracy: 0.0147 - factorized_top_k/top_50_categorical_accuracy: 0.0623 - factorized_top_k/top_100_categorical_accuracy: 0.1134 - loss: 70357.9119 - regularization_loss: 0.0000e+00 - total_loss: 70357.9119\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 4s 443ms/step - root_mean_squared_error: 1.9656 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0075 - factorized_top_k/top_10_categorical_accuracy: 0.0153 - factorized_top_k/top_50_categorical_accuracy: 0.0636 - factorized_top_k/top_100_categorical_accuracy: 0.1155 - loss: 70357.1982 - regularization_loss: 0.0000e+00 - total_loss: 70357.1982\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 452ms/step - root_mean_squared_error: 1.9065 - factorized_top_k/top_1_categorical_accuracy: 1.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0077 - factorized_top_k/top_10_categorical_accuracy: 0.0158 - factorized_top_k/top_50_categorical_accuracy: 0.0652 - factorized_top_k/top_100_categorical_accuracy: 0.1174 - loss: 70356.4865 - regularization_loss: 0.0000e+00 - total_loss: 70356.4865\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 1.8493 - factorized_top_k/top_1_categorical_accuracy: 1.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0079 - factorized_top_k/top_10_categorical_accuracy: 0.0162 - factorized_top_k/top_50_categorical_accuracy: 0.0666 - factorized_top_k/top_100_categorical_accuracy: 0.1195 - loss: 70355.7869 - regularization_loss: 0.0000e+00 - total_loss: 70355.7869\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 4s 433ms/step - root_mean_squared_error: 1.7941 - factorized_top_k/top_1_categorical_accuracy: 1.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0081 - factorized_top_k/top_10_categorical_accuracy: 0.0167 - factorized_top_k/top_50_categorical_accuracy: 0.0680 - factorized_top_k/top_100_categorical_accuracy: 0.1214 - loss: 70355.0909 - regularization_loss: 0.0000e+00 - total_loss: 70355.0909\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 1.7410 - factorized_top_k/top_1_categorical_accuracy: 1.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0083 - factorized_top_k/top_10_categorical_accuracy: 0.0170 - factorized_top_k/top_50_categorical_accuracy: 0.0693 - factorized_top_k/top_100_categorical_accuracy: 0.1235 - loss: 70354.4034 - regularization_loss: 0.0000e+00 - total_loss: 70354.4034\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 4s 450ms/step - root_mean_squared_error: 1.6904 - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0086 - factorized_top_k/top_10_categorical_accuracy: 0.0176 - factorized_top_k/top_50_categorical_accuracy: 0.0707 - factorized_top_k/top_100_categorical_accuracy: 0.1253 - loss: 70353.7209 - regularization_loss: 0.0000e+00 - total_loss: 70353.7209\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 5s 460ms/step - root_mean_squared_error: 1.6421 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0089 - factorized_top_k/top_10_categorical_accuracy: 0.0181 - factorized_top_k/top_50_categorical_accuracy: 0.0718 - factorized_top_k/top_100_categorical_accuracy: 0.1273 - loss: 70353.0419 - regularization_loss: 0.0000e+00 - total_loss: 70353.0419\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 441ms/step - root_mean_squared_error: 1.5964 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0092 - factorized_top_k/top_10_categorical_accuracy: 0.0186 - factorized_top_k/top_50_categorical_accuracy: 0.0731 - factorized_top_k/top_100_categorical_accuracy: 0.1294 - loss: 70352.3665 - regularization_loss: 0.0000e+00 - total_loss: 70352.3665\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 1.5533 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0095 - factorized_top_k/top_10_categorical_accuracy: 0.0191 - factorized_top_k/top_50_categorical_accuracy: 0.0746 - factorized_top_k/top_100_categorical_accuracy: 0.1315 - loss: 70351.6989 - regularization_loss: 0.0000e+00 - total_loss: 70351.6989\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 5s 456ms/step - root_mean_squared_error: 1.5128 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0098 - factorized_top_k/top_10_categorical_accuracy: 0.0196 - factorized_top_k/top_50_categorical_accuracy: 0.0761 - factorized_top_k/top_100_categorical_accuracy: 0.1339 - loss: 70351.0327 - regularization_loss: 0.0000e+00 - total_loss: 70351.0327\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 5s 456ms/step - root_mean_squared_error: 1.4751 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0102 - factorized_top_k/top_10_categorical_accuracy: 0.0201 - factorized_top_k/top_50_categorical_accuracy: 0.0778 - factorized_top_k/top_100_categorical_accuracy: 0.1359 - loss: 70350.3693 - regularization_loss: 0.0000e+00 - total_loss: 70350.3693\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 5s 455ms/step - root_mean_squared_error: 1.4399 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0105 - factorized_top_k/top_10_categorical_accuracy: 0.0205 - factorized_top_k/top_50_categorical_accuracy: 0.0795 - factorized_top_k/top_100_categorical_accuracy: 0.1379 - loss: 70349.7060 - regularization_loss: 0.0000e+00 - total_loss: 70349.7060\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 5s 464ms/step - root_mean_squared_error: 1.4074 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0107 - factorized_top_k/top_10_categorical_accuracy: 0.0209 - factorized_top_k/top_50_categorical_accuracy: 0.0809 - factorized_top_k/top_100_categorical_accuracy: 0.1404 - loss: 70349.0426 - regularization_loss: 0.0000e+00 - total_loss: 70349.0426\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.3775 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0110 - factorized_top_k/top_10_categorical_accuracy: 0.0215 - factorized_top_k/top_50_categorical_accuracy: 0.0825 - factorized_top_k/top_100_categorical_accuracy: 0.1428 - loss: 70348.3778 - regularization_loss: 0.0000e+00 - total_loss: 70348.3778\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 1.3501 - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0114 - factorized_top_k/top_10_categorical_accuracy: 0.0220 - factorized_top_k/top_50_categorical_accuracy: 0.0840 - factorized_top_k/top_100_categorical_accuracy: 0.1450 - loss: 70347.7145 - regularization_loss: 0.0000e+00 - total_loss: 70347.7145\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.3252 - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0118 - factorized_top_k/top_10_categorical_accuracy: 0.0227 - factorized_top_k/top_50_categorical_accuracy: 0.0860 - factorized_top_k/top_100_categorical_accuracy: 0.1475 - loss: 70347.0469 - regularization_loss: 0.0000e+00 - total_loss: 70347.0469\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 4s 441ms/step - root_mean_squared_error: 1.3025 - factorized_top_k/top_1_categorical_accuracy: 1.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0120 - factorized_top_k/top_10_categorical_accuracy: 0.0232 - factorized_top_k/top_50_categorical_accuracy: 0.0878 - factorized_top_k/top_100_categorical_accuracy: 0.1499 - loss: 70346.3807 - regularization_loss: 0.0000e+00 - total_loss: 70346.3807\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 1.2820 - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0124 - factorized_top_k/top_10_categorical_accuracy: 0.0238 - factorized_top_k/top_50_categorical_accuracy: 0.0894 - factorized_top_k/top_100_categorical_accuracy: 0.1523 - loss: 70345.7053 - regularization_loss: 0.0000e+00 - total_loss: 70345.7053\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 1.2636 - factorized_top_k/top_1_categorical_accuracy: 3.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0128 - factorized_top_k/top_10_categorical_accuracy: 0.0245 - factorized_top_k/top_50_categorical_accuracy: 0.0911 - factorized_top_k/top_100_categorical_accuracy: 0.1547 - loss: 70345.0270 - regularization_loss: 0.0000e+00 - total_loss: 70345.0270\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 4s 433ms/step - root_mean_squared_error: 1.2471 - factorized_top_k/top_1_categorical_accuracy: 1.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0130 - factorized_top_k/top_10_categorical_accuracy: 0.0249 - factorized_top_k/top_50_categorical_accuracy: 0.0929 - factorized_top_k/top_100_categorical_accuracy: 0.1570 - loss: 70344.3466 - regularization_loss: 0.0000e+00 - total_loss: 70344.3466\n",
      "5/5 [==============================] - 2s 260ms/step - root_mean_squared_error: 1.2397 - factorized_top_k/top_1_categorical_accuracy: 6.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0047 - factorized_top_k/top_10_categorical_accuracy: 0.0093 - factorized_top_k/top_50_categorical_accuracy: 0.0448 - factorized_top_k/top_100_categorical_accuracy: 0.0839 - loss: 32587.6582 - regularization_loss: 0.0000e+00 - total_loss: 32587.6582\n",
      "Retrieval top-100 accuracy: 0.084.\n",
      "Ranking RMSE: 1.240.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.001))\n",
    "model.fit(cached_train, epochs=50)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 5s 442ms/step - root_mean_squared_error: 9.2875 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 7.7500e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0020 - factorized_top_k/top_50_categorical_accuracy: 0.0215 - factorized_top_k/top_100_categorical_accuracy: 0.0556 - loss: 69974.8082 - regularization_loss: 0.0000e+00 - total_loss: 69974.8082\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 3.6376 - factorized_top_k/top_1_categorical_accuracy: 5.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0117 - factorized_top_k/top_10_categorical_accuracy: 0.0252 - factorized_top_k/top_50_categorical_accuracy: 0.1285 - factorized_top_k/top_100_categorical_accuracy: 0.2391 - loss: 66757.0866 - regularization_loss: 0.0000e+00 - total_loss: 66757.0866\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 4s 434ms/step - root_mean_squared_error: 3.2551 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0208 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - factorized_top_k/top_50_categorical_accuracy: 0.1894 - factorized_top_k/top_100_categorical_accuracy: 0.3195 - loss: 64874.7827 - regularization_loss: 0.0000e+00 - total_loss: 64874.7827\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 5s 447ms/step - root_mean_squared_error: 2.7917 - factorized_top_k/top_1_categorical_accuracy: 0.0021 - factorized_top_k/top_5_categorical_accuracy: 0.0249 - factorized_top_k/top_10_categorical_accuracy: 0.0536 - factorized_top_k/top_50_categorical_accuracy: 0.2240 - factorized_top_k/top_100_categorical_accuracy: 0.3683 - loss: 63912.1271 - regularization_loss: 0.0000e+00 - total_loss: 63912.1271\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 4s 446ms/step - root_mean_squared_error: 2.3372 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0278 - factorized_top_k/top_10_categorical_accuracy: 0.0598 - factorized_top_k/top_50_categorical_accuracy: 0.2491 - factorized_top_k/top_100_categorical_accuracy: 0.4019 - loss: 63386.7614 - regularization_loss: 0.0000e+00 - total_loss: 63386.7614\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.9402 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0291 - factorized_top_k/top_10_categorical_accuracy: 0.0629 - factorized_top_k/top_50_categorical_accuracy: 0.2638 - factorized_top_k/top_100_categorical_accuracy: 0.4184 - loss: 63071.2024 - regularization_loss: 0.0000e+00 - total_loss: 63071.2024\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 1.6263 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0284 - factorized_top_k/top_10_categorical_accuracy: 0.0659 - factorized_top_k/top_50_categorical_accuracy: 0.2728 - factorized_top_k/top_100_categorical_accuracy: 0.4322 - loss: 62878.4205 - regularization_loss: 0.0000e+00 - total_loss: 62878.4205\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 4s 432ms/step - root_mean_squared_error: 1.4035 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0290 - factorized_top_k/top_10_categorical_accuracy: 0.0668 - factorized_top_k/top_50_categorical_accuracy: 0.2806 - factorized_top_k/top_100_categorical_accuracy: 0.4402 - loss: 62743.1513 - regularization_loss: 0.0000e+00 - total_loss: 62743.1513\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 5s 453ms/step - root_mean_squared_error: 1.2635 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0294 - factorized_top_k/top_10_categorical_accuracy: 0.0683 - factorized_top_k/top_50_categorical_accuracy: 0.2866 - factorized_top_k/top_100_categorical_accuracy: 0.4471 - loss: 62644.9837 - regularization_loss: 0.0000e+00 - total_loss: 62644.9837\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 5s 458ms/step - root_mean_squared_error: 1.1865 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0292 - factorized_top_k/top_10_categorical_accuracy: 0.0692 - factorized_top_k/top_50_categorical_accuracy: 0.2907 - factorized_top_k/top_100_categorical_accuracy: 0.4528 - loss: 62568.6491 - regularization_loss: 0.0000e+00 - total_loss: 62568.6491\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 5s 469ms/step - root_mean_squared_error: 1.1495 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0294 - factorized_top_k/top_10_categorical_accuracy: 0.0695 - factorized_top_k/top_50_categorical_accuracy: 0.2946 - factorized_top_k/top_100_categorical_accuracy: 0.4570 - loss: 62505.6470 - regularization_loss: 0.0000e+00 - total_loss: 62505.6470\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 5s 451ms/step - root_mean_squared_error: 1.1339 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0292 - factorized_top_k/top_10_categorical_accuracy: 0.0706 - factorized_top_k/top_50_categorical_accuracy: 0.2981 - factorized_top_k/top_100_categorical_accuracy: 0.4599 - loss: 62458.5369 - regularization_loss: 0.0000e+00 - total_loss: 62458.5369\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 1.1282 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0295 - factorized_top_k/top_10_categorical_accuracy: 0.0706 - factorized_top_k/top_50_categorical_accuracy: 0.3013 - factorized_top_k/top_100_categorical_accuracy: 0.4633 - loss: 62407.9499 - regularization_loss: 0.0000e+00 - total_loss: 62407.9499\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.1264 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0291 - factorized_top_k/top_10_categorical_accuracy: 0.0712 - factorized_top_k/top_50_categorical_accuracy: 0.3029 - factorized_top_k/top_100_categorical_accuracy: 0.4659 - loss: 62370.6921 - regularization_loss: 0.0000e+00 - total_loss: 62370.6921\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 1.1260 - factorized_top_k/top_1_categorical_accuracy: 0.0018 - factorized_top_k/top_5_categorical_accuracy: 0.0294 - factorized_top_k/top_10_categorical_accuracy: 0.0711 - factorized_top_k/top_50_categorical_accuracy: 0.3047 - factorized_top_k/top_100_categorical_accuracy: 0.4680 - loss: 62339.6673 - regularization_loss: 0.0000e+00 - total_loss: 62339.6673\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 4s 436ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0290 - factorized_top_k/top_10_categorical_accuracy: 0.0711 - factorized_top_k/top_50_categorical_accuracy: 0.3063 - factorized_top_k/top_100_categorical_accuracy: 0.4693 - loss: 62321.7859 - regularization_loss: 0.0000e+00 - total_loss: 62321.7859\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 4s 444ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0285 - factorized_top_k/top_10_categorical_accuracy: 0.0710 - factorized_top_k/top_50_categorical_accuracy: 0.3089 - factorized_top_k/top_100_categorical_accuracy: 0.4712 - loss: 62287.2987 - regularization_loss: 0.0000e+00 - total_loss: 62287.2987\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0289 - factorized_top_k/top_10_categorical_accuracy: 0.0711 - factorized_top_k/top_50_categorical_accuracy: 0.3092 - factorized_top_k/top_100_categorical_accuracy: 0.4725 - loss: 62262.5749 - regularization_loss: 0.0000e+00 - total_loss: 62262.5749\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0283 - factorized_top_k/top_10_categorical_accuracy: 0.0716 - factorized_top_k/top_50_categorical_accuracy: 0.3113 - factorized_top_k/top_100_categorical_accuracy: 0.4742 - loss: 62245.8416 - regularization_loss: 0.0000e+00 - total_loss: 62245.8416\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 4s 437ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0289 - factorized_top_k/top_10_categorical_accuracy: 0.0722 - factorized_top_k/top_50_categorical_accuracy: 0.3120 - factorized_top_k/top_100_categorical_accuracy: 0.4756 - loss: 62232.9975 - regularization_loss: 0.0000e+00 - total_loss: 62232.9975\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 5s 469ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0284 - factorized_top_k/top_10_categorical_accuracy: 0.0714 - factorized_top_k/top_50_categorical_accuracy: 0.3132 - factorized_top_k/top_100_categorical_accuracy: 0.4761 - loss: 62211.5444 - regularization_loss: 0.0000e+00 - total_loss: 62211.5444\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0289 - factorized_top_k/top_10_categorical_accuracy: 0.0718 - factorized_top_k/top_50_categorical_accuracy: 0.3140 - factorized_top_k/top_100_categorical_accuracy: 0.4777 - loss: 62197.2319 - regularization_loss: 0.0000e+00 - total_loss: 62197.2319\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 4s 450ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0284 - factorized_top_k/top_10_categorical_accuracy: 0.0716 - factorized_top_k/top_50_categorical_accuracy: 0.3158 - factorized_top_k/top_100_categorical_accuracy: 0.4784 - loss: 62177.4943 - regularization_loss: 0.0000e+00 - total_loss: 62177.4943\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0288 - factorized_top_k/top_10_categorical_accuracy: 0.0723 - factorized_top_k/top_50_categorical_accuracy: 0.3163 - factorized_top_k/top_100_categorical_accuracy: 0.4797 - loss: 62166.5611 - regularization_loss: 0.0000e+00 - total_loss: 62166.5611\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 4s 447ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0283 - factorized_top_k/top_10_categorical_accuracy: 0.0715 - factorized_top_k/top_50_categorical_accuracy: 0.3170 - factorized_top_k/top_100_categorical_accuracy: 0.4805 - loss: 62158.3011 - regularization_loss: 0.0000e+00 - total_loss: 62158.3011\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0284 - factorized_top_k/top_10_categorical_accuracy: 0.0715 - factorized_top_k/top_50_categorical_accuracy: 0.3181 - factorized_top_k/top_100_categorical_accuracy: 0.4811 - loss: 62147.0192 - regularization_loss: 0.0000e+00 - total_loss: 62147.0192\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0018 - factorized_top_k/top_5_categorical_accuracy: 0.0286 - factorized_top_k/top_10_categorical_accuracy: 0.0719 - factorized_top_k/top_50_categorical_accuracy: 0.3189 - factorized_top_k/top_100_categorical_accuracy: 0.4824 - loss: 62132.0018 - regularization_loss: 0.0000e+00 - total_loss: 62132.0018\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0289 - factorized_top_k/top_10_categorical_accuracy: 0.0718 - factorized_top_k/top_50_categorical_accuracy: 0.3190 - factorized_top_k/top_100_categorical_accuracy: 0.4828 - loss: 62126.4116 - regularization_loss: 0.0000e+00 - total_loss: 62126.4116\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0287 - factorized_top_k/top_10_categorical_accuracy: 0.0713 - factorized_top_k/top_50_categorical_accuracy: 0.3201 - factorized_top_k/top_100_categorical_accuracy: 0.4833 - loss: 62117.7585 - regularization_loss: 0.0000e+00 - total_loss: 62117.7585\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 5s 470ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0282 - factorized_top_k/top_10_categorical_accuracy: 0.0709 - factorized_top_k/top_50_categorical_accuracy: 0.3203 - factorized_top_k/top_100_categorical_accuracy: 0.4839 - loss: 62109.9031 - regularization_loss: 0.0000e+00 - total_loss: 62109.9031\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 4s 433ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0286 - factorized_top_k/top_10_categorical_accuracy: 0.0718 - factorized_top_k/top_50_categorical_accuracy: 0.3216 - factorized_top_k/top_100_categorical_accuracy: 0.4850 - loss: 62099.1584 - regularization_loss: 0.0000e+00 - total_loss: 62099.1584\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0288 - factorized_top_k/top_10_categorical_accuracy: 0.0714 - factorized_top_k/top_50_categorical_accuracy: 0.3218 - factorized_top_k/top_100_categorical_accuracy: 0.4852 - loss: 62085.4513 - regularization_loss: 0.0000e+00 - total_loss: 62085.4513\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 4s 438ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0280 - factorized_top_k/top_10_categorical_accuracy: 0.0717 - factorized_top_k/top_50_categorical_accuracy: 0.3224 - factorized_top_k/top_100_categorical_accuracy: 0.4858 - loss: 62074.7177 - regularization_loss: 0.0000e+00 - total_loss: 62074.7177\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 5s 446ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0283 - factorized_top_k/top_10_categorical_accuracy: 0.0714 - factorized_top_k/top_50_categorical_accuracy: 0.3217 - factorized_top_k/top_100_categorical_accuracy: 0.4863 - loss: 62072.0249 - regularization_loss: 0.0000e+00 - total_loss: 62072.0249\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0287 - factorized_top_k/top_10_categorical_accuracy: 0.0719 - factorized_top_k/top_50_categorical_accuracy: 0.3239 - factorized_top_k/top_100_categorical_accuracy: 0.4864 - loss: 62066.0316 - regularization_loss: 0.0000e+00 - total_loss: 62066.0316\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 4s 431ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0284 - factorized_top_k/top_10_categorical_accuracy: 0.0712 - factorized_top_k/top_50_categorical_accuracy: 0.3238 - factorized_top_k/top_100_categorical_accuracy: 0.4875 - loss: 62059.7504 - regularization_loss: 0.0000e+00 - total_loss: 62059.7504\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 437ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0279 - factorized_top_k/top_10_categorical_accuracy: 0.0715 - factorized_top_k/top_50_categorical_accuracy: 0.3244 - factorized_top_k/top_100_categorical_accuracy: 0.4870 - loss: 62050.8200 - regularization_loss: 0.0000e+00 - total_loss: 62050.8200\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0018 - factorized_top_k/top_5_categorical_accuracy: 0.0285 - factorized_top_k/top_10_categorical_accuracy: 0.0712 - factorized_top_k/top_50_categorical_accuracy: 0.3249 - factorized_top_k/top_100_categorical_accuracy: 0.4886 - loss: 62045.2603 - regularization_loss: 0.0000e+00 - total_loss: 62045.2603\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 437ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0284 - factorized_top_k/top_10_categorical_accuracy: 0.0718 - factorized_top_k/top_50_categorical_accuracy: 0.3258 - factorized_top_k/top_100_categorical_accuracy: 0.4883 - loss: 62038.4126 - regularization_loss: 0.0000e+00 - total_loss: 62038.4126\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 5s 462ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0280 - factorized_top_k/top_10_categorical_accuracy: 0.0709 - factorized_top_k/top_50_categorical_accuracy: 0.3258 - factorized_top_k/top_100_categorical_accuracy: 0.4895 - loss: 62033.7003 - regularization_loss: 0.0000e+00 - total_loss: 62033.7003\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 5s 466ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0280 - factorized_top_k/top_10_categorical_accuracy: 0.0717 - factorized_top_k/top_50_categorical_accuracy: 0.3269 - factorized_top_k/top_100_categorical_accuracy: 0.4892 - loss: 62027.2884 - regularization_loss: 0.0000e+00 - total_loss: 62027.2884\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 5s 471ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0280 - factorized_top_k/top_10_categorical_accuracy: 0.0713 - factorized_top_k/top_50_categorical_accuracy: 0.3262 - factorized_top_k/top_100_categorical_accuracy: 0.4896 - loss: 62023.4741 - regularization_loss: 0.0000e+00 - total_loss: 62023.4741\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 5s 483ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0282 - factorized_top_k/top_10_categorical_accuracy: 0.0716 - factorized_top_k/top_50_categorical_accuracy: 0.3273 - factorized_top_k/top_100_categorical_accuracy: 0.4897 - loss: 62013.0462 - regularization_loss: 0.0000e+00 - total_loss: 62013.0462\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 5s 473ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0283 - factorized_top_k/top_10_categorical_accuracy: 0.0717 - factorized_top_k/top_50_categorical_accuracy: 0.3275 - factorized_top_k/top_100_categorical_accuracy: 0.4906 - loss: 62012.7876 - regularization_loss: 0.0000e+00 - total_loss: 62012.7876\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 5s 471ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0277 - factorized_top_k/top_10_categorical_accuracy: 0.0718 - factorized_top_k/top_50_categorical_accuracy: 0.3277 - factorized_top_k/top_100_categorical_accuracy: 0.4905 - loss: 62001.3388 - regularization_loss: 0.0000e+00 - total_loss: 62001.3388\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0280 - factorized_top_k/top_10_categorical_accuracy: 0.0711 - factorized_top_k/top_50_categorical_accuracy: 0.3280 - factorized_top_k/top_100_categorical_accuracy: 0.4909 - loss: 62004.5966 - regularization_loss: 0.0000e+00 - total_loss: 62004.5966\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0277 - factorized_top_k/top_10_categorical_accuracy: 0.0718 - factorized_top_k/top_50_categorical_accuracy: 0.3285 - factorized_top_k/top_100_categorical_accuracy: 0.4915 - loss: 61999.8207 - regularization_loss: 0.0000e+00 - total_loss: 61999.8207\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0284 - factorized_top_k/top_10_categorical_accuracy: 0.0719 - factorized_top_k/top_50_categorical_accuracy: 0.3291 - factorized_top_k/top_100_categorical_accuracy: 0.4921 - loss: 61997.1712 - regularization_loss: 0.0000e+00 - total_loss: 61997.1712\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 4s 447ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0018 - factorized_top_k/top_5_categorical_accuracy: 0.0273 - factorized_top_k/top_10_categorical_accuracy: 0.0714 - factorized_top_k/top_50_categorical_accuracy: 0.3298 - factorized_top_k/top_100_categorical_accuracy: 0.4923 - loss: 61998.9698 - regularization_loss: 0.0000e+00 - total_loss: 61998.9698\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 4s 418ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0018 - factorized_top_k/top_5_categorical_accuracy: 0.0285 - factorized_top_k/top_10_categorical_accuracy: 0.0717 - factorized_top_k/top_50_categorical_accuracy: 0.3295 - factorized_top_k/top_100_categorical_accuracy: 0.4924 - loss: 61986.9901 - regularization_loss: 0.0000e+00 - total_loss: 61986.9901\n",
      "5/5 [==============================] - 2s 225ms/step - root_mean_squared_error: 1.1248 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0013 - factorized_top_k/top_50_categorical_accuracy: 0.0723 - factorized_top_k/top_100_categorical_accuracy: 0.1916 - loss: 34574.9095 - regularization_loss: 0.0000e+00 - total_loss: 34574.9095\n",
      "Retrieval top-100 accuracy: 0.192.\n",
      "Ranking RMSE: 1.125.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.1))\n",
    "model.fit(cached_train, epochs=50)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 5s 414ms/step - root_mean_squared_error: 2.2767 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0037 - factorized_top_k/top_50_categorical_accuracy: 0.0244 - factorized_top_k/top_100_categorical_accuracy: 0.0539 - loss: 70369.3061 - regularization_loss: 0.0000e+00 - total_loss: 70369.3061\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 4s 413ms/step - root_mean_squared_error: 1.3214 - factorized_top_k/top_1_categorical_accuracy: 8.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0141 - factorized_top_k/top_10_categorical_accuracy: 0.0327 - factorized_top_k/top_50_categorical_accuracy: 0.1530 - factorized_top_k/top_100_categorical_accuracy: 0.2665 - loss: 70130.6776 - regularization_loss: 0.0000e+00 - total_loss: 70130.6776\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 4s 414ms/step - root_mean_squared_error: 1.1260 - factorized_top_k/top_1_categorical_accuracy: 1.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0138 - factorized_top_k/top_10_categorical_accuracy: 0.0349 - factorized_top_k/top_50_categorical_accuracy: 0.1837 - factorized_top_k/top_100_categorical_accuracy: 0.3172 - loss: 69284.5341 - regularization_loss: 0.0000e+00 - total_loss: 69284.5341\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 4s 448ms/step - root_mean_squared_error: 1.0630 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0147 - factorized_top_k/top_10_categorical_accuracy: 0.0369 - factorized_top_k/top_50_categorical_accuracy: 0.1884 - factorized_top_k/top_100_categorical_accuracy: 0.3223 - loss: 67991.1406 - regularization_loss: 0.0000e+00 - total_loss: 67991.1406\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 1.0168 - factorized_top_k/top_1_categorical_accuracy: 2.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0195 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - factorized_top_k/top_50_categorical_accuracy: 0.1942 - factorized_top_k/top_100_categorical_accuracy: 0.3250 - loss: 66984.4908 - regularization_loss: 0.0000e+00 - total_loss: 66984.4908\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 5s 475ms/step - root_mean_squared_error: 1.0019 - factorized_top_k/top_1_categorical_accuracy: 1.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0215 - factorized_top_k/top_10_categorical_accuracy: 0.0461 - factorized_top_k/top_50_categorical_accuracy: 0.1928 - factorized_top_k/top_100_categorical_accuracy: 0.3203 - loss: 66280.6477 - regularization_loss: 0.0000e+00 - total_loss: 66280.6477\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 4s 437ms/step - root_mean_squared_error: 0.9899 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0478 - factorized_top_k/top_50_categorical_accuracy: 0.1962 - factorized_top_k/top_100_categorical_accuracy: 0.3239 - loss: 65752.5114 - regularization_loss: 0.0000e+00 - total_loss: 65752.5114\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 0.9761 - factorized_top_k/top_1_categorical_accuracy: 6.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0240 - factorized_top_k/top_10_categorical_accuracy: 0.0508 - factorized_top_k/top_50_categorical_accuracy: 0.2045 - factorized_top_k/top_100_categorical_accuracy: 0.3335 - loss: 65328.4432 - regularization_loss: 0.0000e+00 - total_loss: 65328.4432\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 5s 458ms/step - root_mean_squared_error: 0.9627 - factorized_top_k/top_1_categorical_accuracy: 6.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0251 - factorized_top_k/top_10_categorical_accuracy: 0.0529 - factorized_top_k/top_50_categorical_accuracy: 0.2120 - factorized_top_k/top_100_categorical_accuracy: 0.3420 - loss: 64968.8707 - regularization_loss: 0.0000e+00 - total_loss: 64968.8707\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 4s 430ms/step - root_mean_squared_error: 0.9513 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0270 - factorized_top_k/top_10_categorical_accuracy: 0.0564 - factorized_top_k/top_50_categorical_accuracy: 0.2177 - factorized_top_k/top_100_categorical_accuracy: 0.3488 - loss: 64656.4879 - regularization_loss: 0.0000e+00 - total_loss: 64656.4879\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 4s 434ms/step - root_mean_squared_error: 0.9440 - factorized_top_k/top_1_categorical_accuracy: 4.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0284 - factorized_top_k/top_10_categorical_accuracy: 0.0588 - factorized_top_k/top_50_categorical_accuracy: 0.2235 - factorized_top_k/top_100_categorical_accuracy: 0.3565 - loss: 64380.8629 - regularization_loss: 0.0000e+00 - total_loss: 64380.8629\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 0.9349 - factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0301 - factorized_top_k/top_10_categorical_accuracy: 0.0615 - factorized_top_k/top_50_categorical_accuracy: 0.2283 - factorized_top_k/top_100_categorical_accuracy: 0.3638 - loss: 64136.5334 - regularization_loss: 0.0000e+00 - total_loss: 64136.5334\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 4s 432ms/step - root_mean_squared_error: 0.9255 - factorized_top_k/top_1_categorical_accuracy: 5.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0309 - factorized_top_k/top_10_categorical_accuracy: 0.0625 - factorized_top_k/top_50_categorical_accuracy: 0.2330 - factorized_top_k/top_100_categorical_accuracy: 0.3702 - loss: 63920.6974 - regularization_loss: 0.0000e+00 - total_loss: 63920.6974\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 5s 466ms/step - root_mean_squared_error: 0.9206 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0314 - factorized_top_k/top_10_categorical_accuracy: 0.0635 - factorized_top_k/top_50_categorical_accuracy: 0.2368 - factorized_top_k/top_100_categorical_accuracy: 0.3758 - loss: 63730.7280 - regularization_loss: 0.0000e+00 - total_loss: 63730.7280\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 0.9256 - factorized_top_k/top_1_categorical_accuracy: 8.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0322 - factorized_top_k/top_10_categorical_accuracy: 0.0650 - factorized_top_k/top_50_categorical_accuracy: 0.2410 - factorized_top_k/top_100_categorical_accuracy: 0.3813 - loss: 63563.6016 - regularization_loss: 0.0000e+00 - total_loss: 63563.6016\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 4s 431ms/step - root_mean_squared_error: 0.9232 - factorized_top_k/top_1_categorical_accuracy: 7.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0326 - factorized_top_k/top_10_categorical_accuracy: 0.0654 - factorized_top_k/top_50_categorical_accuracy: 0.2450 - factorized_top_k/top_100_categorical_accuracy: 0.3860 - loss: 63416.3409 - regularization_loss: 0.0000e+00 - total_loss: 63416.3409\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 4s 437ms/step - root_mean_squared_error: 0.9076 - factorized_top_k/top_1_categorical_accuracy: 5.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0332 - factorized_top_k/top_10_categorical_accuracy: 0.0669 - factorized_top_k/top_50_categorical_accuracy: 0.2483 - factorized_top_k/top_100_categorical_accuracy: 0.3911 - loss: 63286.2159 - regularization_loss: 0.0000e+00 - total_loss: 63286.2159\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 440ms/step - root_mean_squared_error: 0.9021 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0340 - factorized_top_k/top_10_categorical_accuracy: 0.0685 - factorized_top_k/top_50_categorical_accuracy: 0.2515 - factorized_top_k/top_100_categorical_accuracy: 0.3959 - loss: 63170.6804 - regularization_loss: 0.0000e+00 - total_loss: 63170.6804\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 0.8962 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0345 - factorized_top_k/top_10_categorical_accuracy: 0.0694 - factorized_top_k/top_50_categorical_accuracy: 0.2550 - factorized_top_k/top_100_categorical_accuracy: 0.4008 - loss: 63067.4751 - regularization_loss: 0.0000e+00 - total_loss: 63067.4751\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 0.8934 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0349 - factorized_top_k/top_10_categorical_accuracy: 0.0705 - factorized_top_k/top_50_categorical_accuracy: 0.2585 - factorized_top_k/top_100_categorical_accuracy: 0.4054 - loss: 62974.7166 - regularization_loss: 0.0000e+00 - total_loss: 62974.7166\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 0.8933 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0351 - factorized_top_k/top_10_categorical_accuracy: 0.0711 - factorized_top_k/top_50_categorical_accuracy: 0.2611 - factorized_top_k/top_100_categorical_accuracy: 0.4090 - loss: 62890.8530 - regularization_loss: 0.0000e+00 - total_loss: 62890.8530\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 4s 437ms/step - root_mean_squared_error: 0.8954 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0357 - factorized_top_k/top_10_categorical_accuracy: 0.0721 - factorized_top_k/top_50_categorical_accuracy: 0.2640 - factorized_top_k/top_100_categorical_accuracy: 0.4128 - loss: 62814.6051 - regularization_loss: 0.0000e+00 - total_loss: 62814.6051\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 4s 445ms/step - root_mean_squared_error: 0.9047 - factorized_top_k/top_1_categorical_accuracy: 7.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0357 - factorized_top_k/top_10_categorical_accuracy: 0.0724 - factorized_top_k/top_50_categorical_accuracy: 0.2669 - factorized_top_k/top_100_categorical_accuracy: 0.4159 - loss: 62744.9013 - regularization_loss: 0.0000e+00 - total_loss: 62744.9013\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 0.8892 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0359 - factorized_top_k/top_10_categorical_accuracy: 0.0735 - factorized_top_k/top_50_categorical_accuracy: 0.2696 - factorized_top_k/top_100_categorical_accuracy: 0.4195 - loss: 62680.8349 - regularization_loss: 0.0000e+00 - total_loss: 62680.8349\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 0.8783 - factorized_top_k/top_1_categorical_accuracy: 9.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0364 - factorized_top_k/top_10_categorical_accuracy: 0.0739 - factorized_top_k/top_50_categorical_accuracy: 0.2720 - factorized_top_k/top_100_categorical_accuracy: 0.4223 - loss: 62621.7042 - regularization_loss: 0.0000e+00 - total_loss: 62621.7042\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 4s 447ms/step - root_mean_squared_error: 0.8739 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0366 - factorized_top_k/top_10_categorical_accuracy: 0.0744 - factorized_top_k/top_50_categorical_accuracy: 0.2740 - factorized_top_k/top_100_categorical_accuracy: 0.4250 - loss: 62566.9066 - regularization_loss: 0.0000e+00 - total_loss: 62566.9066\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 0.8724 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0369 - factorized_top_k/top_10_categorical_accuracy: 0.0751 - factorized_top_k/top_50_categorical_accuracy: 0.2758 - factorized_top_k/top_100_categorical_accuracy: 0.4275 - loss: 62515.9304 - regularization_loss: 0.0000e+00 - total_loss: 62515.9304\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 0.8693 - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0374 - factorized_top_k/top_10_categorical_accuracy: 0.0761 - factorized_top_k/top_50_categorical_accuracy: 0.2781 - factorized_top_k/top_100_categorical_accuracy: 0.4300 - loss: 62468.3285 - regularization_loss: 0.0000e+00 - total_loss: 62468.3285\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 0.8651 - factorized_top_k/top_1_categorical_accuracy: 8.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0372 - factorized_top_k/top_10_categorical_accuracy: 0.0759 - factorized_top_k/top_50_categorical_accuracy: 0.2794 - factorized_top_k/top_100_categorical_accuracy: 0.4326 - loss: 62423.7326 - regularization_loss: 0.0000e+00 - total_loss: 62423.7326\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 0.8640 - factorized_top_k/top_1_categorical_accuracy: 9.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0375 - factorized_top_k/top_10_categorical_accuracy: 0.0768 - factorized_top_k/top_50_categorical_accuracy: 0.2808 - factorized_top_k/top_100_categorical_accuracy: 0.4349 - loss: 62381.8445 - regularization_loss: 0.0000e+00 - total_loss: 62381.8445\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 4s 427ms/step - root_mean_squared_error: 0.8705 - factorized_top_k/top_1_categorical_accuracy: 8.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0378 - factorized_top_k/top_10_categorical_accuracy: 0.0775 - factorized_top_k/top_50_categorical_accuracy: 0.2826 - factorized_top_k/top_100_categorical_accuracy: 0.4372 - loss: 62342.3924 - regularization_loss: 0.0000e+00 - total_loss: 62342.3924\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 434ms/step - root_mean_squared_error: 0.8671 - factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0378 - factorized_top_k/top_10_categorical_accuracy: 0.0777 - factorized_top_k/top_50_categorical_accuracy: 0.2843 - factorized_top_k/top_100_categorical_accuracy: 0.4392 - loss: 62305.1282 - regularization_loss: 0.0000e+00 - total_loss: 62305.1282\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 5s 456ms/step - root_mean_squared_error: 0.8636 - factorized_top_k/top_1_categorical_accuracy: 8.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0381 - factorized_top_k/top_10_categorical_accuracy: 0.0781 - factorized_top_k/top_50_categorical_accuracy: 0.2860 - factorized_top_k/top_100_categorical_accuracy: 0.4412 - loss: 62269.8562 - regularization_loss: 0.0000e+00 - total_loss: 62269.8562\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 0.8638 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0385 - factorized_top_k/top_10_categorical_accuracy: 0.0786 - factorized_top_k/top_50_categorical_accuracy: 0.2873 - factorized_top_k/top_100_categorical_accuracy: 0.4429 - loss: 62236.4151 - regularization_loss: 0.0000e+00 - total_loss: 62236.4151\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 4s 440ms/step - root_mean_squared_error: 0.8773 - factorized_top_k/top_1_categorical_accuracy: 9.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0386 - factorized_top_k/top_10_categorical_accuracy: 0.0786 - factorized_top_k/top_50_categorical_accuracy: 0.2888 - factorized_top_k/top_100_categorical_accuracy: 0.4446 - loss: 62204.6555 - regularization_loss: 0.0000e+00 - total_loss: 62204.6555\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 439ms/step - root_mean_squared_error: 0.8824 - factorized_top_k/top_1_categorical_accuracy: 6.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0384 - factorized_top_k/top_10_categorical_accuracy: 0.0787 - factorized_top_k/top_50_categorical_accuracy: 0.2899 - factorized_top_k/top_100_categorical_accuracy: 0.4462 - loss: 62174.4205 - regularization_loss: 0.0000e+00 - total_loss: 62174.4205\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 5s 452ms/step - root_mean_squared_error: 0.8686 - factorized_top_k/top_1_categorical_accuracy: 6.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0385 - factorized_top_k/top_10_categorical_accuracy: 0.0791 - factorized_top_k/top_50_categorical_accuracy: 0.2914 - factorized_top_k/top_100_categorical_accuracy: 0.4476 - loss: 62145.5483 - regularization_loss: 0.0000e+00 - total_loss: 62145.5483\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 0.8495 - factorized_top_k/top_1_categorical_accuracy: 8.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0388 - factorized_top_k/top_10_categorical_accuracy: 0.0798 - factorized_top_k/top_50_categorical_accuracy: 0.2929 - factorized_top_k/top_100_categorical_accuracy: 0.4494 - loss: 62117.9790 - regularization_loss: 0.0000e+00 - total_loss: 62117.9790\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 0.8442 - factorized_top_k/top_1_categorical_accuracy: 6.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0390 - factorized_top_k/top_10_categorical_accuracy: 0.0801 - factorized_top_k/top_50_categorical_accuracy: 0.2937 - factorized_top_k/top_100_categorical_accuracy: 0.4508 - loss: 62091.6342 - regularization_loss: 0.0000e+00 - total_loss: 62091.6342\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 0.8375 - factorized_top_k/top_1_categorical_accuracy: 8.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0392 - factorized_top_k/top_10_categorical_accuracy: 0.0809 - factorized_top_k/top_50_categorical_accuracy: 0.2949 - factorized_top_k/top_100_categorical_accuracy: 0.4524 - loss: 62066.4066 - regularization_loss: 0.0000e+00 - total_loss: 62066.4066\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 0.8348 - factorized_top_k/top_1_categorical_accuracy: 8.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0395 - factorized_top_k/top_10_categorical_accuracy: 0.0815 - factorized_top_k/top_50_categorical_accuracy: 0.2962 - factorized_top_k/top_100_categorical_accuracy: 0.4538 - loss: 62042.2287 - regularization_loss: 0.0000e+00 - total_loss: 62042.2287\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 4s 432ms/step - root_mean_squared_error: 0.8325 - factorized_top_k/top_1_categorical_accuracy: 6.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0395 - factorized_top_k/top_10_categorical_accuracy: 0.0815 - factorized_top_k/top_50_categorical_accuracy: 0.2973 - factorized_top_k/top_100_categorical_accuracy: 0.4548 - loss: 62019.0202 - regularization_loss: 0.0000e+00 - total_loss: 62019.0202\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 4s 434ms/step - root_mean_squared_error: 0.8350 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0396 - factorized_top_k/top_10_categorical_accuracy: 0.0817 - factorized_top_k/top_50_categorical_accuracy: 0.2979 - factorized_top_k/top_100_categorical_accuracy: 0.4561 - loss: 61996.7212 - regularization_loss: 0.0000e+00 - total_loss: 61996.7212\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 4s 448ms/step - root_mean_squared_error: 0.8332 - factorized_top_k/top_1_categorical_accuracy: 6.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0398 - factorized_top_k/top_10_categorical_accuracy: 0.0821 - factorized_top_k/top_50_categorical_accuracy: 0.2992 - factorized_top_k/top_100_categorical_accuracy: 0.4571 - loss: 61975.2674 - regularization_loss: 0.0000e+00 - total_loss: 61975.2674\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 0.8867 - factorized_top_k/top_1_categorical_accuracy: 5.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0397 - factorized_top_k/top_10_categorical_accuracy: 0.0824 - factorized_top_k/top_50_categorical_accuracy: 0.2998 - factorized_top_k/top_100_categorical_accuracy: 0.4582 - loss: 61954.6847 - regularization_loss: 0.0000e+00 - total_loss: 61954.6847\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 5s 461ms/step - root_mean_squared_error: 0.8402 - factorized_top_k/top_1_categorical_accuracy: 5.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0397 - factorized_top_k/top_10_categorical_accuracy: 0.0828 - factorized_top_k/top_50_categorical_accuracy: 0.3009 - factorized_top_k/top_100_categorical_accuracy: 0.4595 - loss: 61934.6935 - regularization_loss: 0.0000e+00 - total_loss: 61934.6935\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 0.8354 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0402 - factorized_top_k/top_10_categorical_accuracy: 0.0832 - factorized_top_k/top_50_categorical_accuracy: 0.3023 - factorized_top_k/top_100_categorical_accuracy: 0.4605 - loss: 61915.4656 - regularization_loss: 0.0000e+00 - total_loss: 61915.4656\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 0.8314 - factorized_top_k/top_1_categorical_accuracy: 7.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0400 - factorized_top_k/top_10_categorical_accuracy: 0.0831 - factorized_top_k/top_50_categorical_accuracy: 0.3032 - factorized_top_k/top_100_categorical_accuracy: 0.4615 - loss: 61896.8949 - regularization_loss: 0.0000e+00 - total_loss: 61896.8949\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 4s 427ms/step - root_mean_squared_error: 0.8295 - factorized_top_k/top_1_categorical_accuracy: 6.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0404 - factorized_top_k/top_10_categorical_accuracy: 0.0834 - factorized_top_k/top_50_categorical_accuracy: 0.3039 - factorized_top_k/top_100_categorical_accuracy: 0.4629 - loss: 61878.9453 - regularization_loss: 0.0000e+00 - total_loss: 61878.9453\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 0.8265 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0410 - factorized_top_k/top_10_categorical_accuracy: 0.0838 - factorized_top_k/top_50_categorical_accuracy: 0.3049 - factorized_top_k/top_100_categorical_accuracy: 0.4638 - loss: 61861.5799 - regularization_loss: 0.0000e+00 - total_loss: 61861.5799\n",
      "5/5 [==============================] - 2s 231ms/step - root_mean_squared_error: 0.9412 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0012 - factorized_top_k/top_10_categorical_accuracy: 0.0035 - factorized_top_k/top_50_categorical_accuracy: 0.0654 - factorized_top_k/top_100_categorical_accuracy: 0.1764 - loss: 33075.6810 - regularization_loss: 0.0000e+00 - total_loss: 33075.6810\n",
      "Retrieval top-100 accuracy: 0.176.\n",
      "Ranking RMSE: 0.941.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01))\n",
    "model.fit(cached_train, epochs=50)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 5s 418ms/step - root_mean_squared_error: 3.5949 - factorized_top_k/top_1_categorical_accuracy: 1.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0021 - factorized_top_k/top_10_categorical_accuracy: 0.0049 - factorized_top_k/top_50_categorical_accuracy: 0.0280 - factorized_top_k/top_100_categorical_accuracy: 0.0565 - loss: 70380.5753 - regularization_loss: 0.0000e+00 - total_loss: 70380.5753\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 4s 451ms/step - root_mean_squared_error: 3.2253 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0033 - factorized_top_k/top_10_categorical_accuracy: 0.0077 - factorized_top_k/top_50_categorical_accuracy: 0.0393 - factorized_top_k/top_100_categorical_accuracy: 0.0746 - loss: 70372.5526 - regularization_loss: 0.0000e+00 - total_loss: 70372.5526\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 2.5284 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0054 - factorized_top_k/top_10_categorical_accuracy: 0.0108 - factorized_top_k/top_50_categorical_accuracy: 0.0505 - factorized_top_k/top_100_categorical_accuracy: 0.0943 - loss: 70363.4304 - regularization_loss: 0.0000e+00 - total_loss: 70363.4304\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 1.4925 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0077 - factorized_top_k/top_10_categorical_accuracy: 0.0155 - factorized_top_k/top_50_categorical_accuracy: 0.0661 - factorized_top_k/top_100_categorical_accuracy: 0.1191 - loss: 70352.8523 - regularization_loss: 0.0000e+00 - total_loss: 70352.8523\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 5s 461ms/step - root_mean_squared_error: 1.2392 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0108 - factorized_top_k/top_10_categorical_accuracy: 0.0223 - factorized_top_k/top_50_categorical_accuracy: 0.0871 - factorized_top_k/top_100_categorical_accuracy: 0.1504 - loss: 70342.8594 - regularization_loss: 0.0000e+00 - total_loss: 70342.8594\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 4s 434ms/step - root_mean_squared_error: 1.1368 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0159 - factorized_top_k/top_10_categorical_accuracy: 0.0310 - factorized_top_k/top_50_categorical_accuracy: 0.1154 - factorized_top_k/top_100_categorical_accuracy: 0.1924 - loss: 70328.3267 - regularization_loss: 0.0000e+00 - total_loss: 70328.3267\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 4s 427ms/step - root_mean_squared_error: 1.0833 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0204 - factorized_top_k/top_10_categorical_accuracy: 0.0404 - factorized_top_k/top_50_categorical_accuracy: 0.1488 - factorized_top_k/top_100_categorical_accuracy: 0.2416 - loss: 70306.1158 - regularization_loss: 0.0000e+00 - total_loss: 70306.1158\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 4s 430ms/step - root_mean_squared_error: 1.0633 - factorized_top_k/top_1_categorical_accuracy: 1.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0237 - factorized_top_k/top_10_categorical_accuracy: 0.0473 - factorized_top_k/top_50_categorical_accuracy: 0.1811 - factorized_top_k/top_100_categorical_accuracy: 0.2879 - loss: 70272.3267 - regularization_loss: 0.0000e+00 - total_loss: 70272.3267\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 1.0584 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0254 - factorized_top_k/top_10_categorical_accuracy: 0.0517 - factorized_top_k/top_50_categorical_accuracy: 0.2019 - factorized_top_k/top_100_categorical_accuracy: 0.3234 - loss: 70222.7003 - regularization_loss: 0.0000e+00 - total_loss: 70222.7003\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 1.0469 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0257 - factorized_top_k/top_10_categorical_accuracy: 0.0531 - factorized_top_k/top_50_categorical_accuracy: 0.2133 - factorized_top_k/top_100_categorical_accuracy: 0.3412 - loss: 70153.1584 - regularization_loss: 0.0000e+00 - total_loss: 70153.1584\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 4s 432ms/step - root_mean_squared_error: 1.0400 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0255 - factorized_top_k/top_10_categorical_accuracy: 0.0533 - factorized_top_k/top_50_categorical_accuracy: 0.2171 - factorized_top_k/top_100_categorical_accuracy: 0.3496 - loss: 70060.6839 - regularization_loss: 0.0000e+00 - total_loss: 70060.6839\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.0355 - factorized_top_k/top_1_categorical_accuracy: 2.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0262 - factorized_top_k/top_10_categorical_accuracy: 0.0538 - factorized_top_k/top_50_categorical_accuracy: 0.2195 - factorized_top_k/top_100_categorical_accuracy: 0.3518 - loss: 69944.0227 - regularization_loss: 0.0000e+00 - total_loss: 69944.0227\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 5s 465ms/step - root_mean_squared_error: 1.0304 - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0257 - factorized_top_k/top_10_categorical_accuracy: 0.0532 - factorized_top_k/top_50_categorical_accuracy: 0.2186 - factorized_top_k/top_100_categorical_accuracy: 0.3518 - loss: 69804.0909 - regularization_loss: 0.0000e+00 - total_loss: 69804.0909\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 4s 441ms/step - root_mean_squared_error: 1.0260 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0258 - factorized_top_k/top_10_categorical_accuracy: 0.0531 - factorized_top_k/top_50_categorical_accuracy: 0.2168 - factorized_top_k/top_100_categorical_accuracy: 0.3510 - loss: 69643.9624 - regularization_loss: 0.0000e+00 - total_loss: 69643.9624\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 4s 430ms/step - root_mean_squared_error: 1.0217 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0252 - factorized_top_k/top_10_categorical_accuracy: 0.0525 - factorized_top_k/top_50_categorical_accuracy: 0.2145 - factorized_top_k/top_100_categorical_accuracy: 0.3484 - loss: 69468.4126 - regularization_loss: 0.0000e+00 - total_loss: 69468.4126\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 5s 460ms/step - root_mean_squared_error: 1.0177 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0248 - factorized_top_k/top_10_categorical_accuracy: 0.0525 - factorized_top_k/top_50_categorical_accuracy: 0.2138 - factorized_top_k/top_100_categorical_accuracy: 0.3465 - loss: 69283.1129 - regularization_loss: 0.0000e+00 - total_loss: 69283.1129\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 1.0139 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0246 - factorized_top_k/top_10_categorical_accuracy: 0.0520 - factorized_top_k/top_50_categorical_accuracy: 0.2120 - factorized_top_k/top_100_categorical_accuracy: 0.3441 - loss: 69093.7670 - regularization_loss: 0.0000e+00 - total_loss: 69093.7670\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 1.0102 - factorized_top_k/top_1_categorical_accuracy: 4.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0252 - factorized_top_k/top_10_categorical_accuracy: 0.0530 - factorized_top_k/top_50_categorical_accuracy: 0.2123 - factorized_top_k/top_100_categorical_accuracy: 0.3430 - loss: 68905.3764 - regularization_loss: 0.0000e+00 - total_loss: 68905.3764\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 1.0071 - factorized_top_k/top_1_categorical_accuracy: 2.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0254 - factorized_top_k/top_10_categorical_accuracy: 0.0524 - factorized_top_k/top_50_categorical_accuracy: 0.2108 - factorized_top_k/top_100_categorical_accuracy: 0.3407 - loss: 68721.7855 - regularization_loss: 0.0000e+00 - total_loss: 68721.7855\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 5s 483ms/step - root_mean_squared_error: 1.0044 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0245 - factorized_top_k/top_10_categorical_accuracy: 0.0516 - factorized_top_k/top_50_categorical_accuracy: 0.2095 - factorized_top_k/top_100_categorical_accuracy: 0.3378 - loss: 68545.6101 - regularization_loss: 0.0000e+00 - total_loss: 68545.6101\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 5s 465ms/step - root_mean_squared_error: 1.0017 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0247 - factorized_top_k/top_10_categorical_accuracy: 0.0513 - factorized_top_k/top_50_categorical_accuracy: 0.2087 - factorized_top_k/top_100_categorical_accuracy: 0.3364 - loss: 68378.3523 - regularization_loss: 0.0000e+00 - total_loss: 68378.3523\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 5s 450ms/step - root_mean_squared_error: 0.9992 - factorized_top_k/top_1_categorical_accuracy: 2.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0250 - factorized_top_k/top_10_categorical_accuracy: 0.0512 - factorized_top_k/top_50_categorical_accuracy: 0.2080 - factorized_top_k/top_100_categorical_accuracy: 0.3352 - loss: 68220.6683 - regularization_loss: 0.0000e+00 - total_loss: 68220.6683\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 4s 446ms/step - root_mean_squared_error: 0.9967 - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0246 - factorized_top_k/top_10_categorical_accuracy: 0.0510 - factorized_top_k/top_50_categorical_accuracy: 0.2067 - factorized_top_k/top_100_categorical_accuracy: 0.3336 - loss: 68072.6193 - regularization_loss: 0.0000e+00 - total_loss: 68072.6193\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 4s 443ms/step - root_mean_squared_error: 0.9942 - factorized_top_k/top_1_categorical_accuracy: 1.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0244 - factorized_top_k/top_10_categorical_accuracy: 0.0507 - factorized_top_k/top_50_categorical_accuracy: 0.2052 - factorized_top_k/top_100_categorical_accuracy: 0.3320 - loss: 67933.8743 - regularization_loss: 0.0000e+00 - total_loss: 67933.8743\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 0.9917 - factorized_top_k/top_1_categorical_accuracy: 2.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0504 - factorized_top_k/top_50_categorical_accuracy: 0.2041 - factorized_top_k/top_100_categorical_accuracy: 0.3303 - loss: 67803.8558 - regularization_loss: 0.0000e+00 - total_loss: 67803.8558\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 0.9892 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0239 - factorized_top_k/top_10_categorical_accuracy: 0.0498 - factorized_top_k/top_50_categorical_accuracy: 0.2027 - factorized_top_k/top_100_categorical_accuracy: 0.3294 - loss: 67681.8786 - regularization_loss: 0.0000e+00 - total_loss: 67681.8786\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 0.9867 - factorized_top_k/top_1_categorical_accuracy: 2.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0499 - factorized_top_k/top_50_categorical_accuracy: 0.2027 - factorized_top_k/top_100_categorical_accuracy: 0.3288 - loss: 67567.1953 - regularization_loss: 0.0000e+00 - total_loss: 67567.1953\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 4s 440ms/step - root_mean_squared_error: 0.9843 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0235 - factorized_top_k/top_10_categorical_accuracy: 0.0492 - factorized_top_k/top_50_categorical_accuracy: 0.2019 - factorized_top_k/top_100_categorical_accuracy: 0.3274 - loss: 67459.0639 - regularization_loss: 0.0000e+00 - total_loss: 67459.0639\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 0.9819 - factorized_top_k/top_1_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0236 - factorized_top_k/top_10_categorical_accuracy: 0.0490 - factorized_top_k/top_50_categorical_accuracy: 0.2022 - factorized_top_k/top_100_categorical_accuracy: 0.3275 - loss: 67356.7855 - regularization_loss: 0.0000e+00 - total_loss: 67356.7855\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 446ms/step - root_mean_squared_error: 0.9795 - factorized_top_k/top_1_categorical_accuracy: 1.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0489 - factorized_top_k/top_50_categorical_accuracy: 0.2021 - factorized_top_k/top_100_categorical_accuracy: 0.3265 - loss: 67259.7159 - regularization_loss: 0.0000e+00 - total_loss: 67259.7159\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 4s 437ms/step - root_mean_squared_error: 0.9772 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0490 - factorized_top_k/top_50_categorical_accuracy: 0.2013 - factorized_top_k/top_100_categorical_accuracy: 0.3259 - loss: 67167.2741 - regularization_loss: 0.0000e+00 - total_loss: 67167.2741\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 429ms/step - root_mean_squared_error: 0.9748 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0490 - factorized_top_k/top_50_categorical_accuracy: 0.2015 - factorized_top_k/top_100_categorical_accuracy: 0.3262 - loss: 67078.9567 - regularization_loss: 0.0000e+00 - total_loss: 67078.9567\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 4s 448ms/step - root_mean_squared_error: 0.9726 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0488 - factorized_top_k/top_50_categorical_accuracy: 0.2016 - factorized_top_k/top_100_categorical_accuracy: 0.3261 - loss: 66994.3175 - regularization_loss: 0.0000e+00 - total_loss: 66994.3175\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 0.9703 - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0231 - factorized_top_k/top_10_categorical_accuracy: 0.0494 - factorized_top_k/top_50_categorical_accuracy: 0.2017 - factorized_top_k/top_100_categorical_accuracy: 0.3262 - loss: 66912.9815 - regularization_loss: 0.0000e+00 - total_loss: 66912.9815\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 0.9680 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0488 - factorized_top_k/top_50_categorical_accuracy: 0.2016 - factorized_top_k/top_100_categorical_accuracy: 0.3262 - loss: 66834.6378 - regularization_loss: 0.0000e+00 - total_loss: 66834.6378\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 0.9658 - factorized_top_k/top_1_categorical_accuracy: 3.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0235 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - factorized_top_k/top_50_categorical_accuracy: 0.2024 - factorized_top_k/top_100_categorical_accuracy: 0.3270 - loss: 66759.0114 - regularization_loss: 0.0000e+00 - total_loss: 66759.0114\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 5s 459ms/step - root_mean_squared_error: 0.9635 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0233 - factorized_top_k/top_10_categorical_accuracy: 0.0493 - factorized_top_k/top_50_categorical_accuracy: 0.2023 - factorized_top_k/top_100_categorical_accuracy: 0.3272 - loss: 66685.8885 - regularization_loss: 0.0000e+00 - total_loss: 66685.8885\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 0.9613 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0237 - factorized_top_k/top_10_categorical_accuracy: 0.0498 - factorized_top_k/top_50_categorical_accuracy: 0.2025 - factorized_top_k/top_100_categorical_accuracy: 0.3275 - loss: 66615.0774 - regularization_loss: 0.0000e+00 - total_loss: 66615.0774\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 447ms/step - root_mean_squared_error: 0.9591 - factorized_top_k/top_1_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0238 - factorized_top_k/top_10_categorical_accuracy: 0.0502 - factorized_top_k/top_50_categorical_accuracy: 0.2030 - factorized_top_k/top_100_categorical_accuracy: 0.3276 - loss: 66546.4304 - regularization_loss: 0.0000e+00 - total_loss: 66546.4304\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 0.9569 - factorized_top_k/top_1_categorical_accuracy: 1.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0238 - factorized_top_k/top_10_categorical_accuracy: 0.0505 - factorized_top_k/top_50_categorical_accuracy: 0.2035 - factorized_top_k/top_100_categorical_accuracy: 0.3281 - loss: 66479.8153 - regularization_loss: 0.0000e+00 - total_loss: 66479.8153\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 4s 439ms/step - root_mean_squared_error: 0.9547 - factorized_top_k/top_1_categorical_accuracy: 1.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0508 - factorized_top_k/top_50_categorical_accuracy: 0.2040 - factorized_top_k/top_100_categorical_accuracy: 0.3288 - loss: 66415.1214 - regularization_loss: 0.0000e+00 - total_loss: 66415.1214\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 4s 449ms/step - root_mean_squared_error: 0.9525 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0509 - factorized_top_k/top_50_categorical_accuracy: 0.2043 - factorized_top_k/top_100_categorical_accuracy: 0.3294 - loss: 66352.2543 - regularization_loss: 0.0000e+00 - total_loss: 66352.2543\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 4s 445ms/step - root_mean_squared_error: 0.9504 - factorized_top_k/top_1_categorical_accuracy: 1.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0242 - factorized_top_k/top_10_categorical_accuracy: 0.0513 - factorized_top_k/top_50_categorical_accuracy: 0.2049 - factorized_top_k/top_100_categorical_accuracy: 0.3300 - loss: 66291.1243 - regularization_loss: 0.0000e+00 - total_loss: 66291.1243\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 0.9483 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0245 - factorized_top_k/top_10_categorical_accuracy: 0.0511 - factorized_top_k/top_50_categorical_accuracy: 0.2044 - factorized_top_k/top_100_categorical_accuracy: 0.3305 - loss: 66231.6534 - regularization_loss: 0.0000e+00 - total_loss: 66231.6534\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 4s 440ms/step - root_mean_squared_error: 0.9462 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0248 - factorized_top_k/top_10_categorical_accuracy: 0.0518 - factorized_top_k/top_50_categorical_accuracy: 0.2052 - factorized_top_k/top_100_categorical_accuracy: 0.3311 - loss: 66173.7678 - regularization_loss: 0.0000e+00 - total_loss: 66173.7678\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 5s 462ms/step - root_mean_squared_error: 0.9440 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0249 - factorized_top_k/top_10_categorical_accuracy: 0.0522 - factorized_top_k/top_50_categorical_accuracy: 0.2056 - factorized_top_k/top_100_categorical_accuracy: 0.3320 - loss: 66117.3935 - regularization_loss: 0.0000e+00 - total_loss: 66117.3935\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 5s 457ms/step - root_mean_squared_error: 0.9418 - factorized_top_k/top_1_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0249 - factorized_top_k/top_10_categorical_accuracy: 0.0522 - factorized_top_k/top_50_categorical_accuracy: 0.2060 - factorized_top_k/top_100_categorical_accuracy: 0.3328 - loss: 66062.4588 - regularization_loss: 0.0000e+00 - total_loss: 66062.4588\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 5s 472ms/step - root_mean_squared_error: 0.9396 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0249 - factorized_top_k/top_10_categorical_accuracy: 0.0523 - factorized_top_k/top_50_categorical_accuracy: 0.2062 - factorized_top_k/top_100_categorical_accuracy: 0.3336 - loss: 66008.9055 - regularization_loss: 0.0000e+00 - total_loss: 66008.9055\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 5s 471ms/step - root_mean_squared_error: 0.9374 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0251 - factorized_top_k/top_10_categorical_accuracy: 0.0528 - factorized_top_k/top_50_categorical_accuracy: 0.2061 - factorized_top_k/top_100_categorical_accuracy: 0.3343 - loss: 65956.6612 - regularization_loss: 0.0000e+00 - total_loss: 65956.6612\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 0.9351 - factorized_top_k/top_1_categorical_accuracy: 4.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0254 - factorized_top_k/top_10_categorical_accuracy: 0.0533 - factorized_top_k/top_50_categorical_accuracy: 0.2070 - factorized_top_k/top_100_categorical_accuracy: 0.3352 - loss: 65905.6612 - regularization_loss: 0.0000e+00 - total_loss: 65905.6612\n",
      "5/5 [==============================] - 2s 226ms/step - root_mean_squared_error: 0.9521 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0096 - factorized_top_k/top_10_categorical_accuracy: 0.0218 - factorized_top_k/top_50_categorical_accuracy: 0.1216 - factorized_top_k/top_100_categorical_accuracy: 0.2312 - loss: 31111.3271 - regularization_loss: 0.0000e+00 - total_loss: 31111.3271\n",
      "Retrieval top-100 accuracy: 0.231.\n",
      "Ranking RMSE: 0.952.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "adamOhOhOne = model.fit(cached_train, epochs=50)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "\n",
    "#*****************************\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>factorized_top_k/top_1_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_5_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_10_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_50_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_100_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>regularization_loss</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.569984</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.028413</td>\n",
       "      <td>0.057937</td>\n",
       "      <td>54854.332031</td>\n",
       "      <td>0</td>\n",
       "      <td>54854.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.125036</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.039437</td>\n",
       "      <td>0.076537</td>\n",
       "      <td>54847.378906</td>\n",
       "      <td>0</td>\n",
       "      <td>54847.378906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.264843</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.050925</td>\n",
       "      <td>0.095875</td>\n",
       "      <td>54838.175781</td>\n",
       "      <td>0</td>\n",
       "      <td>54838.175781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.284054</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.066375</td>\n",
       "      <td>0.120325</td>\n",
       "      <td>54831.042969</td>\n",
       "      <td>0</td>\n",
       "      <td>54831.042969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.282530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>0.022412</td>\n",
       "      <td>0.089175</td>\n",
       "      <td>0.149725</td>\n",
       "      <td>54822.332031</td>\n",
       "      <td>0</td>\n",
       "      <td>54822.332031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.100013</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.015650</td>\n",
       "      <td>0.030963</td>\n",
       "      <td>0.116125</td>\n",
       "      <td>0.190388</td>\n",
       "      <td>54809.097656</td>\n",
       "      <td>0</td>\n",
       "      <td>54809.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.090638</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.020188</td>\n",
       "      <td>0.040650</td>\n",
       "      <td>0.148388</td>\n",
       "      <td>0.237538</td>\n",
       "      <td>54788.785156</td>\n",
       "      <td>0</td>\n",
       "      <td>54788.785156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.069134</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.023675</td>\n",
       "      <td>0.048637</td>\n",
       "      <td>0.180425</td>\n",
       "      <td>0.283475</td>\n",
       "      <td>54758.261719</td>\n",
       "      <td>0</td>\n",
       "      <td>54758.261719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.059724</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.025888</td>\n",
       "      <td>0.053025</td>\n",
       "      <td>0.202150</td>\n",
       "      <td>0.318363</td>\n",
       "      <td>54714.082031</td>\n",
       "      <td>0</td>\n",
       "      <td>54714.082031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.047601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025725</td>\n",
       "      <td>0.053112</td>\n",
       "      <td>0.211087</td>\n",
       "      <td>0.336163</td>\n",
       "      <td>54653.179688</td>\n",
       "      <td>0</td>\n",
       "      <td>54653.179688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.040850</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.027113</td>\n",
       "      <td>0.055037</td>\n",
       "      <td>0.217525</td>\n",
       "      <td>0.347712</td>\n",
       "      <td>54573.363281</td>\n",
       "      <td>0</td>\n",
       "      <td>54573.363281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.034473</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.025937</td>\n",
       "      <td>0.054075</td>\n",
       "      <td>0.215375</td>\n",
       "      <td>0.349125</td>\n",
       "      <td>54473.867188</td>\n",
       "      <td>0</td>\n",
       "      <td>54473.867188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    root_mean_squared_error  factorized_top_k/top_1_categorical_accuracy  \\\n",
       "0                  3.569984                                     0.000112   \n",
       "1                  3.125036                                     0.000087   \n",
       "2                  2.264843                                     0.000012   \n",
       "3                  1.284054                                     0.000025   \n",
       "4                  1.282530                                     0.000000   \n",
       "5                  1.100013                                     0.000050   \n",
       "6                  1.090638                                     0.000112   \n",
       "7                  1.069134                                     0.000225   \n",
       "8                  1.059724                                     0.000762   \n",
       "9                  1.047601                                     0.000000   \n",
       "10                 1.040850                                     0.000762   \n",
       "11                 1.034473                                     0.000012   \n",
       "\n",
       "    factorized_top_k/top_5_categorical_accuracy  \\\n",
       "0                                      0.002650   \n",
       "1                                      0.003975   \n",
       "2                                      0.005675   \n",
       "3                                      0.008375   \n",
       "4                                      0.011475   \n",
       "5                                      0.015650   \n",
       "6                                      0.020188   \n",
       "7                                      0.023675   \n",
       "8                                      0.025888   \n",
       "9                                      0.025725   \n",
       "10                                     0.027113   \n",
       "11                                     0.025937   \n",
       "\n",
       "    factorized_top_k/top_10_categorical_accuracy  \\\n",
       "0                                       0.005700   \n",
       "1                                       0.008750   \n",
       "2                                       0.011700   \n",
       "3                                       0.016425   \n",
       "4                                       0.022412   \n",
       "5                                       0.030963   \n",
       "6                                       0.040650   \n",
       "7                                       0.048637   \n",
       "8                                       0.053025   \n",
       "9                                       0.053112   \n",
       "10                                      0.055037   \n",
       "11                                      0.054075   \n",
       "\n",
       "    factorized_top_k/top_50_categorical_accuracy  \\\n",
       "0                                       0.028413   \n",
       "1                                       0.039437   \n",
       "2                                       0.050925   \n",
       "3                                       0.066375   \n",
       "4                                       0.089175   \n",
       "5                                       0.116125   \n",
       "6                                       0.148388   \n",
       "7                                       0.180425   \n",
       "8                                       0.202150   \n",
       "9                                       0.211087   \n",
       "10                                      0.217525   \n",
       "11                                      0.215375   \n",
       "\n",
       "    factorized_top_k/top_100_categorical_accuracy          loss  \\\n",
       "0                                        0.057937  54854.332031   \n",
       "1                                        0.076537  54847.378906   \n",
       "2                                        0.095875  54838.175781   \n",
       "3                                        0.120325  54831.042969   \n",
       "4                                        0.149725  54822.332031   \n",
       "5                                        0.190388  54809.097656   \n",
       "6                                        0.237538  54788.785156   \n",
       "7                                        0.283475  54758.261719   \n",
       "8                                        0.318363  54714.082031   \n",
       "9                                        0.336163  54653.179688   \n",
       "10                                       0.347712  54573.363281   \n",
       "11                                       0.349125  54473.867188   \n",
       "\n",
       "    regularization_loss    total_loss  \n",
       "0                     0  54854.332031  \n",
       "1                     0  54847.378906  \n",
       "2                     0  54838.175781  \n",
       "3                     0  54831.042969  \n",
       "4                     0  54822.332031  \n",
       "5                     0  54809.097656  \n",
       "6                     0  54788.785156  \n",
       "7                     0  54758.261719  \n",
       "8                     0  54714.082031  \n",
       "9                     0  54653.179688  \n",
       "10                    0  54573.363281  \n",
       "11                    0  54473.867188  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adamOhOhOne = pd.DataFrame(adamOhOhOne.history)\n",
    "adamOhOhOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 6s 438ms/step - root_mean_squared_error: 3.3250 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0023 - factorized_top_k/top_10_categorical_accuracy: 0.0049 - factorized_top_k/top_50_categorical_accuracy: 0.0278 - factorized_top_k/top_100_categorical_accuracy: 0.0581 - loss: 70378.5973 - regularization_loss: 0.0000e+00 - total_loss: 70378.5973\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 4s 440ms/step - root_mean_squared_error: 2.1429 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0041 - factorized_top_k/top_10_categorical_accuracy: 0.0088 - factorized_top_k/top_50_categorical_accuracy: 0.0440 - factorized_top_k/top_100_categorical_accuracy: 0.0841 - loss: 70364.7109 - regularization_loss: 0.0000e+00 - total_loss: 70364.7109\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 4s 445ms/step - root_mean_squared_error: 1.2328 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0068 - factorized_top_k/top_10_categorical_accuracy: 0.0145 - factorized_top_k/top_50_categorical_accuracy: 0.0628 - factorized_top_k/top_100_categorical_accuracy: 0.1135 - loss: 70354.1946 - regularization_loss: 0.0000e+00 - total_loss: 70354.1946\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 4s 436ms/step - root_mean_squared_error: 1.1075 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0113 - factorized_top_k/top_10_categorical_accuracy: 0.0222 - factorized_top_k/top_50_categorical_accuracy: 0.0900 - factorized_top_k/top_100_categorical_accuracy: 0.1534 - loss: 70342.5419 - regularization_loss: 0.0000e+00 - total_loss: 70342.5419\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 1.0810 - factorized_top_k/top_1_categorical_accuracy: 3.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0162 - factorized_top_k/top_10_categorical_accuracy: 0.0317 - factorized_top_k/top_50_categorical_accuracy: 0.1251 - factorized_top_k/top_100_categorical_accuracy: 0.2063 - loss: 70324.9979 - regularization_loss: 0.0000e+00 - total_loss: 70324.9979\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 4s 438ms/step - root_mean_squared_error: 1.0648 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0193 - factorized_top_k/top_10_categorical_accuracy: 0.0392 - factorized_top_k/top_50_categorical_accuracy: 0.1562 - factorized_top_k/top_100_categorical_accuracy: 0.2552 - loss: 70299.2869 - regularization_loss: 0.0000e+00 - total_loss: 70299.2869\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 1.0557 - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0443 - factorized_top_k/top_50_categorical_accuracy: 0.1799 - factorized_top_k/top_100_categorical_accuracy: 0.2938 - loss: 70263.9403 - regularization_loss: 0.0000e+00 - total_loss: 70263.9403\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 4s 450ms/step - root_mean_squared_error: 1.0505 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0224 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - factorized_top_k/top_50_categorical_accuracy: 0.1926 - factorized_top_k/top_100_categorical_accuracy: 0.3155 - loss: 70218.1925 - regularization_loss: 0.0000e+00 - total_loss: 70218.1925\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 4s 436ms/step - root_mean_squared_error: 1.0455 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0473 - factorized_top_k/top_50_categorical_accuracy: 0.1982 - factorized_top_k/top_100_categorical_accuracy: 0.3262 - loss: 70161.9482 - regularization_loss: 0.0000e+00 - total_loss: 70161.9482\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 4s 431ms/step - root_mean_squared_error: 1.0389 - factorized_top_k/top_1_categorical_accuracy: 1.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0234 - factorized_top_k/top_10_categorical_accuracy: 0.0488 - factorized_top_k/top_50_categorical_accuracy: 0.2029 - factorized_top_k/top_100_categorical_accuracy: 0.3325 - loss: 70095.5803 - regularization_loss: 0.0000e+00 - total_loss: 70095.5803\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 1.0344 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0234 - factorized_top_k/top_10_categorical_accuracy: 0.0489 - factorized_top_k/top_50_categorical_accuracy: 0.2047 - factorized_top_k/top_100_categorical_accuracy: 0.3354 - loss: 70019.8239 - regularization_loss: 0.0000e+00 - total_loss: 70019.8239\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 4s 428ms/step - root_mean_squared_error: 1.0314 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0236 - factorized_top_k/top_10_categorical_accuracy: 0.0499 - factorized_top_k/top_50_categorical_accuracy: 0.2046 - factorized_top_k/top_100_categorical_accuracy: 0.3362 - loss: 69935.6385 - regularization_loss: 0.0000e+00 - total_loss: 69935.6385\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 4s 433ms/step - root_mean_squared_error: 1.0282 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0231 - factorized_top_k/top_10_categorical_accuracy: 0.0497 - factorized_top_k/top_50_categorical_accuracy: 0.2048 - factorized_top_k/top_100_categorical_accuracy: 0.3364 - loss: 69844.1250 - regularization_loss: 0.0000e+00 - total_loss: 69844.1250\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 1.0251 - factorized_top_k/top_1_categorical_accuracy: 1.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0233 - factorized_top_k/top_10_categorical_accuracy: 0.0500 - factorized_top_k/top_50_categorical_accuracy: 0.2046 - factorized_top_k/top_100_categorical_accuracy: 0.3366 - loss: 69746.4673 - regularization_loss: 0.0000e+00 - total_loss: 69746.4673\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 1.0226 - factorized_top_k/top_1_categorical_accuracy: 2.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0237 - factorized_top_k/top_10_categorical_accuracy: 0.0504 - factorized_top_k/top_50_categorical_accuracy: 0.2045 - factorized_top_k/top_100_categorical_accuracy: 0.3359 - loss: 69643.8771 - regularization_loss: 0.0000e+00 - total_loss: 69643.8771\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 1.0215 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0497 - factorized_top_k/top_50_categorical_accuracy: 0.2024 - factorized_top_k/top_100_categorical_accuracy: 0.3342 - loss: 69537.5582 - regularization_loss: 0.0000e+00 - total_loss: 69537.5582\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 1.0207 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0234 - factorized_top_k/top_10_categorical_accuracy: 0.0495 - factorized_top_k/top_50_categorical_accuracy: 0.2023 - factorized_top_k/top_100_categorical_accuracy: 0.3334 - loss: 69428.6513 - regularization_loss: 0.0000e+00 - total_loss: 69428.6513\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 469ms/step - root_mean_squared_error: 1.0177 - factorized_top_k/top_1_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0233 - factorized_top_k/top_10_categorical_accuracy: 0.0494 - factorized_top_k/top_50_categorical_accuracy: 0.2019 - factorized_top_k/top_100_categorical_accuracy: 0.3323 - loss: 69318.1960 - regularization_loss: 0.0000e+00 - total_loss: 69318.1960\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 5s 461ms/step - root_mean_squared_error: 1.0176 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0492 - factorized_top_k/top_50_categorical_accuracy: 0.2016 - factorized_top_k/top_100_categorical_accuracy: 0.3307 - loss: 69207.1697 - regularization_loss: 0.0000e+00 - total_loss: 69207.1697\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 5s 460ms/step - root_mean_squared_error: 1.0133 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0229 - factorized_top_k/top_10_categorical_accuracy: 0.0491 - factorized_top_k/top_50_categorical_accuracy: 0.2008 - factorized_top_k/top_100_categorical_accuracy: 0.3294 - loss: 69096.3636 - regularization_loss: 0.0000e+00 - total_loss: 69096.3636\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 5s 449ms/step - root_mean_squared_error: 1.0130 - factorized_top_k/top_1_categorical_accuracy: 8.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0486 - factorized_top_k/top_50_categorical_accuracy: 0.2002 - factorized_top_k/top_100_categorical_accuracy: 0.3277 - loss: 68986.4872 - regularization_loss: 0.0000e+00 - total_loss: 68986.4872\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 4s 414ms/step - root_mean_squared_error: 1.0133 - factorized_top_k/top_1_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0234 - factorized_top_k/top_10_categorical_accuracy: 0.0491 - factorized_top_k/top_50_categorical_accuracy: 0.2001 - factorized_top_k/top_100_categorical_accuracy: 0.3268 - loss: 68878.0930 - regularization_loss: 0.0000e+00 - total_loss: 68878.0930\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 1.0064 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0231 - factorized_top_k/top_10_categorical_accuracy: 0.0485 - factorized_top_k/top_50_categorical_accuracy: 0.1988 - factorized_top_k/top_100_categorical_accuracy: 0.3248 - loss: 68771.6136 - regularization_loss: 0.0000e+00 - total_loss: 68771.6136\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.0122 - factorized_top_k/top_1_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0228 - factorized_top_k/top_10_categorical_accuracy: 0.0483 - factorized_top_k/top_50_categorical_accuracy: 0.1985 - factorized_top_k/top_100_categorical_accuracy: 0.3234 - loss: 68667.4205 - regularization_loss: 0.0000e+00 - total_loss: 68667.4205\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 4s 412ms/step - root_mean_squared_error: 1.0117 - factorized_top_k/top_1_categorical_accuracy: 2.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0230 - factorized_top_k/top_10_categorical_accuracy: 0.0483 - factorized_top_k/top_50_categorical_accuracy: 0.1977 - factorized_top_k/top_100_categorical_accuracy: 0.3224 - loss: 68565.7259 - regularization_loss: 0.0000e+00 - total_loss: 68565.7259\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 4s 444ms/step - root_mean_squared_error: 1.0049 - factorized_top_k/top_1_categorical_accuracy: 1.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0226 - factorized_top_k/top_10_categorical_accuracy: 0.0476 - factorized_top_k/top_50_categorical_accuracy: 0.1961 - factorized_top_k/top_100_categorical_accuracy: 0.3208 - loss: 68466.6982 - regularization_loss: 0.0000e+00 - total_loss: 68466.6982\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.0064 - factorized_top_k/top_1_categorical_accuracy: 2.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0224 - factorized_top_k/top_10_categorical_accuracy: 0.0475 - factorized_top_k/top_50_categorical_accuracy: 0.1946 - factorized_top_k/top_100_categorical_accuracy: 0.3198 - loss: 68370.4730 - regularization_loss: 0.0000e+00 - total_loss: 68370.4730\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 1.0052 - factorized_top_k/top_1_categorical_accuracy: 3.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0223 - factorized_top_k/top_10_categorical_accuracy: 0.0471 - factorized_top_k/top_50_categorical_accuracy: 0.1940 - factorized_top_k/top_100_categorical_accuracy: 0.3181 - loss: 68277.0788 - regularization_loss: 0.0000e+00 - total_loss: 68277.0788\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.0011 - factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0225 - factorized_top_k/top_10_categorical_accuracy: 0.0467 - factorized_top_k/top_50_categorical_accuracy: 0.1926 - factorized_top_k/top_100_categorical_accuracy: 0.3172 - loss: 68186.5256 - regularization_loss: 0.0000e+00 - total_loss: 68186.5256\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.0069 - factorized_top_k/top_1_categorical_accuracy: 6.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0224 - factorized_top_k/top_10_categorical_accuracy: 0.0463 - factorized_top_k/top_50_categorical_accuracy: 0.1921 - factorized_top_k/top_100_categorical_accuracy: 0.3160 - loss: 68098.8118 - regularization_loss: 0.0000e+00 - total_loss: 68098.8118\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.0035 - factorized_top_k/top_1_categorical_accuracy: 8.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0225 - factorized_top_k/top_10_categorical_accuracy: 0.0461 - factorized_top_k/top_50_categorical_accuracy: 0.1905 - factorized_top_k/top_100_categorical_accuracy: 0.3153 - loss: 68013.8466 - regularization_loss: 0.0000e+00 - total_loss: 68013.8466\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 0.9986 - factorized_top_k/top_1_categorical_accuracy: 6.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0224 - factorized_top_k/top_10_categorical_accuracy: 0.0455 - factorized_top_k/top_50_categorical_accuracy: 0.1894 - factorized_top_k/top_100_categorical_accuracy: 0.3143 - loss: 67931.5760 - regularization_loss: 0.0000e+00 - total_loss: 67931.5760\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.0033 - factorized_top_k/top_1_categorical_accuracy: 7.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0221 - factorized_top_k/top_10_categorical_accuracy: 0.0454 - factorized_top_k/top_50_categorical_accuracy: 0.1887 - factorized_top_k/top_100_categorical_accuracy: 0.3142 - loss: 67851.9318 - regularization_loss: 0.0000e+00 - total_loss: 67851.9318\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 5s 447ms/step - root_mean_squared_error: 0.9962 - factorized_top_k/top_1_categorical_accuracy: 4.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0215 - factorized_top_k/top_10_categorical_accuracy: 0.0444 - factorized_top_k/top_50_categorical_accuracy: 0.1868 - factorized_top_k/top_100_categorical_accuracy: 0.3133 - loss: 67774.7720 - regularization_loss: 0.0000e+00 - total_loss: 67774.7720\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 438ms/step - root_mean_squared_error: 0.9958 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0213 - factorized_top_k/top_10_categorical_accuracy: 0.0443 - factorized_top_k/top_50_categorical_accuracy: 0.1866 - factorized_top_k/top_100_categorical_accuracy: 0.3120 - loss: 67700.0220 - regularization_loss: 0.0000e+00 - total_loss: 67700.0220\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 5s 461ms/step - root_mean_squared_error: 1.0009 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0209 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - factorized_top_k/top_50_categorical_accuracy: 0.1852 - factorized_top_k/top_100_categorical_accuracy: 0.3109 - loss: 67627.5810 - regularization_loss: 0.0000e+00 - total_loss: 67627.5810\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 0.9947 - factorized_top_k/top_1_categorical_accuracy: 6.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0209 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.1845 - factorized_top_k/top_100_categorical_accuracy: 0.3102 - loss: 67557.2876 - regularization_loss: 0.0000e+00 - total_loss: 67557.2876\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 0.9930 - factorized_top_k/top_1_categorical_accuracy: 8.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0208 - factorized_top_k/top_10_categorical_accuracy: 0.0436 - factorized_top_k/top_50_categorical_accuracy: 0.1839 - factorized_top_k/top_100_categorical_accuracy: 0.3097 - loss: 67489.0646 - regularization_loss: 0.0000e+00 - total_loss: 67489.0646\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 0.9956 - factorized_top_k/top_1_categorical_accuracy: 8.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0209 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.1844 - factorized_top_k/top_100_categorical_accuracy: 0.3094 - loss: 67422.8146 - regularization_loss: 0.0000e+00 - total_loss: 67422.8146\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 4s 442ms/step - root_mean_squared_error: 0.9903 - factorized_top_k/top_1_categorical_accuracy: 7.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0208 - factorized_top_k/top_10_categorical_accuracy: 0.0432 - factorized_top_k/top_50_categorical_accuracy: 0.1842 - factorized_top_k/top_100_categorical_accuracy: 0.3085 - loss: 67358.3942 - regularization_loss: 0.0000e+00 - total_loss: 67358.3942\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 0.9898 - factorized_top_k/top_1_categorical_accuracy: 9.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0211 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.1839 - factorized_top_k/top_100_categorical_accuracy: 0.3086 - loss: 67295.7251 - regularization_loss: 0.0000e+00 - total_loss: 67295.7251\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 4s 447ms/step - root_mean_squared_error: 0.9916 - factorized_top_k/top_1_categorical_accuracy: 7.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0209 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - factorized_top_k/top_50_categorical_accuracy: 0.1838 - factorized_top_k/top_100_categorical_accuracy: 0.3087 - loss: 67234.7273 - regularization_loss: 0.0000e+00 - total_loss: 67234.7273\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 0.9899 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0210 - factorized_top_k/top_10_categorical_accuracy: 0.0441 - factorized_top_k/top_50_categorical_accuracy: 0.1840 - factorized_top_k/top_100_categorical_accuracy: 0.3090 - loss: 67175.2663 - regularization_loss: 0.0000e+00 - total_loss: 67175.2663\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 0.9884 - factorized_top_k/top_1_categorical_accuracy: 9.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0445 - factorized_top_k/top_50_categorical_accuracy: 0.1841 - factorized_top_k/top_100_categorical_accuracy: 0.3094 - loss: 67117.2947 - regularization_loss: 0.0000e+00 - total_loss: 67117.2947\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 0.9857 - factorized_top_k/top_1_categorical_accuracy: 9.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0212 - factorized_top_k/top_10_categorical_accuracy: 0.0447 - factorized_top_k/top_50_categorical_accuracy: 0.1844 - factorized_top_k/top_100_categorical_accuracy: 0.3094 - loss: 67060.7273 - regularization_loss: 0.0000e+00 - total_loss: 67060.7273\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 0.9859 - factorized_top_k/top_1_categorical_accuracy: 9.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0449 - factorized_top_k/top_50_categorical_accuracy: 0.1844 - factorized_top_k/top_100_categorical_accuracy: 0.3098 - loss: 67005.4993 - regularization_loss: 0.0000e+00 - total_loss: 67005.4993\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 4s 433ms/step - root_mean_squared_error: 0.9855 - factorized_top_k/top_1_categorical_accuracy: 8.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0214 - factorized_top_k/top_10_categorical_accuracy: 0.0450 - factorized_top_k/top_50_categorical_accuracy: 0.1846 - factorized_top_k/top_100_categorical_accuracy: 0.3105 - loss: 66951.5234 - regularization_loss: 0.0000e+00 - total_loss: 66951.5234\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 4s 422ms/step - root_mean_squared_error: 0.9837 - factorized_top_k/top_1_categorical_accuracy: 9.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0451 - factorized_top_k/top_50_categorical_accuracy: 0.1853 - factorized_top_k/top_100_categorical_accuracy: 0.3109 - loss: 66898.7528 - regularization_loss: 0.0000e+00 - total_loss: 66898.7528\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 0.9877 - factorized_top_k/top_1_categorical_accuracy: 8.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0215 - factorized_top_k/top_10_categorical_accuracy: 0.0450 - factorized_top_k/top_50_categorical_accuracy: 0.1860 - factorized_top_k/top_100_categorical_accuracy: 0.3110 - loss: 66847.1236 - regularization_loss: 0.0000e+00 - total_loss: 66847.1236\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 4s 439ms/step - root_mean_squared_error: 0.9806 - factorized_top_k/top_1_categorical_accuracy: 9.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0453 - factorized_top_k/top_50_categorical_accuracy: 0.1859 - factorized_top_k/top_100_categorical_accuracy: 0.3116 - loss: 66796.5653 - regularization_loss: 0.0000e+00 - total_loss: 66796.5653\n",
      "5/5 [==============================] - 2s 259ms/step - root_mean_squared_error: 0.9734 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0107 - factorized_top_k/top_10_categorical_accuracy: 0.0233 - factorized_top_k/top_50_categorical_accuracy: 0.1289 - factorized_top_k/top_100_categorical_accuracy: 0.2372 - loss: 31242.4626 - regularization_loss: 0.0000e+00 - total_loss: 31242.4626\n",
      "Retrieval top-100 accuracy: 0.237.\n",
      "Ranking RMSE: 0.973.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001))\n",
    "rmsOhOhOne = model.fit(cached_train, epochs=50)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "#**************************\n",
    "\n",
    "rmsOhOhOne = pd.DataFrame(rmsOhOhOne.history)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>factorized_top_k/top_1_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_5_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_10_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_50_categorical_accuracy</th>\n",
       "      <th>factorized_top_k/top_100_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>regularization_loss</th>\n",
       "      <th>total_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.325034</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.027787</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>54850.746094</td>\n",
       "      <td>0</td>\n",
       "      <td>54850.746094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.142920</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.084125</td>\n",
       "      <td>54839.691406</td>\n",
       "      <td>0</td>\n",
       "      <td>54839.691406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.232760</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.006825</td>\n",
       "      <td>0.014475</td>\n",
       "      <td>0.062825</td>\n",
       "      <td>0.113537</td>\n",
       "      <td>54831.464844</td>\n",
       "      <td>0</td>\n",
       "      <td>54831.464844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.107500</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.011288</td>\n",
       "      <td>0.022150</td>\n",
       "      <td>0.089975</td>\n",
       "      <td>0.153375</td>\n",
       "      <td>54820.328125</td>\n",
       "      <td>0</td>\n",
       "      <td>54820.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.080956</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>0.031688</td>\n",
       "      <td>0.125137</td>\n",
       "      <td>0.206275</td>\n",
       "      <td>54803.410156</td>\n",
       "      <td>0</td>\n",
       "      <td>54803.410156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.064817</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.019350</td>\n",
       "      <td>0.039212</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.255163</td>\n",
       "      <td>54779.136719</td>\n",
       "      <td>0</td>\n",
       "      <td>54779.136719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.055693</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.021662</td>\n",
       "      <td>0.044325</td>\n",
       "      <td>0.179888</td>\n",
       "      <td>0.293775</td>\n",
       "      <td>54746.566406</td>\n",
       "      <td>0</td>\n",
       "      <td>54746.566406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.050477</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.022363</td>\n",
       "      <td>0.046737</td>\n",
       "      <td>0.192600</td>\n",
       "      <td>0.315550</td>\n",
       "      <td>54705.226562</td>\n",
       "      <td>0</td>\n",
       "      <td>54705.226562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.045479</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.022788</td>\n",
       "      <td>0.047288</td>\n",
       "      <td>0.198200</td>\n",
       "      <td>0.326237</td>\n",
       "      <td>54655.312500</td>\n",
       "      <td>0</td>\n",
       "      <td>54655.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.038926</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.048775</td>\n",
       "      <td>0.202863</td>\n",
       "      <td>0.332500</td>\n",
       "      <td>54597.226562</td>\n",
       "      <td>0</td>\n",
       "      <td>54597.226562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.034364</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.048862</td>\n",
       "      <td>0.204725</td>\n",
       "      <td>0.335387</td>\n",
       "      <td>54531.664062</td>\n",
       "      <td>0</td>\n",
       "      <td>54531.664062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.031444</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.023563</td>\n",
       "      <td>0.049863</td>\n",
       "      <td>0.204625</td>\n",
       "      <td>0.336175</td>\n",
       "      <td>54459.472656</td>\n",
       "      <td>0</td>\n",
       "      <td>54459.472656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.028169</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.049737</td>\n",
       "      <td>0.204775</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>54381.621094</td>\n",
       "      <td>0</td>\n",
       "      <td>54381.621094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.025089</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.050012</td>\n",
       "      <td>0.204588</td>\n",
       "      <td>0.336563</td>\n",
       "      <td>54299.089844</td>\n",
       "      <td>0</td>\n",
       "      <td>54299.089844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.022600</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.023737</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.204475</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>54212.894531</td>\n",
       "      <td>0</td>\n",
       "      <td>54212.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.021502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022987</td>\n",
       "      <td>0.049663</td>\n",
       "      <td>0.202438</td>\n",
       "      <td>0.334225</td>\n",
       "      <td>54124.046875</td>\n",
       "      <td>0</td>\n",
       "      <td>54124.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.020692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.049525</td>\n",
       "      <td>0.202300</td>\n",
       "      <td>0.333412</td>\n",
       "      <td>54033.460938</td>\n",
       "      <td>0</td>\n",
       "      <td>54033.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.017650</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.023338</td>\n",
       "      <td>0.049438</td>\n",
       "      <td>0.201875</td>\n",
       "      <td>0.332262</td>\n",
       "      <td>53941.925781</td>\n",
       "      <td>0</td>\n",
       "      <td>53941.925781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.017568</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>0.201550</td>\n",
       "      <td>0.330687</td>\n",
       "      <td>53850.316406</td>\n",
       "      <td>0</td>\n",
       "      <td>53850.316406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.013344</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.022925</td>\n",
       "      <td>0.049112</td>\n",
       "      <td>0.200850</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>53759.203125</td>\n",
       "      <td>0</td>\n",
       "      <td>53759.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.013012</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.048575</td>\n",
       "      <td>0.200212</td>\n",
       "      <td>0.327675</td>\n",
       "      <td>53669.152344</td>\n",
       "      <td>0</td>\n",
       "      <td>53669.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.013289</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.023387</td>\n",
       "      <td>0.049137</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.326825</td>\n",
       "      <td>53580.593750</td>\n",
       "      <td>0</td>\n",
       "      <td>53580.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.006372</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.023062</td>\n",
       "      <td>0.048512</td>\n",
       "      <td>0.198825</td>\n",
       "      <td>0.324762</td>\n",
       "      <td>53493.816406</td>\n",
       "      <td>0</td>\n",
       "      <td>53493.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.012242</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.022825</td>\n",
       "      <td>0.048338</td>\n",
       "      <td>0.198488</td>\n",
       "      <td>0.323413</td>\n",
       "      <td>53409.140625</td>\n",
       "      <td>0</td>\n",
       "      <td>53409.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.011730</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.048313</td>\n",
       "      <td>0.197663</td>\n",
       "      <td>0.322375</td>\n",
       "      <td>53326.628906</td>\n",
       "      <td>0</td>\n",
       "      <td>53326.628906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.004950</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.022650</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>0.196100</td>\n",
       "      <td>0.320762</td>\n",
       "      <td>53246.453125</td>\n",
       "      <td>0</td>\n",
       "      <td>53246.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.006447</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.022412</td>\n",
       "      <td>0.047537</td>\n",
       "      <td>0.194562</td>\n",
       "      <td>0.319825</td>\n",
       "      <td>53168.695312</td>\n",
       "      <td>0</td>\n",
       "      <td>53168.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.005241</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.022338</td>\n",
       "      <td>0.047125</td>\n",
       "      <td>0.194037</td>\n",
       "      <td>0.318063</td>\n",
       "      <td>53093.324219</td>\n",
       "      <td>0</td>\n",
       "      <td>53093.324219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.001108</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.192612</td>\n",
       "      <td>0.317175</td>\n",
       "      <td>53020.328125</td>\n",
       "      <td>0</td>\n",
       "      <td>53020.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.006875</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.022375</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>0.316050</td>\n",
       "      <td>52949.730469</td>\n",
       "      <td>0</td>\n",
       "      <td>52949.730469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.003497</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.022475</td>\n",
       "      <td>0.046050</td>\n",
       "      <td>0.190525</td>\n",
       "      <td>0.315300</td>\n",
       "      <td>52881.386719</td>\n",
       "      <td>0</td>\n",
       "      <td>52881.386719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.022363</td>\n",
       "      <td>0.045525</td>\n",
       "      <td>0.189425</td>\n",
       "      <td>0.314337</td>\n",
       "      <td>52815.300781</td>\n",
       "      <td>0</td>\n",
       "      <td>52815.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.003289</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.022062</td>\n",
       "      <td>0.045425</td>\n",
       "      <td>0.188750</td>\n",
       "      <td>0.314162</td>\n",
       "      <td>52751.429688</td>\n",
       "      <td>0</td>\n",
       "      <td>52751.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.996156</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.021463</td>\n",
       "      <td>0.044375</td>\n",
       "      <td>0.186850</td>\n",
       "      <td>0.313287</td>\n",
       "      <td>52689.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>52689.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.995777</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>0.044312</td>\n",
       "      <td>0.186575</td>\n",
       "      <td>0.311987</td>\n",
       "      <td>52629.800781</td>\n",
       "      <td>0</td>\n",
       "      <td>52629.800781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.000939</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.020850</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>0.185225</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>52571.945312</td>\n",
       "      <td>0</td>\n",
       "      <td>52571.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.994730</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.020887</td>\n",
       "      <td>0.043550</td>\n",
       "      <td>0.184450</td>\n",
       "      <td>0.310212</td>\n",
       "      <td>52515.847656</td>\n",
       "      <td>0</td>\n",
       "      <td>52515.847656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.992958</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.020813</td>\n",
       "      <td>0.043612</td>\n",
       "      <td>0.183925</td>\n",
       "      <td>0.309650</td>\n",
       "      <td>52461.445312</td>\n",
       "      <td>0</td>\n",
       "      <td>52461.445312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.995617</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.020850</td>\n",
       "      <td>0.043488</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.309350</td>\n",
       "      <td>52408.769531</td>\n",
       "      <td>0</td>\n",
       "      <td>52408.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.990270</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>0.043250</td>\n",
       "      <td>0.184213</td>\n",
       "      <td>0.308538</td>\n",
       "      <td>52357.578125</td>\n",
       "      <td>0</td>\n",
       "      <td>52357.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.989776</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.043475</td>\n",
       "      <td>0.183887</td>\n",
       "      <td>0.308650</td>\n",
       "      <td>52307.792969</td>\n",
       "      <td>0</td>\n",
       "      <td>52307.792969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.020887</td>\n",
       "      <td>0.043812</td>\n",
       "      <td>0.183775</td>\n",
       "      <td>0.308725</td>\n",
       "      <td>52259.496094</td>\n",
       "      <td>0</td>\n",
       "      <td>52259.496094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.989910</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.044062</td>\n",
       "      <td>0.183962</td>\n",
       "      <td>0.308975</td>\n",
       "      <td>52212.328125</td>\n",
       "      <td>0</td>\n",
       "      <td>52212.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.988355</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.044487</td>\n",
       "      <td>0.184137</td>\n",
       "      <td>0.309413</td>\n",
       "      <td>52166.417969</td>\n",
       "      <td>0</td>\n",
       "      <td>52166.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.985666</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.044675</td>\n",
       "      <td>0.184375</td>\n",
       "      <td>0.309413</td>\n",
       "      <td>52121.718750</td>\n",
       "      <td>0</td>\n",
       "      <td>52121.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.985854</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>0.044863</td>\n",
       "      <td>0.184425</td>\n",
       "      <td>0.309812</td>\n",
       "      <td>52078.121094</td>\n",
       "      <td>0</td>\n",
       "      <td>52078.121094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.985531</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.045050</td>\n",
       "      <td>0.184587</td>\n",
       "      <td>0.310500</td>\n",
       "      <td>52035.507812</td>\n",
       "      <td>0</td>\n",
       "      <td>52035.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.983693</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>0.045137</td>\n",
       "      <td>0.185312</td>\n",
       "      <td>0.310887</td>\n",
       "      <td>51993.933594</td>\n",
       "      <td>0</td>\n",
       "      <td>51993.933594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.987662</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>0.044987</td>\n",
       "      <td>0.185975</td>\n",
       "      <td>0.311038</td>\n",
       "      <td>51953.203125</td>\n",
       "      <td>0</td>\n",
       "      <td>51953.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.980629</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>0.045288</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.311637</td>\n",
       "      <td>51913.390625</td>\n",
       "      <td>0</td>\n",
       "      <td>51913.390625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    root_mean_squared_error  factorized_top_k/top_1_categorical_accuracy  \\\n",
       "0                  3.325034                                     0.000063   \n",
       "1                  2.142920                                     0.000050   \n",
       "2                  1.232760                                     0.000075   \n",
       "3                  1.107500                                     0.000050   \n",
       "4                  1.080956                                     0.000388   \n",
       "5                  1.064817                                     0.000125   \n",
       "6                  1.055693                                     0.000188   \n",
       "7                  1.050477                                     0.000125   \n",
       "8                  1.045479                                     0.000025   \n",
       "9                  1.038926                                     0.000175   \n",
       "10                 1.034364                                     0.000012   \n",
       "11                 1.031444                                     0.000075   \n",
       "12                 1.028169                                     0.000012   \n",
       "13                 1.025089                                     0.000112   \n",
       "14                 1.022600                                     0.000225   \n",
       "15                 1.021502                                     0.000000   \n",
       "16                 1.020692                                     0.000000   \n",
       "17                 1.017650                                     0.000025   \n",
       "18                 1.017568                                     0.000050   \n",
       "19                 1.013344                                     0.000075   \n",
       "20                 1.013012                                     0.000087   \n",
       "21                 1.013289                                     0.000200   \n",
       "22                 1.006372                                     0.000125   \n",
       "23                 1.012242                                     0.000188   \n",
       "24                 1.011730                                     0.000288   \n",
       "25                 1.004950                                     0.000163   \n",
       "26                 1.006447                                     0.000213   \n",
       "27                 1.005241                                     0.000325   \n",
       "28                 1.001108                                     0.000450   \n",
       "29                 1.006875                                     0.000650   \n",
       "30                 1.003497                                     0.000813   \n",
       "31                 0.998583                                     0.000662   \n",
       "32                 1.003289                                     0.000775   \n",
       "33                 0.996156                                     0.000487   \n",
       "34                 0.995777                                     0.000750   \n",
       "35                 1.000939                                     0.000500   \n",
       "36                 0.994730                                     0.000662   \n",
       "37                 0.992958                                     0.000800   \n",
       "38                 0.995617                                     0.000850   \n",
       "39                 0.990270                                     0.000762   \n",
       "40                 0.989776                                     0.000925   \n",
       "41                 0.991597                                     0.000775   \n",
       "42                 0.989910                                     0.001088   \n",
       "43                 0.988355                                     0.000975   \n",
       "44                 0.985666                                     0.000900   \n",
       "45                 0.985854                                     0.000913   \n",
       "46                 0.985531                                     0.000850   \n",
       "47                 0.983693                                     0.000987   \n",
       "48                 0.987662                                     0.000888   \n",
       "49                 0.980629                                     0.000975   \n",
       "\n",
       "    factorized_top_k/top_5_categorical_accuracy  \\\n",
       "0                                      0.002313   \n",
       "1                                      0.004050   \n",
       "2                                      0.006825   \n",
       "3                                      0.011288   \n",
       "4                                      0.016225   \n",
       "5                                      0.019350   \n",
       "6                                      0.021662   \n",
       "7                                      0.022363   \n",
       "8                                      0.022788   \n",
       "9                                      0.023363   \n",
       "10                                     0.023400   \n",
       "11                                     0.023563   \n",
       "12                                     0.023075   \n",
       "13                                     0.023300   \n",
       "14                                     0.023737   \n",
       "15                                     0.022987   \n",
       "16                                     0.023375   \n",
       "17                                     0.023338   \n",
       "18                                     0.023038   \n",
       "19                                     0.022925   \n",
       "20                                     0.023038   \n",
       "21                                     0.023387   \n",
       "22                                     0.023062   \n",
       "23                                     0.022825   \n",
       "24                                     0.023000   \n",
       "25                                     0.022650   \n",
       "26                                     0.022412   \n",
       "27                                     0.022338   \n",
       "28                                     0.022500   \n",
       "29                                     0.022375   \n",
       "30                                     0.022475   \n",
       "31                                     0.022363   \n",
       "32                                     0.022062   \n",
       "33                                     0.021463   \n",
       "34                                     0.021337   \n",
       "35                                     0.020850   \n",
       "36                                     0.020887   \n",
       "37                                     0.020813   \n",
       "38                                     0.020850   \n",
       "39                                     0.020762   \n",
       "40                                     0.021087   \n",
       "41                                     0.020887   \n",
       "42                                     0.021038   \n",
       "43                                     0.021238   \n",
       "44                                     0.021225   \n",
       "45                                     0.021375   \n",
       "46                                     0.021400   \n",
       "47                                     0.021713   \n",
       "48                                     0.021537   \n",
       "49                                     0.021725   \n",
       "\n",
       "    factorized_top_k/top_10_categorical_accuracy  \\\n",
       "0                                       0.004875   \n",
       "1                                       0.008763   \n",
       "2                                       0.014475   \n",
       "3                                       0.022150   \n",
       "4                                       0.031688   \n",
       "5                                       0.039212   \n",
       "6                                       0.044325   \n",
       "7                                       0.046737   \n",
       "8                                       0.047288   \n",
       "9                                       0.048775   \n",
       "10                                      0.048862   \n",
       "11                                      0.049863   \n",
       "12                                      0.049737   \n",
       "13                                      0.050012   \n",
       "14                                      0.050400   \n",
       "15                                      0.049663   \n",
       "16                                      0.049525   \n",
       "17                                      0.049438   \n",
       "18                                      0.049213   \n",
       "19                                      0.049112   \n",
       "20                                      0.048575   \n",
       "21                                      0.049137   \n",
       "22                                      0.048512   \n",
       "23                                      0.048338   \n",
       "24                                      0.048313   \n",
       "25                                      0.047625   \n",
       "26                                      0.047537   \n",
       "27                                      0.047125   \n",
       "28                                      0.046675   \n",
       "29                                      0.046300   \n",
       "30                                      0.046050   \n",
       "31                                      0.045525   \n",
       "32                                      0.045425   \n",
       "33                                      0.044375   \n",
       "34                                      0.044312   \n",
       "35                                      0.043837   \n",
       "36                                      0.043550   \n",
       "37                                      0.043612   \n",
       "38                                      0.043488   \n",
       "39                                      0.043250   \n",
       "40                                      0.043475   \n",
       "41                                      0.043812   \n",
       "42                                      0.044062   \n",
       "43                                      0.044487   \n",
       "44                                      0.044675   \n",
       "45                                      0.044863   \n",
       "46                                      0.045050   \n",
       "47                                      0.045137   \n",
       "48                                      0.044987   \n",
       "49                                      0.045288   \n",
       "\n",
       "    factorized_top_k/top_50_categorical_accuracy  \\\n",
       "0                                       0.027787   \n",
       "1                                       0.044000   \n",
       "2                                       0.062825   \n",
       "3                                       0.089975   \n",
       "4                                       0.125137   \n",
       "5                                       0.156250   \n",
       "6                                       0.179888   \n",
       "7                                       0.192600   \n",
       "8                                       0.198200   \n",
       "9                                       0.202863   \n",
       "10                                      0.204725   \n",
       "11                                      0.204625   \n",
       "12                                      0.204775   \n",
       "13                                      0.204588   \n",
       "14                                      0.204475   \n",
       "15                                      0.202438   \n",
       "16                                      0.202300   \n",
       "17                                      0.201875   \n",
       "18                                      0.201550   \n",
       "19                                      0.200850   \n",
       "20                                      0.200212   \n",
       "21                                      0.200100   \n",
       "22                                      0.198825   \n",
       "23                                      0.198488   \n",
       "24                                      0.197663   \n",
       "25                                      0.196100   \n",
       "26                                      0.194562   \n",
       "27                                      0.194037   \n",
       "28                                      0.192612   \n",
       "29                                      0.192113   \n",
       "30                                      0.190525   \n",
       "31                                      0.189425   \n",
       "32                                      0.188750   \n",
       "33                                      0.186850   \n",
       "34                                      0.186575   \n",
       "35                                      0.185225   \n",
       "36                                      0.184450   \n",
       "37                                      0.183925   \n",
       "38                                      0.184400   \n",
       "39                                      0.184213   \n",
       "40                                      0.183887   \n",
       "41                                      0.183775   \n",
       "42                                      0.183962   \n",
       "43                                      0.184137   \n",
       "44                                      0.184375   \n",
       "45                                      0.184425   \n",
       "46                                      0.184587   \n",
       "47                                      0.185312   \n",
       "48                                      0.185975   \n",
       "49                                      0.185900   \n",
       "\n",
       "    factorized_top_k/top_100_categorical_accuracy          loss  \\\n",
       "0                                        0.058100  54850.746094   \n",
       "1                                        0.084125  54839.691406   \n",
       "2                                        0.113537  54831.464844   \n",
       "3                                        0.153375  54820.328125   \n",
       "4                                        0.206275  54803.410156   \n",
       "5                                        0.255163  54779.136719   \n",
       "6                                        0.293775  54746.566406   \n",
       "7                                        0.315550  54705.226562   \n",
       "8                                        0.326237  54655.312500   \n",
       "9                                        0.332500  54597.226562   \n",
       "10                                       0.335387  54531.664062   \n",
       "11                                       0.336175  54459.472656   \n",
       "12                                       0.336400  54381.621094   \n",
       "13                                       0.336563  54299.089844   \n",
       "14                                       0.335900  54212.894531   \n",
       "15                                       0.334225  54124.046875   \n",
       "16                                       0.333412  54033.460938   \n",
       "17                                       0.332262  53941.925781   \n",
       "18                                       0.330687  53850.316406   \n",
       "19                                       0.329400  53759.203125   \n",
       "20                                       0.327675  53669.152344   \n",
       "21                                       0.326825  53580.593750   \n",
       "22                                       0.324762  53493.816406   \n",
       "23                                       0.323413  53409.140625   \n",
       "24                                       0.322375  53326.628906   \n",
       "25                                       0.320762  53246.453125   \n",
       "26                                       0.319825  53168.695312   \n",
       "27                                       0.318063  53093.324219   \n",
       "28                                       0.317175  53020.328125   \n",
       "29                                       0.316050  52949.730469   \n",
       "30                                       0.315300  52881.386719   \n",
       "31                                       0.314337  52815.300781   \n",
       "32                                       0.314162  52751.429688   \n",
       "33                                       0.313287  52689.625000   \n",
       "34                                       0.311987  52629.800781   \n",
       "35                                       0.310900  52571.945312   \n",
       "36                                       0.310212  52515.847656   \n",
       "37                                       0.309650  52461.445312   \n",
       "38                                       0.309350  52408.769531   \n",
       "39                                       0.308538  52357.578125   \n",
       "40                                       0.308650  52307.792969   \n",
       "41                                       0.308725  52259.496094   \n",
       "42                                       0.308975  52212.328125   \n",
       "43                                       0.309413  52166.417969   \n",
       "44                                       0.309413  52121.718750   \n",
       "45                                       0.309812  52078.121094   \n",
       "46                                       0.310500  52035.507812   \n",
       "47                                       0.310887  51993.933594   \n",
       "48                                       0.311038  51953.203125   \n",
       "49                                       0.311637  51913.390625   \n",
       "\n",
       "    regularization_loss    total_loss  \n",
       "0                     0  54850.746094  \n",
       "1                     0  54839.691406  \n",
       "2                     0  54831.464844  \n",
       "3                     0  54820.328125  \n",
       "4                     0  54803.410156  \n",
       "5                     0  54779.136719  \n",
       "6                     0  54746.566406  \n",
       "7                     0  54705.226562  \n",
       "8                     0  54655.312500  \n",
       "9                     0  54597.226562  \n",
       "10                    0  54531.664062  \n",
       "11                    0  54459.472656  \n",
       "12                    0  54381.621094  \n",
       "13                    0  54299.089844  \n",
       "14                    0  54212.894531  \n",
       "15                    0  54124.046875  \n",
       "16                    0  54033.460938  \n",
       "17                    0  53941.925781  \n",
       "18                    0  53850.316406  \n",
       "19                    0  53759.203125  \n",
       "20                    0  53669.152344  \n",
       "21                    0  53580.593750  \n",
       "22                    0  53493.816406  \n",
       "23                    0  53409.140625  \n",
       "24                    0  53326.628906  \n",
       "25                    0  53246.453125  \n",
       "26                    0  53168.695312  \n",
       "27                    0  53093.324219  \n",
       "28                    0  53020.328125  \n",
       "29                    0  52949.730469  \n",
       "30                    0  52881.386719  \n",
       "31                    0  52815.300781  \n",
       "32                    0  52751.429688  \n",
       "33                    0  52689.625000  \n",
       "34                    0  52629.800781  \n",
       "35                    0  52571.945312  \n",
       "36                    0  52515.847656  \n",
       "37                    0  52461.445312  \n",
       "38                    0  52408.769531  \n",
       "39                    0  52357.578125  \n",
       "40                    0  52307.792969  \n",
       "41                    0  52259.496094  \n",
       "42                    0  52212.328125  \n",
       "43                    0  52166.417969  \n",
       "44                    0  52121.718750  \n",
       "45                    0  52078.121094  \n",
       "46                    0  52035.507812  \n",
       "47                    0  51993.933594  \n",
       "48                    0  51953.203125  \n",
       "49                    0  51913.390625  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsOhOhOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 6s 403ms/step - root_mean_squared_error: 2.3321 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0044 - factorized_top_k/top_50_categorical_accuracy: 0.0399 - factorized_top_k/top_100_categorical_accuracy: 0.0886 - loss: 70279.8949 - regularization_loss: 0.0000e+00 - total_loss: 70279.8949\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 4s 407ms/step - root_mean_squared_error: 1.6464 - factorized_top_k/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0065 - factorized_top_k/top_10_categorical_accuracy: 0.0199 - factorized_top_k/top_50_categorical_accuracy: 0.1298 - factorized_top_k/top_100_categorical_accuracy: 0.2468 - loss: 69166.3232 - regularization_loss: 0.0000e+00 - total_loss: 69166.3232\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 4s 413ms/step - root_mean_squared_error: 1.3998 - factorized_top_k/top_1_categorical_accuracy: 4.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0129 - factorized_top_k/top_10_categorical_accuracy: 0.0307 - factorized_top_k/top_50_categorical_accuracy: 0.1518 - factorized_top_k/top_100_categorical_accuracy: 0.2746 - loss: 68047.8949 - regularization_loss: 0.0000e+00 - total_loss: 68047.8949\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 4s 410ms/step - root_mean_squared_error: 1.3153 - factorized_top_k/top_1_categorical_accuracy: 9.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0166 - factorized_top_k/top_10_categorical_accuracy: 0.0366 - factorized_top_k/top_50_categorical_accuracy: 0.1638 - factorized_top_k/top_100_categorical_accuracy: 0.2839 - loss: 67324.2266 - regularization_loss: 0.0000e+00 - total_loss: 67324.2266\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 4s 445ms/step - root_mean_squared_error: 1.3797 - factorized_top_k/top_1_categorical_accuracy: 8.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0185 - factorized_top_k/top_10_categorical_accuracy: 0.0398 - factorized_top_k/top_50_categorical_accuracy: 0.1737 - factorized_top_k/top_100_categorical_accuracy: 0.2953 - loss: 66771.5320 - regularization_loss: 0.0000e+00 - total_loss: 66771.5320\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 4s 410ms/step - root_mean_squared_error: 1.3126 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0207 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.1836 - factorized_top_k/top_100_categorical_accuracy: 0.3074 - loss: 66323.0682 - regularization_loss: 0.0000e+00 - total_loss: 66323.0682\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 4s 411ms/step - root_mean_squared_error: 1.2689 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0227 - factorized_top_k/top_10_categorical_accuracy: 0.0464 - factorized_top_k/top_50_categorical_accuracy: 0.1917 - factorized_top_k/top_100_categorical_accuracy: 0.3169 - loss: 65947.1953 - regularization_loss: 0.0000e+00 - total_loss: 65947.1953\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 4s 414ms/step - root_mean_squared_error: 1.3466 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0237 - factorized_top_k/top_10_categorical_accuracy: 0.0488 - factorized_top_k/top_50_categorical_accuracy: 0.1985 - factorized_top_k/top_100_categorical_accuracy: 0.3255 - loss: 65621.7649 - regularization_loss: 0.0000e+00 - total_loss: 65621.7649\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.3105 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0248 - factorized_top_k/top_10_categorical_accuracy: 0.0513 - factorized_top_k/top_50_categorical_accuracy: 0.2044 - factorized_top_k/top_100_categorical_accuracy: 0.3350 - loss: 65331.9474 - regularization_loss: 0.0000e+00 - total_loss: 65331.9474\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 1.1831 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0260 - factorized_top_k/top_10_categorical_accuracy: 0.0538 - factorized_top_k/top_50_categorical_accuracy: 0.2110 - factorized_top_k/top_100_categorical_accuracy: 0.3429 - loss: 65071.0376 - regularization_loss: 0.0000e+00 - total_loss: 65071.0376\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.1646 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0270 - factorized_top_k/top_10_categorical_accuracy: 0.0555 - factorized_top_k/top_50_categorical_accuracy: 0.2158 - factorized_top_k/top_100_categorical_accuracy: 0.3497 - loss: 64835.1570 - regularization_loss: 0.0000e+00 - total_loss: 64835.1570\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 4s 428ms/step - root_mean_squared_error: 1.1357 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0284 - factorized_top_k/top_10_categorical_accuracy: 0.0575 - factorized_top_k/top_50_categorical_accuracy: 0.2222 - factorized_top_k/top_100_categorical_accuracy: 0.3559 - loss: 64621.4432 - regularization_loss: 0.0000e+00 - total_loss: 64621.4432\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 4s 436ms/step - root_mean_squared_error: 1.1690 - factorized_top_k/top_1_categorical_accuracy: 8.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0287 - factorized_top_k/top_10_categorical_accuracy: 0.0586 - factorized_top_k/top_50_categorical_accuracy: 0.2270 - factorized_top_k/top_100_categorical_accuracy: 0.3602 - loss: 64428.0895 - regularization_loss: 0.0000e+00 - total_loss: 64428.0895\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.1334 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0296 - factorized_top_k/top_10_categorical_accuracy: 0.0606 - factorized_top_k/top_50_categorical_accuracy: 0.2312 - factorized_top_k/top_100_categorical_accuracy: 0.3649 - loss: 64253.0490 - regularization_loss: 0.0000e+00 - total_loss: 64253.0490\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 5s 458ms/step - root_mean_squared_error: 1.0986 - factorized_top_k/top_1_categorical_accuracy: 9.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0296 - factorized_top_k/top_10_categorical_accuracy: 0.0614 - factorized_top_k/top_50_categorical_accuracy: 0.2333 - factorized_top_k/top_100_categorical_accuracy: 0.3689 - loss: 64094.6612 - regularization_loss: 0.0000e+00 - total_loss: 64094.6612\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 5s 459ms/step - root_mean_squared_error: 1.1610 - factorized_top_k/top_1_categorical_accuracy: 8.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0301 - factorized_top_k/top_10_categorical_accuracy: 0.0625 - factorized_top_k/top_50_categorical_accuracy: 0.2364 - factorized_top_k/top_100_categorical_accuracy: 0.3730 - loss: 63951.4638 - regularization_loss: 0.0000e+00 - total_loss: 63951.4638\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 5s 471ms/step - root_mean_squared_error: 1.0767 - factorized_top_k/top_1_categorical_accuracy: 7.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0308 - factorized_top_k/top_10_categorical_accuracy: 0.0636 - factorized_top_k/top_50_categorical_accuracy: 0.2389 - factorized_top_k/top_100_categorical_accuracy: 0.3763 - loss: 63821.4354 - regularization_loss: 0.0000e+00 - total_loss: 63821.4354\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 4s 417ms/step - root_mean_squared_error: 1.0885 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0311 - factorized_top_k/top_10_categorical_accuracy: 0.0643 - factorized_top_k/top_50_categorical_accuracy: 0.2410 - factorized_top_k/top_100_categorical_accuracy: 0.3796 - loss: 63703.6214 - regularization_loss: 0.0000e+00 - total_loss: 63703.6214\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.0926 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0314 - factorized_top_k/top_10_categorical_accuracy: 0.0650 - factorized_top_k/top_50_categorical_accuracy: 0.2426 - factorized_top_k/top_100_categorical_accuracy: 0.3826 - loss: 63596.5952 - regularization_loss: 0.0000e+00 - total_loss: 63596.5952\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 1.0667 - factorized_top_k/top_1_categorical_accuracy: 9.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0315 - factorized_top_k/top_10_categorical_accuracy: 0.0656 - factorized_top_k/top_50_categorical_accuracy: 0.2442 - factorized_top_k/top_100_categorical_accuracy: 0.3854 - loss: 63499.0732 - regularization_loss: 0.0000e+00 - total_loss: 63499.0732\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.0743 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0317 - factorized_top_k/top_10_categorical_accuracy: 0.0661 - factorized_top_k/top_50_categorical_accuracy: 0.2462 - factorized_top_k/top_100_categorical_accuracy: 0.3884 - loss: 63410.1690 - regularization_loss: 0.0000e+00 - total_loss: 63410.1690\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 4s 441ms/step - root_mean_squared_error: 1.0614 - factorized_top_k/top_1_categorical_accuracy: 6.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0316 - factorized_top_k/top_10_categorical_accuracy: 0.0662 - factorized_top_k/top_50_categorical_accuracy: 0.2479 - factorized_top_k/top_100_categorical_accuracy: 0.3912 - loss: 63328.7095 - regularization_loss: 0.0000e+00 - total_loss: 63328.7095\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.0567 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0321 - factorized_top_k/top_10_categorical_accuracy: 0.0667 - factorized_top_k/top_50_categorical_accuracy: 0.2501 - factorized_top_k/top_100_categorical_accuracy: 0.3943 - loss: 63253.9055 - regularization_loss: 0.0000e+00 - total_loss: 63253.9055\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 4s 446ms/step - root_mean_squared_error: 1.0639 - factorized_top_k/top_1_categorical_accuracy: 8.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0324 - factorized_top_k/top_10_categorical_accuracy: 0.0669 - factorized_top_k/top_50_categorical_accuracy: 0.2520 - factorized_top_k/top_100_categorical_accuracy: 0.3974 - loss: 63185.0447 - regularization_loss: 0.0000e+00 - total_loss: 63185.0447\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.0380 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0329 - factorized_top_k/top_10_categorical_accuracy: 0.0674 - factorized_top_k/top_50_categorical_accuracy: 0.2540 - factorized_top_k/top_100_categorical_accuracy: 0.3999 - loss: 63121.3295 - regularization_loss: 0.0000e+00 - total_loss: 63121.3295\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 1.0432 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0330 - factorized_top_k/top_10_categorical_accuracy: 0.0676 - factorized_top_k/top_50_categorical_accuracy: 0.2559 - factorized_top_k/top_100_categorical_accuracy: 0.4022 - loss: 63062.2116 - regularization_loss: 0.0000e+00 - total_loss: 63062.2116\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 5s 466ms/step - root_mean_squared_error: 1.0354 - factorized_top_k/top_1_categorical_accuracy: 8.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0330 - factorized_top_k/top_10_categorical_accuracy: 0.0680 - factorized_top_k/top_50_categorical_accuracy: 0.2577 - factorized_top_k/top_100_categorical_accuracy: 0.4053 - loss: 63007.2351 - regularization_loss: 0.0000e+00 - total_loss: 63007.2351\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 4s 436ms/step - root_mean_squared_error: 1.0301 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0334 - factorized_top_k/top_10_categorical_accuracy: 0.0682 - factorized_top_k/top_50_categorical_accuracy: 0.2591 - factorized_top_k/top_100_categorical_accuracy: 0.4081 - loss: 62955.9091 - regularization_loss: 0.0000e+00 - total_loss: 62955.9091\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 427ms/step - root_mean_squared_error: 1.0272 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0336 - factorized_top_k/top_10_categorical_accuracy: 0.0690 - factorized_top_k/top_50_categorical_accuracy: 0.2613 - factorized_top_k/top_100_categorical_accuracy: 0.4105 - loss: 62907.9339 - regularization_loss: 0.0000e+00 - total_loss: 62907.9339\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 1.0195 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0335 - factorized_top_k/top_10_categorical_accuracy: 0.0698 - factorized_top_k/top_50_categorical_accuracy: 0.2631 - factorized_top_k/top_100_categorical_accuracy: 0.4125 - loss: 62862.8665 - regularization_loss: 0.0000e+00 - total_loss: 62862.8665\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 4s 441ms/step - root_mean_squared_error: 1.0132 - factorized_top_k/top_1_categorical_accuracy: 9.2500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0337 - factorized_top_k/top_10_categorical_accuracy: 0.0700 - factorized_top_k/top_50_categorical_accuracy: 0.2643 - factorized_top_k/top_100_categorical_accuracy: 0.4151 - loss: 62820.5483 - regularization_loss: 0.0000e+00 - total_loss: 62820.5483\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 1.0038 - factorized_top_k/top_1_categorical_accuracy: 8.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0338 - factorized_top_k/top_10_categorical_accuracy: 0.0705 - factorized_top_k/top_50_categorical_accuracy: 0.2659 - factorized_top_k/top_100_categorical_accuracy: 0.4170 - loss: 62780.6108 - regularization_loss: 0.0000e+00 - total_loss: 62780.6108\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 4s 430ms/step - root_mean_squared_error: 1.0040 - factorized_top_k/top_1_categorical_accuracy: 9.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0339 - factorized_top_k/top_10_categorical_accuracy: 0.0710 - factorized_top_k/top_50_categorical_accuracy: 0.2678 - factorized_top_k/top_100_categorical_accuracy: 0.4191 - loss: 62742.9382 - regularization_loss: 0.0000e+00 - total_loss: 62742.9382\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 5s 455ms/step - root_mean_squared_error: 1.0011 - factorized_top_k/top_1_categorical_accuracy: 7.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0343 - factorized_top_k/top_10_categorical_accuracy: 0.0713 - factorized_top_k/top_50_categorical_accuracy: 0.2694 - factorized_top_k/top_100_categorical_accuracy: 0.4209 - loss: 62707.2244 - regularization_loss: 0.0000e+00 - total_loss: 62707.2244\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 4s 445ms/step - root_mean_squared_error: 0.9946 - factorized_top_k/top_1_categorical_accuracy: 8.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0347 - factorized_top_k/top_10_categorical_accuracy: 0.0714 - factorized_top_k/top_50_categorical_accuracy: 0.2710 - factorized_top_k/top_100_categorical_accuracy: 0.4228 - loss: 62673.4070 - regularization_loss: 0.0000e+00 - total_loss: 62673.4070\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 4s 425ms/step - root_mean_squared_error: 0.9899 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0351 - factorized_top_k/top_10_categorical_accuracy: 0.0717 - factorized_top_k/top_50_categorical_accuracy: 0.2723 - factorized_top_k/top_100_categorical_accuracy: 0.4249 - loss: 62641.2365 - regularization_loss: 0.0000e+00 - total_loss: 62641.2365\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 433ms/step - root_mean_squared_error: 0.9827 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0349 - factorized_top_k/top_10_categorical_accuracy: 0.0715 - factorized_top_k/top_50_categorical_accuracy: 0.2737 - factorized_top_k/top_100_categorical_accuracy: 0.4264 - loss: 62610.6463 - regularization_loss: 0.0000e+00 - total_loss: 62610.6463\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 426ms/step - root_mean_squared_error: 0.9657 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0354 - factorized_top_k/top_10_categorical_accuracy: 0.0722 - factorized_top_k/top_50_categorical_accuracy: 0.2747 - factorized_top_k/top_100_categorical_accuracy: 0.4285 - loss: 62581.3956 - regularization_loss: 0.0000e+00 - total_loss: 62581.3956\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 424ms/step - root_mean_squared_error: 1.0269 - factorized_top_k/top_1_categorical_accuracy: 9.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0352 - factorized_top_k/top_10_categorical_accuracy: 0.0722 - factorized_top_k/top_50_categorical_accuracy: 0.2758 - factorized_top_k/top_100_categorical_accuracy: 0.4305 - loss: 62553.7827 - regularization_loss: 0.0000e+00 - total_loss: 62553.7827\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 4s 446ms/step - root_mean_squared_error: 0.9375 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0354 - factorized_top_k/top_10_categorical_accuracy: 0.0727 - factorized_top_k/top_50_categorical_accuracy: 0.2773 - factorized_top_k/top_100_categorical_accuracy: 0.4319 - loss: 62526.8793 - regularization_loss: 0.0000e+00 - total_loss: 62526.8793\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 0.9795 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0354 - factorized_top_k/top_10_categorical_accuracy: 0.0728 - factorized_top_k/top_50_categorical_accuracy: 0.2782 - factorized_top_k/top_100_categorical_accuracy: 0.4332 - loss: 62501.4389 - regularization_loss: 0.0000e+00 - total_loss: 62501.4389\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 0.9735 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0356 - factorized_top_k/top_10_categorical_accuracy: 0.0732 - factorized_top_k/top_50_categorical_accuracy: 0.2794 - factorized_top_k/top_100_categorical_accuracy: 0.4345 - loss: 62476.9450 - regularization_loss: 0.0000e+00 - total_loss: 62476.9450\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 0.9637 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0358 - factorized_top_k/top_10_categorical_accuracy: 0.0733 - factorized_top_k/top_50_categorical_accuracy: 0.2806 - factorized_top_k/top_100_categorical_accuracy: 0.4357 - loss: 62453.4457 - regularization_loss: 0.0000e+00 - total_loss: 62453.4457\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 4s 438ms/step - root_mean_squared_error: 0.9557 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0363 - factorized_top_k/top_10_categorical_accuracy: 0.0737 - factorized_top_k/top_50_categorical_accuracy: 0.2817 - factorized_top_k/top_100_categorical_accuracy: 0.4370 - loss: 62430.8416 - regularization_loss: 0.0000e+00 - total_loss: 62430.8416\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 0.9481 - factorized_top_k/top_1_categorical_accuracy: 9.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0360 - factorized_top_k/top_10_categorical_accuracy: 0.0737 - factorized_top_k/top_50_categorical_accuracy: 0.2826 - factorized_top_k/top_100_categorical_accuracy: 0.4383 - loss: 62409.1080 - regularization_loss: 0.0000e+00 - total_loss: 62409.1080\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 5s 462ms/step - root_mean_squared_error: 0.9474 - factorized_top_k/top_1_categorical_accuracy: 8.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0360 - factorized_top_k/top_10_categorical_accuracy: 0.0740 - factorized_top_k/top_50_categorical_accuracy: 0.2836 - factorized_top_k/top_100_categorical_accuracy: 0.4399 - loss: 62388.1616 - regularization_loss: 0.0000e+00 - total_loss: 62388.1616\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 5s 457ms/step - root_mean_squared_error: 0.9415 - factorized_top_k/top_1_categorical_accuracy: 7.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0360 - factorized_top_k/top_10_categorical_accuracy: 0.0741 - factorized_top_k/top_50_categorical_accuracy: 0.2843 - factorized_top_k/top_100_categorical_accuracy: 0.4410 - loss: 62367.9837 - regularization_loss: 0.0000e+00 - total_loss: 62367.9837\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 5s 476ms/step - root_mean_squared_error: 0.9354 - factorized_top_k/top_1_categorical_accuracy: 6.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0362 - factorized_top_k/top_10_categorical_accuracy: 0.0743 - factorized_top_k/top_50_categorical_accuracy: 0.2854 - factorized_top_k/top_100_categorical_accuracy: 0.4420 - loss: 62348.4925 - regularization_loss: 0.0000e+00 - total_loss: 62348.4925\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 5s 472ms/step - root_mean_squared_error: 0.9205 - factorized_top_k/top_1_categorical_accuracy: 7.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0360 - factorized_top_k/top_10_categorical_accuracy: 0.0746 - factorized_top_k/top_50_categorical_accuracy: 0.2864 - factorized_top_k/top_100_categorical_accuracy: 0.4430 - loss: 62329.6655 - regularization_loss: 0.0000e+00 - total_loss: 62329.6655\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 0.9145 - factorized_top_k/top_1_categorical_accuracy: 6.6250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0361 - factorized_top_k/top_10_categorical_accuracy: 0.0751 - factorized_top_k/top_50_categorical_accuracy: 0.2873 - factorized_top_k/top_100_categorical_accuracy: 0.4442 - loss: 62311.4496 - regularization_loss: 0.0000e+00 - total_loss: 62311.4496\n",
      "5/5 [==============================] - 2s 247ms/step - root_mean_squared_error: 0.9896 - factorized_top_k/top_1_categorical_accuracy: 1.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0014 - factorized_top_k/top_10_categorical_accuracy: 0.0040 - factorized_top_k/top_50_categorical_accuracy: 0.0684 - factorized_top_k/top_100_categorical_accuracy: 0.1742 - loss: 32792.6758 - regularization_loss: 0.0000e+00 - total_loss: 32792.6758\n",
      "Retrieval top-100 accuracy: 0.174.\n",
      "Ranking RMSE: 0.990.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01))\n",
    "model.fit(cached_train, epochs=50)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 6s 471ms/step - root_mean_squared_error: 249.8298 - factorized_top_k/top_1_categorical_accuracy: 3.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0029 - factorized_top_k/top_10_categorical_accuracy: 0.0057 - factorized_top_k/top_50_categorical_accuracy: 0.0305 - factorized_top_k/top_100_categorical_accuracy: 0.0623 - loss: 126293.7528 - regularization_loss: 0.0000e+00 - total_loss: 126293.7528\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 5s 464ms/step - root_mean_squared_error: 2.0819 - factorized_top_k/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0028 - factorized_top_k/top_10_categorical_accuracy: 0.0063 - factorized_top_k/top_50_categorical_accuracy: 0.0341 - factorized_top_k/top_100_categorical_accuracy: 0.0724 - loss: 70157.4347 - regularization_loss: 0.0000e+00 - total_loss: 70157.4347\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 5s 462ms/step - root_mean_squared_error: 1.7456 - factorized_top_k/top_1_categorical_accuracy: 8.7500e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0059 - factorized_top_k/top_10_categorical_accuracy: 0.0112 - factorized_top_k/top_50_categorical_accuracy: 0.0514 - factorized_top_k/top_100_categorical_accuracy: 0.1055 - loss: 69078.4453 - regularization_loss: 0.0000e+00 - total_loss: 69078.4453\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 5s 463ms/step - root_mean_squared_error: 1.6001 - factorized_top_k/top_1_categorical_accuracy: 6.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0092 - factorized_top_k/top_10_categorical_accuracy: 0.0177 - factorized_top_k/top_50_categorical_accuracy: 0.0855 - factorized_top_k/top_100_categorical_accuracy: 0.1675 - loss: 67597.2358 - regularization_loss: 0.0000e+00 - total_loss: 67597.2358\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 5s 462ms/step - root_mean_squared_error: 1.5262 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0117 - factorized_top_k/top_10_categorical_accuracy: 0.0250 - factorized_top_k/top_50_categorical_accuracy: 0.1256 - factorized_top_k/top_100_categorical_accuracy: 0.2351 - loss: 66487.7450 - regularization_loss: 0.0000e+00 - total_loss: 66487.7450\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 5s 462ms/step - root_mean_squared_error: 1.4306 - factorized_top_k/top_1_categorical_accuracy: 9.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0148 - factorized_top_k/top_10_categorical_accuracy: 0.0314 - factorized_top_k/top_50_categorical_accuracy: 0.1570 - factorized_top_k/top_100_categorical_accuracy: 0.2815 - loss: 65911.8608 - regularization_loss: 0.0000e+00 - total_loss: 65911.8608\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 5s 461ms/step - root_mean_squared_error: 1.3263 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0154 - factorized_top_k/top_10_categorical_accuracy: 0.0353 - factorized_top_k/top_50_categorical_accuracy: 0.1742 - factorized_top_k/top_100_categorical_accuracy: 0.3068 - loss: 65640.7983 - regularization_loss: 0.0000e+00 - total_loss: 65640.7983\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 5s 470ms/step - root_mean_squared_error: 1.2336 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0162 - factorized_top_k/top_10_categorical_accuracy: 0.0372 - factorized_top_k/top_50_categorical_accuracy: 0.1850 - factorized_top_k/top_100_categorical_accuracy: 0.3226 - loss: 65489.1733 - regularization_loss: 0.0000e+00 - total_loss: 65489.1733\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.5652 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0161 - factorized_top_k/top_10_categorical_accuracy: 0.0371 - factorized_top_k/top_50_categorical_accuracy: 0.1914 - factorized_top_k/top_100_categorical_accuracy: 0.3308 - loss: 65395.3232 - regularization_loss: 0.0000e+00 - total_loss: 65395.3232\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 4s 418ms/step - root_mean_squared_error: 1.4927 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0162 - factorized_top_k/top_10_categorical_accuracy: 0.0382 - factorized_top_k/top_50_categorical_accuracy: 0.1984 - factorized_top_k/top_100_categorical_accuracy: 0.3386 - loss: 65306.1392 - regularization_loss: 0.0000e+00 - total_loss: 65306.1392\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 4s 415ms/step - root_mean_squared_error: 1.5446 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0166 - factorized_top_k/top_10_categorical_accuracy: 0.0396 - factorized_top_k/top_50_categorical_accuracy: 0.2030 - factorized_top_k/top_100_categorical_accuracy: 0.3446 - loss: 65221.1598 - regularization_loss: 0.0000e+00 - total_loss: 65221.1598\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 4s 412ms/step - root_mean_squared_error: 1.4991 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0170 - factorized_top_k/top_10_categorical_accuracy: 0.0402 - factorized_top_k/top_50_categorical_accuracy: 0.2056 - factorized_top_k/top_100_categorical_accuracy: 0.3485 - loss: 65151.1428 - regularization_loss: 0.0000e+00 - total_loss: 65151.1428\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 4s 413ms/step - root_mean_squared_error: 1.4893 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0175 - factorized_top_k/top_10_categorical_accuracy: 0.0410 - factorized_top_k/top_50_categorical_accuracy: 0.2089 - factorized_top_k/top_100_categorical_accuracy: 0.3530 - loss: 65097.3949 - regularization_loss: 0.0000e+00 - total_loss: 65097.3949\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 4s 415ms/step - root_mean_squared_error: 1.5290 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0177 - factorized_top_k/top_10_categorical_accuracy: 0.0415 - factorized_top_k/top_50_categorical_accuracy: 0.2099 - factorized_top_k/top_100_categorical_accuracy: 0.3548 - loss: 65055.7230 - regularization_loss: 0.0000e+00 - total_loss: 65055.7230\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 4s 413ms/step - root_mean_squared_error: 1.4127 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0181 - factorized_top_k/top_10_categorical_accuracy: 0.0419 - factorized_top_k/top_50_categorical_accuracy: 0.2126 - factorized_top_k/top_100_categorical_accuracy: 0.3580 - loss: 65016.3168 - regularization_loss: 0.0000e+00 - total_loss: 65016.3168\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 4s 414ms/step - root_mean_squared_error: 1.3223 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0181 - factorized_top_k/top_10_categorical_accuracy: 0.0420 - factorized_top_k/top_50_categorical_accuracy: 0.2130 - factorized_top_k/top_100_categorical_accuracy: 0.3609 - loss: 64984.8928 - regularization_loss: 0.0000e+00 - total_loss: 64984.8928\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.2835 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0179 - factorized_top_k/top_10_categorical_accuracy: 0.0422 - factorized_top_k/top_50_categorical_accuracy: 0.2145 - factorized_top_k/top_100_categorical_accuracy: 0.3625 - loss: 64960.4901 - regularization_loss: 0.0000e+00 - total_loss: 64960.4901\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 4s 450ms/step - root_mean_squared_error: 1.1608 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0180 - factorized_top_k/top_10_categorical_accuracy: 0.0420 - factorized_top_k/top_50_categorical_accuracy: 0.2150 - factorized_top_k/top_100_categorical_accuracy: 0.3630 - loss: 64938.0597 - regularization_loss: 0.0000e+00 - total_loss: 64938.0597\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.1414 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0181 - factorized_top_k/top_10_categorical_accuracy: 0.0427 - factorized_top_k/top_50_categorical_accuracy: 0.2167 - factorized_top_k/top_100_categorical_accuracy: 0.3647 - loss: 64925.4162 - regularization_loss: 0.0000e+00 - total_loss: 64925.4162\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 4s 418ms/step - root_mean_squared_error: 1.1029 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0184 - factorized_top_k/top_10_categorical_accuracy: 0.0424 - factorized_top_k/top_50_categorical_accuracy: 0.2175 - factorized_top_k/top_100_categorical_accuracy: 0.3661 - loss: 64905.3153 - regularization_loss: 0.0000e+00 - total_loss: 64905.3153\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 4s 418ms/step - root_mean_squared_error: 1.1044 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0183 - factorized_top_k/top_10_categorical_accuracy: 0.0432 - factorized_top_k/top_50_categorical_accuracy: 0.2187 - factorized_top_k/top_100_categorical_accuracy: 0.3675 - loss: 64883.3253 - regularization_loss: 0.0000e+00 - total_loss: 64883.3253\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 4s 444ms/step - root_mean_squared_error: 1.0746 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0426 - factorized_top_k/top_50_categorical_accuracy: 0.2192 - factorized_top_k/top_100_categorical_accuracy: 0.3673 - loss: 64877.3643 - regularization_loss: 0.0000e+00 - total_loss: 64877.3643\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.0684 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0184 - factorized_top_k/top_10_categorical_accuracy: 0.0428 - factorized_top_k/top_50_categorical_accuracy: 0.2196 - factorized_top_k/top_100_categorical_accuracy: 0.3684 - loss: 64864.7386 - regularization_loss: 0.0000e+00 - total_loss: 64864.7386\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 1.2624 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0428 - factorized_top_k/top_50_categorical_accuracy: 0.2201 - factorized_top_k/top_100_categorical_accuracy: 0.3696 - loss: 64857.0078 - regularization_loss: 0.0000e+00 - total_loss: 64857.0078\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 5s 467ms/step - root_mean_squared_error: 2.0750 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0426 - factorized_top_k/top_50_categorical_accuracy: 0.2208 - factorized_top_k/top_100_categorical_accuracy: 0.3707 - loss: 64843.3004 - regularization_loss: 0.0000e+00 - total_loss: 64843.3004\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 5s 455ms/step - root_mean_squared_error: 1.1363 - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0181 - factorized_top_k/top_10_categorical_accuracy: 0.0426 - factorized_top_k/top_50_categorical_accuracy: 0.2207 - factorized_top_k/top_100_categorical_accuracy: 0.3708 - loss: 64841.5433 - regularization_loss: 0.0000e+00 - total_loss: 64841.5433\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 5s 475ms/step - root_mean_squared_error: 1.1830 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0184 - factorized_top_k/top_10_categorical_accuracy: 0.0428 - factorized_top_k/top_50_categorical_accuracy: 0.2206 - factorized_top_k/top_100_categorical_accuracy: 0.3712 - loss: 64837.0987 - regularization_loss: 0.0000e+00 - total_loss: 64837.0987\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 2.4232 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0428 - factorized_top_k/top_50_categorical_accuracy: 0.2210 - factorized_top_k/top_100_categorical_accuracy: 0.3721 - loss: 64828.7834 - regularization_loss: 0.0000e+00 - total_loss: 64828.7834\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 4s 418ms/step - root_mean_squared_error: 4.6273 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0186 - factorized_top_k/top_10_categorical_accuracy: 0.0426 - factorized_top_k/top_50_categorical_accuracy: 0.2207 - factorized_top_k/top_100_categorical_accuracy: 0.3724 - loss: 64835.3203 - regularization_loss: 0.0000e+00 - total_loss: 64835.3203\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 432ms/step - root_mean_squared_error: 1.2205 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0179 - factorized_top_k/top_10_categorical_accuracy: 0.0423 - factorized_top_k/top_50_categorical_accuracy: 0.2213 - factorized_top_k/top_100_categorical_accuracy: 0.3731 - loss: 64817.1889 - regularization_loss: 0.0000e+00 - total_loss: 64817.1889\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 1.1545 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0184 - factorized_top_k/top_10_categorical_accuracy: 0.0433 - factorized_top_k/top_50_categorical_accuracy: 0.2221 - factorized_top_k/top_100_categorical_accuracy: 0.3736 - loss: 64807.3885 - regularization_loss: 0.0000e+00 - total_loss: 64807.3885\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.1297 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0184 - factorized_top_k/top_10_categorical_accuracy: 0.0434 - factorized_top_k/top_50_categorical_accuracy: 0.2229 - factorized_top_k/top_100_categorical_accuracy: 0.3750 - loss: 64810.0426 - regularization_loss: 0.0000e+00 - total_loss: 64810.0426\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 1.1260 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0187 - factorized_top_k/top_10_categorical_accuracy: 0.0433 - factorized_top_k/top_50_categorical_accuracy: 0.2231 - factorized_top_k/top_100_categorical_accuracy: 0.3758 - loss: 64792.6839 - regularization_loss: 0.0000e+00 - total_loss: 64792.6839\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 4s 418ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0187 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.2235 - factorized_top_k/top_100_categorical_accuracy: 0.3758 - loss: 64793.9418 - regularization_loss: 0.0000e+00 - total_loss: 64793.9418\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 4s 418ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0188 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - factorized_top_k/top_50_categorical_accuracy: 0.2237 - factorized_top_k/top_100_categorical_accuracy: 0.3762 - loss: 64790.6527 - regularization_loss: 0.0000e+00 - total_loss: 64790.6527\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0428 - factorized_top_k/top_50_categorical_accuracy: 0.2241 - factorized_top_k/top_100_categorical_accuracy: 0.3756 - loss: 64774.8828 - regularization_loss: 0.0000e+00 - total_loss: 64774.8828\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 455ms/step - root_mean_squared_error: 1.2183 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.2230 - factorized_top_k/top_100_categorical_accuracy: 0.3763 - loss: 64784.5625 - regularization_loss: 0.0000e+00 - total_loss: 64784.5625\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 5s 465ms/step - root_mean_squared_error: 1.1275 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0183 - factorized_top_k/top_10_categorical_accuracy: 0.0432 - factorized_top_k/top_50_categorical_accuracy: 0.2234 - factorized_top_k/top_100_categorical_accuracy: 0.3759 - loss: 64789.7528 - regularization_loss: 0.0000e+00 - total_loss: 64789.7528\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 1.1258 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0188 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.2236 - factorized_top_k/top_100_categorical_accuracy: 0.3757 - loss: 64773.1222 - regularization_loss: 0.0000e+00 - total_loss: 64773.1222\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 4s 416ms/step - root_mean_squared_error: 1.1259 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0185 - factorized_top_k/top_10_categorical_accuracy: 0.0436 - factorized_top_k/top_50_categorical_accuracy: 0.2247 - factorized_top_k/top_100_categorical_accuracy: 0.3770 - loss: 64768.9553 - regularization_loss: 0.0000e+00 - total_loss: 64768.9553\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 4s 421ms/step - root_mean_squared_error: 1.1260 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0185 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.2244 - factorized_top_k/top_100_categorical_accuracy: 0.3767 - loss: 64771.1925 - regularization_loss: 0.0000e+00 - total_loss: 64771.1925\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 5s 463ms/step - root_mean_squared_error: 1.1272 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0187 - factorized_top_k/top_10_categorical_accuracy: 0.0433 - factorized_top_k/top_50_categorical_accuracy: 0.2253 - factorized_top_k/top_100_categorical_accuracy: 0.3771 - loss: 64760.2578 - regularization_loss: 0.0000e+00 - total_loss: 64760.2578\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 4s 423ms/step - root_mean_squared_error: 1.1269 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0186 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - factorized_top_k/top_50_categorical_accuracy: 0.2249 - factorized_top_k/top_100_categorical_accuracy: 0.3763 - loss: 64763.4901 - regularization_loss: 0.0000e+00 - total_loss: 64763.4901\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 5s 457ms/step - root_mean_squared_error: 1.1271 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0183 - factorized_top_k/top_10_categorical_accuracy: 0.0432 - factorized_top_k/top_50_categorical_accuracy: 0.2245 - factorized_top_k/top_100_categorical_accuracy: 0.3768 - loss: 64755.0412 - regularization_loss: 0.0000e+00 - total_loss: 64755.0412\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 4s 419ms/step - root_mean_squared_error: 1.1270 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0188 - factorized_top_k/top_10_categorical_accuracy: 0.0438 - factorized_top_k/top_50_categorical_accuracy: 0.2258 - factorized_top_k/top_100_categorical_accuracy: 0.3774 - loss: 64752.8750 - regularization_loss: 0.0000e+00 - total_loss: 64752.8750\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 4s 415ms/step - root_mean_squared_error: 1.1270 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0187 - factorized_top_k/top_10_categorical_accuracy: 0.0437 - factorized_top_k/top_50_categorical_accuracy: 0.2259 - factorized_top_k/top_100_categorical_accuracy: 0.3780 - loss: 64763.3835 - regularization_loss: 0.0000e+00 - total_loss: 64763.3835\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 4s 420ms/step - root_mean_squared_error: 1.1270 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0187 - factorized_top_k/top_10_categorical_accuracy: 0.0439 - factorized_top_k/top_50_categorical_accuracy: 0.2258 - factorized_top_k/top_100_categorical_accuracy: 0.3781 - loss: 64755.1790 - regularization_loss: 0.0000e+00 - total_loss: 64755.1790\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 5s 468ms/step - root_mean_squared_error: 1.1270 - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0184 - factorized_top_k/top_10_categorical_accuracy: 0.0437 - factorized_top_k/top_50_categorical_accuracy: 0.2258 - factorized_top_k/top_100_categorical_accuracy: 0.3778 - loss: 64746.4240 - regularization_loss: 0.0000e+00 - total_loss: 64746.4240\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 5s 452ms/step - root_mean_squared_error: 1.1270 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0433 - factorized_top_k/top_50_categorical_accuracy: 0.2249 - factorized_top_k/top_100_categorical_accuracy: 0.3779 - loss: 64752.8331 - regularization_loss: 0.0000e+00 - total_loss: 64752.8331\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 5s 461ms/step - root_mean_squared_error: 1.1270 - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0181 - factorized_top_k/top_10_categorical_accuracy: 0.0436 - factorized_top_k/top_50_categorical_accuracy: 0.2258 - factorized_top_k/top_100_categorical_accuracy: 0.3782 - loss: 64748.0973 - regularization_loss: 0.0000e+00 - total_loss: 64748.0973\n",
      "5/5 [==============================] - 2s 244ms/step - root_mean_squared_error: 1.1275 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0012 - factorized_top_k/top_10_categorical_accuracy: 0.0052 - factorized_top_k/top_50_categorical_accuracy: 0.0785 - factorized_top_k/top_100_categorical_accuracy: 0.1919 - loss: 32806.9290 - regularization_loss: 0.0000e+00 - total_loss: 32806.9290\n",
      "Retrieval top-100 accuracy: 0.192.\n",
      "Ranking RMSE: 1.127.\n"
     ]
    }
   ],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.1))\n",
    "model.fit(cached_train, epochs=50)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05662500113248825,\n",
       " 0.09629999846220016,\n",
       " 0.1764875054359436,\n",
       " 0.2833249866962433,\n",
       " 0.33338749408721924,\n",
       " 0.34255000948905945,\n",
       " 0.34536251425743103,\n",
       " 0.34353750944137573,\n",
       " 0.34220001101493835,\n",
       " 0.33951249718666077,\n",
       " 0.33841249346733093,\n",
       " 0.33723750710487366,\n",
       " 0.3356125056743622,\n",
       " 0.3351125121116638,\n",
       " 0.334199994802475,\n",
       " 0.3333374857902527,\n",
       " 0.3324500024318695,\n",
       " 0.3318125009536743,\n",
       " 0.3310374915599823,\n",
       " 0.33031249046325684,\n",
       " 0.3307499885559082,\n",
       " 0.3296250104904175,\n",
       " 0.32932499051094055,\n",
       " 0.3287000060081482,\n",
       " 0.32827499508857727,\n",
       " 0.328062504529953,\n",
       " 0.328125,\n",
       " 0.32727500796318054,\n",
       " 0.32714998722076416,\n",
       " 0.32698750495910645,\n",
       " 0.3266499936580658,\n",
       " 0.3262749910354614,\n",
       " 0.3260999917984009,\n",
       " 0.32606250047683716,\n",
       " 0.3259499967098236,\n",
       " 0.32622501254081726,\n",
       " 0.32583749294281006,\n",
       " 0.3259125053882599,\n",
       " 0.32587501406669617,\n",
       " 0.3260500133037567,\n",
       " 0.32615000009536743,\n",
       " 0.3260500133037567,\n",
       " 0.3259499967098236,\n",
       " 0.3261750042438507,\n",
       " 0.32624998688697815,\n",
       " 0.3268499970436096,\n",
       " 0.32673749327659607,\n",
       " 0.3267875015735626,\n",
       " 0.327162504196167,\n",
       " 0.3273000121116638]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaOhOne.history['factorized_top_k/top_100_categorical_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05649999901652336,\n",
       " 0.07458750158548355,\n",
       " 0.09425000101327896,\n",
       " 0.11913750320672989,\n",
       " 0.1503625065088272,\n",
       " 0.19242499768733978,\n",
       " 0.24156250059604645,\n",
       " 0.2879374921321869,\n",
       " 0.3233624994754791,\n",
       " 0.34117498993873596,\n",
       " 0.34956249594688416,\n",
       " 0.3518249988555908,\n",
       " 0.35183748602867126,\n",
       " 0.3510124981403351,\n",
       " 0.3483999967575073,\n",
       " 0.34654998779296875,\n",
       " 0.3440625071525574,\n",
       " 0.34299999475479126,\n",
       " 0.3406749963760376,\n",
       " 0.33783748745918274,\n",
       " 0.33640000224113464,\n",
       " 0.33515000343322754,\n",
       " 0.3336375057697296,\n",
       " 0.33198750019073486,\n",
       " 0.3302749991416931,\n",
       " 0.32936251163482666,\n",
       " 0.3288249969482422,\n",
       " 0.3274250030517578,\n",
       " 0.3274500072002411,\n",
       " 0.32651248574256897,\n",
       " 0.32587501406669617,\n",
       " 0.32622501254081726,\n",
       " 0.3260999917984009,\n",
       " 0.3261624872684479,\n",
       " 0.32621249556541443,\n",
       " 0.32698750495910645,\n",
       " 0.32718750834465027,\n",
       " 0.3275125026702881,\n",
       " 0.3275874853134155,\n",
       " 0.32811251282691956,\n",
       " 0.32875001430511475,\n",
       " 0.32936251163482666,\n",
       " 0.3299750089645386,\n",
       " 0.3304624855518341,\n",
       " 0.3310999870300293,\n",
       " 0.3319624960422516,\n",
       " 0.3327625095844269,\n",
       " 0.33364999294281006,\n",
       " 0.3343124985694885,\n",
       " 0.33524999022483826]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " adamOhOhOne.history[\"factorized_top_k/top_100_categorical_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x243932f1790>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_validation_runs = len(rmsOhOhOne[\"factorized_top_k/top_100_categorical_accuracy\"])\n",
    "epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
    "\n",
    "plt.plot(epochs, adaOhOne.history[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"ada\")\n",
    "plt.plot(epochs, adamOhOhOne.history[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"adam\")\n",
    "plt.plot(epochs, rmsOhOhOne[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"rms\")\n",
    "#plt.plot(RMS_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"RMS .01\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAdam = max(adamOhOhOne.history[\"factorized_top_k/top_100_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAda = max(adaOhOne.history[\"factorized_top_k/top_100_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaOhOne.history[\"factorized_top_k/top_100_categorical_accuracy\"].index(maxAda)  #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adamOhOhOne.history[\"factorized_top_k/top_100_categorical_accuracy\"].index(maxAdam)   #12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni_rkOsaB3f9"
   },
   "source": [
    "The result is a model that performs roughly as well on both tasks as each specialized model. \n",
    "\n",
    "While the results here do not show a clear accuracy benefit from a joint model in this case, multi-task learning is in general an extremely useful tool. We can expect better results when we can transfer knowledge from a data-abundant task (such as clicks) to a closely related data-sparse task (such as purchases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 80: [b'Citizen Kane (1941)' b'Room with a View, A (1986)'\n",
      " b'Third Man, The (1949)' b'Graduate, The (1967)'\n",
      " b'Raise the Red Lantern (1991)' b'Roman Holiday (1953)'\n",
      " b'It Happened One Night (1934)' b'Killing Fields, The (1984)'\n",
      " b'Annie Hall (1977)' b'Cinema Paradiso (1988)']\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index(movies.batch(1000).map(model.movie_model), movies)\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"80\"]))\n",
    "print(f\"Recommendations for user 80: {titles[0, :]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multitask.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
